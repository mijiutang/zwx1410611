 

# 第 5 章  数据的深度分析(数据挖掘、机器学习)

从明细数据，计算一些聚集统计量 (Aggregation), 生成报表 (Report), 观察同比/ 环比的变化，以及通过数据透视表 (Pivotal Table) 从不同维度观察数据的汇总信息，只能算是对数据的简单分析。要从数据里挖掘和提取隐含的模式和规律，简单分析是无能为力的。我们需要在数据上运行更加复杂的算法，这些算法主要是数据挖掘和机器学习算法。

## 5.1  机器学习与数据挖掘简介  

从广义上来说，机器学习是一种能够赋予机器学习的能力，让它完成直接编程无法完成的功能的方法。从实践上来说，机器学习是一种通过利用数据，训练出模型，然后使用模型进行预测的方法。由此可见，数据对于机器学习的意义。可以说数据是原材料，机器学习是加工工具，模型是产品。我们可以利用这个产品做预测，指导未来的决策。

机器学习和人工智能紧密关联。人工智能的概念自20世纪50年代提出以来，学术界和产业界不断研究和探索。人工智能的研究大概经历了几个阶段，从早期的逻辑推理，到中期的专家系统，到近期的机器学习。从另外一个角度来看，人类的智能主要包括归纳总结和逻辑演绎，对应到人工智能研究的连接主义(如神经网络)和符号主义(如符号推理系统)。符号主义的主要思想是应用逻辑推理法则，从公理出发，推演整个理论体系。连接主义的研究策略，以神经网络为例，则试图在研究和了解人脑工作原理的基础上，创造出一个人工的神经网络，然后利用数据对该网络进行训练，使其具有强大的预测能力。由此可以看出，人工智能包含机器学习，人工神经网络是机器学习的一种形式。

数据挖掘可以认为是机器学习算法在数据库上的应用，很多数据挖掘中的算法是机器学习算法在数据库中的优化。数据挖掘能够形成自己的学术圈，是因为它贡献了独特的算法，其中最著名的是关联规则分析方法——Apriori 算法。Apriori 算法不是机器学习算法在数据库上的优化，而是由数据挖掘学术圈的学者创造出来的算法。关联规则的功能，可以通过下面的典故来了解。

在一家超市里有一个有趣的现象：尿布和啤酒赫然摆在一起出售。这个奇怪的举措却使尿布和啤酒的销量双双增加了。很多人认为这是一个笑话，但它是发生在美国沃尔玛连锁超市的真实案例，成为一个典故，不断流传。沃尔玛是著名的零售商，拥有世界上最大的数据仓库系统。为了能够准确了解顾客在其门店的购买习惯，沃尔玛利用数据挖掘方法，对各个门店的原始交易数据进行分析和挖掘。对顾客的购物行为进行购物篮的关联分析，可以知道顾客经常一起购买的商品有哪些。

他们有一个意外的发现，跟尿布一起购买最多的商品竟是啤酒！经过实际调查和分析，揭示了一个隐藏在“尿布与啤酒”背后的美国人的行为模式。在美国，太太经常叮嘱丈夫，下班后为小孩买尿布，丈夫们在买尿布后，有30%～40%的人又随手带回了他们喜欢的啤酒。

机器学习的目的是预测(包括分类和回归)。分类是根据输入数据，判别这些数据隶属于哪个类别 (Category)。回归则是根据输入数据，计算一个输出值 (Numeric)。输入数据一般为一个向量，向量的各个分量也称为特征 (Feature)，输出则是一个类别或者一个数值。

机器学习的基本过程是利用训练数据(包含输入数据和预期输出的分类或者数值)训练一个模型 (Model)，利用这个模型，就可以对新的实例数据 (Instance) 进行分类和计算一个预测值。比如在垃圾邮件分类中，输入向量是邮件里是否包含某个单词或者短语的由0,1构成的向量，表示某个具体的单词或者短语是否出现，输出则是该邮件是否为垃圾邮件的类别判定。对图像进行分类(假设图像集的每张图像只有某种动物，整个图像集对应一个动物集合)，图像分辨率为320×240，图像为真彩色，即每个像素有三个原色。输入向量为320×240×3的向量，输出则是某个动物的分类，比如马、牛、羊、猪、狗、猫等。又比如，在对时间序列数据进行预测的应用中，输入的是在历史时间序列 (Time Series，比如股票价格)上计算的一系列指标(比如移动平均值 (Moving Average) 等)构成的一个向量，输出则是未来某个时刻的该时间序列的一个具体数值。

在本章中，我们把常用的机器学习和数据挖掘方法进行统一的介绍。这些算法可以进行简单的分类，其中的一种分类方法是把机器学习方法分为有监督学习 (Supervised Learning)、无监督学习 (Unsupervised Learning) 和半监督学习 (Semi-Supervised Learning)。

1. **有监督学习**

   有监督学习是机器学习的一种类别，训练数据由输入特征 (Feature) 和预期的输出构成，输出可以是一个连续的值(称为回归分析)，或者是一个分类的类别标签(称为分类)。比如给定20张图片及其标签作为训练集，其中10张图片是小狗的图片，那么其标签为“狗”，另外10张图片是其他物体的图片，那么其标签为“非狗”，有监督学习的任务就是训练一个模型，当这个模型再遇到新的图片时，能够根据这个图片是不是狗的图片，给出“狗”和“非狗”的分类结果。在实际应用中，有监督学习的具体实例包括，输入数据包含疾病的症状，标签是具体的疾病；输入数据包含各种手写字符的图片，标签是这些手写图片对应的实际字符等。决策树、支持向量机 (SVM)、K 最近邻 (KNN) 等算法，都属于有监督学习。

2. **无监督学习**

   无监督学习与有监督学习的区别是它没有训练样本，直接对数据进行建模。K-Means 聚类算法就是典型的无监督学习算法，它的目的是把相似的对象聚集在一起。聚类算法获得的每个类簇 (Cluster)，需要用户进行观察和判断，以便了解其实际意义。

3. **半监督学习**

   半监督学习是有监督学习和无监督学习相结合的一种学习方法。它研究如何利用少量的标注 (Annotated) 样本和大量的未标注样本进行训练和预测的问题。半监督学习包括半监督分类、半监督回归、半监督聚类和半监督降维算法。

## 5.2  主流机器学习与数据挖掘方法  

### 5.2.1 决策树

在机器学习中，决策树是这样一个预测模型，它表示对象属性(比如贷款用户的年龄、是否有工作、是否有房产、信用评分等)和对象类别(是否批准其贷款申请)之间的一种映射。决策树中的非叶子节点，表示对象属性的判断条件。其分支表示符合节点条件的所有对象，树的叶子节点表示对象所属的类别。

文献①给出了一个实例，我们通过该实例来了解决策树的基本原理。表5-1是历史上某银行授予贷款的客户列表。每个记录表示一个客户，表格的各个列表示客户的一些属性 (包括年龄 (Age)、是否有工作 (Has Job)、是否有房产 (Own House)、信用评价 (Credit Rating) 等)。其中，最后一列 (Class) 表示是否授予该客户贷款申请，也就是客户的贷款申请是否获得批准。该表格记录了该银行根据不同用户的情况，是否批准其贷款申请的历史信息。

| ID   | Age    | Has Job | Own House | Credit Rating | Class |
| ---- | ------ | ------- | --------- | ------------- | ----- |
| 1    | young  | false   | false     | fair          | No    |
| 2    | young  | false   | false     | good          | No    |
| 3    | young  | true    | false     | good          | Yes   |
| 4    | young  | true    | true      | fair          | Yes   |
| 5    | young  | false   | false     | fair          | No    |
| 6    | middle | false   | false     | fair          | No    |
| 7    | middle | false   | false     | good          | No    |
| 8    | middle | true    | true      | good          | Yes   |
| 9    | middle | false   | true      | excellent     | Yes   |
| 10   | middle | false   | true      | excellent     | Yes   |
| 11   | old    | false   | true      | excellent     | Yes   |
| 12   | old    | false   | true      | good          | Yes   |
| 13   | old    | true    | false     | good          | Yes   |
| 14   | old    | true    | false     | excellent     | Yes   |
| 15   | old    | false   | false     | fair          | No    |

图5-1是从上述历史数据中训练出来的一个决策树。利用该决策树，银行就可以根据新来客户的一些基本属性，决定是否批准其贷款申请。比如某个新客户的年龄是中年，拥有房产，那么我们根据其基本信息，沿着决策树的树根一直到叶子节点，得出 “Yes” 的决策结果，即可以批准其贷款申请。具体是，我们首先访问根节点Age，根据该用户的年龄为中年，我们应该走中间那个分支，到达是否拥有房产的节点“Own House?”，由于该客户拥有房产，所以我们走左边那个分支，到达叶子节点，节点的标签是 “Yes”，也就是应批准其贷款申请。

![决策树示例](https://via.placeholder.com/150 "决策树示例")

决策树可以转化为一系列的规则 (Rule)，从而构成一个规则集 (Rule Set)，这样的规则很容易理解和运用。比如上述决策树，最左边的分支对应的规则是：如果客户年龄属于青年，而且有工作，那么就可以批准其贷款申请。

1. **决策树的构造过程**

   决策树的创建从根节点开始，也就是需要确定一个属性，根据不同记录在该属性上的取值，对所有记录进行划分。接下来，对每个分支重复这个过程，即对每个分支选择另外一个未参与树的创建的属性，继续对样本进行划分，一直到某个分支上的样本都属于同一类(或者隶属该路径的样本大部分属于同一类)。比如在上述实例中，经过树中的一系列非叶子节点的划分后，样本被分成批准贷款 (Yes) 和未批准贷款 (No) 两类，这样的节点形成叶子节点。

   属性的选择也称为特征选择。特征选择的目的是使分类后的数据集比较纯，即数据(子)集里主要是某个类别的样本，因为决策树的目标就是把数据集按对应的类别标签进行分类。理想的情况是，通过特征的选择，能把不同类别的数据集贴上对应的类别标签。为了衡量一个数据集的纯度，就需要引入数据纯度函数。

   其中一个应用广泛的度量函数是信息增益 (Information Gain)。信息熵表示的是不确定性。非均匀分布时，不确定性最大，此时熵就最大。当选择某个特征，对数据集进行分类时，分类后的数据集的信息熵会比分类前的小，其差值表示为信息增益。信息增益可以衡量某个特征对分类结果的影响大小。

   对于一个数据集，特征 A 作用之前的信息熵计算公式为：

   \[
   H(D) = -\sum_{i=1}^{c} P_i \log_2(P_i)
   \]

   式中，D 为训练数据集；c 为类别数量；P_i 为类别 i 样本数量占所有样本的比例。

   对应数据集 D，选择特征 A 作为决策树判断节点时，在特征 A 作用后的信息熵为 InfoA(D)，计算如下：

   \[
   InfoA(D) = \sum_{j=1}^{k} \frac{|D_j|}{|D|} H(D_j)
   \]

   式中，k 为样本 D 被分为 k 个子集。

   信息增益表示数据集 D 在特征 A 的作用后，其信息熵减少的值(信息熵差值)，其计算公式如下：

   \[
   Gain(A) = Info(D) - InfoA(D)
   \]

   在决策树的构建过程中，需要选择特征值时，都选择 Gain(A) 值最大的特征。

2. **决策树的剪枝**

   在决策树建立的过程中，很容易出现过拟合 (Overfitting) 的现象。过拟合是指模型非常逼近训练样本，模型是在训练样本上训练出来的，在训练样本上预测的准确率很高，但是对测试样本的预测准确率不高，效果并不好，也就是模型的泛化能力 (Generalization) 差。当把模型应用到新数据上时，其预测效果不好，过拟合不利于模型的实际应用。

   决策树同样出现过拟合现象，可以通过剪枝进行一定的修复。剪枝分为预先剪枝和后剪枝两种情况。预先剪枝指的是在决策树构造过程中，使用一定条件加以限制，在产生完全拟合的决策树之前就停止生长。预先剪枝的判断方法也有很多，比如信息增益小于一定阈值时，通过剪枝使决策树停止生长。

   后剪枝是在决策树构造完成之后，也就是所有的训练样本都可以用决策树划分到不同子类以后，按照自底向上的方向，修剪决策树。后剪枝有两种方式：一种是用新的叶子节点替换子树，该节点的预测类由子树数据集中的多数类决定；另一种是用子树中最常使用的分支代替子树。后剪枝一般能够产生更好的效果，因为预先剪枝可能过早地终止决策树构造过程。需要注意的是，后剪枝在子树被剪掉后，决策树构造的一部分计算就浪费了。

   决策树算法有一些变种，包括ID3, C4.5, CART 等，一般都需要经过两个阶段来进行构造，即树的生长阶段 (Growing) 和剪枝阶段 (Pruning)。

   决策树的应用非常广泛，除了上述是否批准贷款申请的实例，还可以应用在对客户进行细分、对垃圾邮件进行识别等场合。

### ### 5.2.2 聚类算法K-Means

K-Means 算法是最简单的一种聚类算法，属于无监督学习算法。

假设我们的样本是 \(\{x^{(1)}, x^{(2)}, \ldots, x^{(m)}\}\)，每个 \(x^{(i)} \in \mathbb{R}^n\)，即它是一个 n 维向量。现在用户给定一个 K 值，要求将样本聚类 (Clustering) 成 K 个类簇 (Cluster)。在这里，我们把整个算法称为聚类算法，聚类算法的结果是一系列的类簇。

K-Means 是一个迭代型的算法，它的算法流程是：

1. 随机选取 K 个聚类质心 (Cluster Centroid)，记为 \(\mu_1, \mu_2, \ldots, \mu_K \in \mathbb{R}^n\)。
2. 重复下面过程，直到收敛：

   2.1. 对于每个样本 \(i\)，计算它应该属于的类：

   \[
   c^{(i)} := \arg \min_j ||x^{(i)} - \mu_j||^2
   \]

   2.2. 对于每一个类别 \(j\)，重新计算它的质心：

   \[
   \mu_j := \frac{\sum_{i=1}^{m} 1\{c^{(i)} = j\} x^{(i)}}{\sum_{i=1}^{m} 1\{c^{(i)} = j\}}
   \]

收敛是在上一次迭代到本次迭代中，每个样本隶属于同样的类别，每个类别的质心不再发生改变。

下面以一个实例展示 K-Mean 标准算法的执行过程。假设我们对样本进行 K=3 的聚类，图5-2中的正方形是样本点，圆形(不同灰度)分别是三个类的质心。

![K-Means 算法实例](https://via.placeholder.com/150 "K-Means 算法实例")

- 图5-2 (a) 表示，由于 K=3，所以算法开始在有效的数据域 (Domain) 里生成3个初始的 (Initial) 质心。
- 图5-2 (b) 表示，所有的样本根据和质心的远近，分配到最近的质心，形成三个类别。图中的三个区域是基于三个质心的对平面的一个 Voronoi Diagram 划分，该划分把平面上的点根据到三个质心的远近分配给各个划分。
- 图5-2 (c) 表示，经过迭代计算，K 个类簇的质心改变了。
- 图5-2 (d) 表示经过多次迭代(把样本分配到各个质心、重新计算各个类簇的质心)，各个类簇最终的质心，即聚类算法收敛的结果。

在 K-Means 算法中，涉及距离的计算，最常用的距离是欧式距离。欧式距离 (Euclidean Distance) 的公式为：

\[
d(x, y) = \sqrt{\sum_{i=1}^{n} (x_i - y_i)^2}
\]

此外，还有闵可夫斯基距离、曼哈顿距离(也称为城市街区距离，City Block Distance)可以使用，它们的计算公式分别为：

\[
d_{\text{Minkowski}}(x, y) = \left( \sum_{i=1}^{n} |x_i - y_i|^p \right)^{1/p}
\]

\[
d_{\text{Manhattan}}(x, y) = \sum_{i=1}^{n} |x_i - y_i|
\]

在 K-Means 算法中，K 值的选择是一个重要的问题。我们希望所选择的 K 正好是数据里隐含的真实的类簇的数目。我们可以选择一个合适的类簇指标，当我们假设的类簇的数目等于或大于真实的类簇的数目时，这个指标变化平缓，当我们假设的类簇的数目小于真实的类簇的数目时，这个指标急剧变化。

可以选择的类簇指标包括平均半径或者直径。类簇的直径是指类簇中任意两点的距离的最大值。类簇的半径是指类簇中所有点到类簇中心距离的最大值。我们可以给出一系列的 K 值，运行 K-Means 算法计算上述类簇指标，然后根据上述原则，选取一个合适的 K 值。

K-Means 是可伸缩和高效的，方便处理大数据集，计算的复杂度为 \(O(NKt)\)，其中 N 为数据对象的数目，t 为迭代的次数。一般来说，\(K \ll N\)，\(t \ll N\)。当各个类簇是密集的，且类簇与类簇之间区别明显时，K-Means 算法可以取得较好的效果。

K-Means 算法有三个缺点：

1. K-Means 算法中的 K 是事先给定的，一个合适的 K 值难以估计。
2. 在 K-Means 算法中，首先需要根据初始类簇中心来确定一个初始划分，然后对初始划分进行优化。初始类簇中心的选择对聚类结果有较大的影响。一旦初始值选择的不好，可能无法得到有效的聚类结果。可以使用遗传算法 (Genetic Algorithm)，帮助选择合适的初始类簇中心。
3. 算法需要不断地进行样本分类调整，不断地计算调整后的新的类簇中心，因此当数据量非常大时，算法的时间开销是非常大的。可以利用采样策略，改进算法效率。也就是初始点的选择，以及每一次迭代完成时对数据的调整，都是建立在随机采样的样本数据的基础之上，这样可以提高算法的收敛速度。

### 5.2.3 分类算法支持向量机 (SVM)

支持向量机由 Boser, Guyon, Vapnik 等在1992年的 ACM Conference on Computational Learning Theory (COLT) 会议上提出。从那以后，支持向量机以其在解决小样本、非线性以及高维模式识别中表现出来的特有优势得到广泛的应用。其应用领域包括文本分类、图像识别等。

1. **二维空间(即平面)数据点的分类**

下面通过一个二维平面上的简单分类来介绍支持向量机分类技术(见图5-3)。在平面上有两种不同的点，用不同的形状表示，一种为圆形，一种为正方形。现在我们在平面上绘制一根直线，把两类点分开。这样的直线可以画很多条，那么哪一条才是最好的分割线呢?

![二维平面上的数据分类](https://via.placeholder.com/150 "二维平面上的数据分类")

在二维平面上，把两类数据分开(假设可以分成两类)需要一条直线。到了3维空间，要把两类数据分开，就需要一个平面。把上述分类机制扩展到基本情形，在高维空间里，把两类数据分开，则需要一个超平面。直线和平面是超平面在2维和3维空间的表现形式。

2. **支持向量**

我们寻找分类函数 \(y = f(x) = w^T x + b\)，超平面上的点代入这个分类函数，得到 \(f(x) = 0\)；超平面一边的数据点代入分类函数，得到 \(f(x) = 1\)；超平面另外一边的数据点代入分类函数，得到 \(f(x) = -1\)。在二维平面上，这个分类函数对应一根直线 \(y = f(x) = ax + b\)。

在二维平面上确定一根直线，就是确定上述方程中的 \(a\) 和 \(b\)。在高维空间上确定一个超平面，则需要确定 \(w\) 向量和 \(b\) 向量。

如何确定 \(w\) 和 \(b\) 呢？答案是寻找一个超平面，它到两个类别数据点的距离都尽可能大，这样的超平面为最优的超平面。

在图5-4中，中间的那根直线到两类数据点的距离是相等的(图中双向箭头的长度表示距离 \(d\))。为了确定这根直线，不需要所有的数据点(向量)，只需要图中显示为深灰色的数据点(向量)，这些向量唯一确定了数据划分的直线(超平面)，称为支持向量 (Support Vector)。

![支持向量](https://via.placeholder.com/150 "支持向量")

通过上面实例的分析和解释，我们总结如下，支持向量机 (Support Vector Machine, SVM) 是一个对高维数据进行分类的分类器。数据点被划分到两个不相交的半空间 (Half Space)，从而实现分类，划分两个半空间的是一个超平面，SVM 分类的主要任务是寻找到和两类数据点都具有最大距离的超平面，目的是使得把两类数据点分开的划分范围 (Margin) 最大化。

SVM 问题模型 \(w^T \cdot x^+ + b = +1\) 和 \(w^T \cdot x^- + b = -1\)

可以看成由样本构成的向量 \((x^+ - x^-)\) 在分类超平面上的法向量上的投影。

假设训练数据为 \((x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n) \in \mathbb{R}^d, y \in \{+1, -1\}\) 线性分类函数 \(w \cdot x + b = 0, w \in \mathbb{R}, b \in \mathbb{R}\)

最大-margin问题转化成优化问题

最小化目标函数：

\[
\frac{1}{2} ||w||^2
\]

约束条件：

\[
y_i ((w \cdot x_i) + b) \geq 1, \quad i = 1, \ldots, n
\]

对间隔最大的超平面进行计算是一个二次规划问题。可以通过应用拉格朗日对偶性 (Lagrange Duality) 求解对偶问题得到最优解。具体的问题转化和求解过程请参考相关资料。对偶问题的具体形式如下：

要解决的问题是在参数 \(\{\alpha, \alpha_2, \ldots, \alpha_n\}\) 上求最大值 \(W\) 的问题，而 \(x_i, y_i\) 都是已知数。在优化模型中的控制参数 \(C\) 的作用是控制目标函数中的两个目标之间的权重。这两个目标是寻找间隔最大的超平面和保证数据点分类误差最小。

有时候两个数据点集，在低维空间中，我们无法找到一个超平面来清晰地划分，比如图5-5 (a) 中的二维平面上的两类数据点，找不到一根直线把它们划分开。SVM 数据分析方法里有一个核函数 (Kernel Function) 技巧，可以巧妙地解决这个问题。通过核函数，可以把低维空间的数据点(向量)映射到高维空间中。经过映射以后，两类数据点在高维空间里，可以有一个超平面把它们分开。

![SVM的核函数技巧](https://via.placeholder.com/150 "SVM的核函数技巧")

在图5-5 (b) 中，两类数据点经过映射以后，映射到3维空间的数据点。在3维空间里，我们可以看到，两类数据点可以用一个平面分开。需要注意的是，图5-5仅仅通过举例说明低维线性不可划分的两类向量，可以通过核函数映射到高维空间，从而达到线性可划分的目的。图5-5的目的是说明核函数的作用，是把低维空间线性不可分的向量，映射到高维空间，使其线性可分。

常用的核函数包括多项式核函数、高斯径向基核函数、指数径向基核函数、多隐层感知核函数、傅立叶级数核函数、样条核函数、B 样条核函数等。

3. **异常值的处理**

在上述 SVM 模型中，超平面本身是由少数几个支持向量 (Support Vector) 确定的，未考虑 Outlier (离群值，异常值)的影响。我们通过下面的实例，展示异常值的影响。

在图5-6里，不同形状表示不同类别的数据点，深灰色的数据点则表示异常值。这个异常值将导致分类错误。我们的目标是计算一个分割超平面，把分类错误降到最小。

这个问题通过在模型中引入松弛变量 (Relax Variable) 来解决。松弛变量是为了纠正或约束少量“不安分”或脱离集体不好归类的数据点的因子。引入松弛变量后，支持向量机的超平面的求解问题仍然可以转化成一个二次规划问题求解。在引入松弛变量的情况下，最优分类平面求解问题表示成约束优化问题。

最小化目标函数：

\[
\frac{1}{2} ||w||^2 + C \sum_{i=1}^{n} \xi_i
\]

约束条件：

\[
y_i ((w \cdot x_i) + b) \geq 1 - \xi_i, \quad \xi_i \geq 0, \quad i = 1, 2, \ldots, n
\]

![SVM 分类器中异常值的处理](https://via.placeholder.com/150 "SVM 分类器中异常值的处理")

正则化参数 \(C\)，可以理解为允许划分错误的权重，\(C\) 越大，表示越不允许出错，当 \(C\) 较小时，允许少量样本划分错误。至此，我们看到，支持向量机不仅能够处理线性分类，还能够处理数据中的非线性(使用核函数)、容忍异常值(使用松弛变量)，是一个强大的分类器。

4. **支持向量回归**

支持向量机的训练数据为 \(\{(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n)\}, x_i \in \mathbb{R}^n, y_i \in \{-1, +1\}\)。如果训练数据中的 \(y_i\) 为一个实数，即 \(y_i \in \mathbb{R}\)，则引出了支持向量回归 (Support Vector Regression, SVR) 问题。

给定训练数据集 \(S\)，以及任意给定 \(\epsilon > 0\)。如果在原始空间 \(\mathbb{R}^n\) 空间存在一个超平面 \(f(x) = \langle w, x \rangle + b, w \in \mathbb{R}^n, b \in \mathbb{R}\)，使 \(|y_i - f(x_i)| \leq \epsilon, \forall (x_i, y_i) \in S\)，则称 \(f(x) = \langle w, x \rangle + b\) 是样本集合 \(S\) 的 \(\epsilon\)-线性回归。问题转化为 \(S\) 中任何点 \((x_i, y_i)\) 到超平面 \(f(x) = \langle w, x \rangle + b\) 的距离不超过 \(\epsilon\)，也就是最大化 \(\frac{2}{\|w\|}\)，等价于 \(\min \frac{1}{2} \|w\|^2\)。

\(\epsilon\)-线性回归问题转化为优化问题：

\[
\min \frac{1}{2} \|w\|^2
\]

\[
\text{s.t.} \quad |(w^T \cdot x_i) + b - y_i| \leq \epsilon, \quad i = 1, 2, \ldots, n
\]

和解决 SVM 分类问题一样，可以引入松弛变量。利用 Lagrange 对偶性，得到优化问题的对偶性形式，再进行求解。

对于不可能在原始空间 \(\mathbb{R}^n\) 可以线性回归的训练数据集 \(S\)，首先用一个非线性函数 \(\phi(S)\) 将数据集 \(S\) 映射到一个高维空间，在高维空间 \(\phi(S)\) 具有很好的线性回归特性，然后在高维空间进行 \(\epsilon\)-线性回归。

于是，支持向量回归分析的过程如下：

已知训练集 \(\{(x_1, y_1), (x_2, y_2), \ldots, (x_n, y_n))\)，其中 \(x_i \in \mathbb{R}^n, y \in \mathbb{R}, i = 1, 2, \ldots, n\)，选择适当的正数 \(\epsilon\) 和 \(C\)。

1. 寻找一个核函数 \(K(s, t)\)，使得 \(K(x_i, x_j) = \langle \phi(x_i), \phi(x_j) \rangle\)。
2. 求优化问题的解 \(\alpha_i, \alpha_i^*\)。

得到最优解 \(\alpha_1, \alpha_1^*, \alpha_2, \alpha_2^*, \ldots, \alpha_n, \alpha_n^*\)。

3. 计算参数 \(b\)，选择开区间 \((0, C)\) 中的 \(\alpha_i\) 或者 \(\alpha_k^*\)，如果选择到的是 \(\alpha_i\)，那么

\[
b = y_i - \sum_{j=1}^{n} (\alpha_j - \alpha_j^*) K(x_j, x_i) - \epsilon
\]

如果选择到的是 \(\alpha_k^*\)，那么

\[
b = y_k - \sum_{j=1}^{n} (\alpha_j - \alpha_j^*) K(x_j, x_k) + \epsilon
\]

4. 最后构造非线性函数。

SVR 的特点可以把非线性函数 \(f(x)\) 看作 2 维空间的一条曲线(多维空间的一个曲面)，训练数据点分布在这个曲线周围，形成一个“管道”。在所有训练数据点中，只有分布在“管道”壁上的那些训练数据点，才决定管道的位置。于是这些训练数据点就称为支持向量。

具体到 2 维平面空间，SVM 的目的是通过一条直线，尽量把两类数据点分开。SVR 的目的则是通过一个管道，尽量把数据点都囊括进来。

为了适应训练数据集的非线性 (Non-Linearity)，传统的拟合方法通常在线性方程里加上高阶项来解决。这种方法一般是有效的，但是也增加了过拟合的风险。

支持向量回归算法采用核函数解决非线性问题。引进核函数的目的是“升维”，在低维空间中的非线性转换成高维空间的线性问题，把非线性回归转换成线性回归，然后求解。或者反过来说，用核函数代替线性方程中的线性项，使得线性回归算法非线性化，即能做非线性回归。SVR 的“升维”虽然增加了可调参数，但是很好地控制了过拟合问题。

### 5.2.4 关联规则分析 Apriori 算法

关联规则分析 (Association Rule Analysis) 最典型的例子是购物篮分析。通过关联规则分析，能够发现顾客每次购物的购物篮中不同商品之间的关联，从而了解客户的消费习惯，让商家能够了解哪些商品被客户同时购买，帮助他们制定更好的营销方案。本章开头提到的“尿布与啤酒”的典故，就是关联规则分析方法的挖掘结果。

关联规则是形如 \(X \rightarrow Y\) 的蕴含式，表示通过 \(X\) 可以推导出 \(Y\)，\(X\) 称为关联规则的左部 (Left Hand Side, LHS)，\(Y\) 称为关联规则的右部 (Right Hand Side, RHS)。在购物篮分析结果里，尿布 \(\rightarrow\) 啤酒表示客户在购买尿布的同时，有很大的可能性购买啤酒。

关联规则有两个指标，分别是支持度 (Support) 和置信度 (Confidence)。关联规则 \(A \rightarrow B\) 的支持度 (support) = \(P(AB)\)，指的是事件 \(A\) 和事件 \(B\) 同时发生的概率。置信度 (confidence) = \(P(B|A) = P(AB)/P(A)\)，指的是发生事件 \(A\) 的基础上，发生事件 \(B\) 的概率。比如，如果尿布 \(\rightarrow\) 啤酒关联规则的支持度为 30%，置信度为 60%，那么就表示所有的商品交易中，30% 交易同时购买了尿布和啤酒，在购买尿布的交易中，60% 的交易同时购买了啤酒。

关联规则分析需要从基础数据中挖掘出支持度和置信度都超过一定阈值的关联规则，以便在决策中应用。同时满足最小支持度阈值和最小置信度阈值的规则，称为强规则。

挖掘关联规则的主流算法为 Apriori 算法。它的基本原理是在数据集中找出同时出现概率符合预定义 (Pre-defined) 支持度的频繁项集，而后从以上频繁项集中，找出符合预定义置信度的关联规则。频繁项集和关联规则可以通过以下实例来解释。

假设有一家商店经营 4 种商品(实际生活中，商品数目比这大得多，但是不影响算法原理的阐述)，分别是商品 0、商品 1、商品 2 和商品 3。那么所有商品的组合有：只包含一种商品的、包含两种商品的、包含三种商品的以及包含四种商品的组合。这些组合，包括空集，构成如图5-7所示的子集或者超集关系。图5-7中的圆圈表示某个商品组合，连接线则表示子集/超集关系。

![集合〈商品0,商品1,商品2,商品3}中所有可能的项集组合](https://via.placeholder.com/150 "集合〈商品0,商品1,商品2,商品3}中所有可能的项集组合")

对于单个项集的支持度，我们可以通过遍历每条记录并检查该记录是否包含该项集来计算。对于包含 \(N\) 种物品的数据集共有 \(2^N - 1\) 种项集组合，重复上述计算过程是不现实的。科研人员发现 Apriori 原理可以减少计算量。

Apriori 原理是，如果某个项集是频繁的，那么它的所有子集也是频繁的。它的逆否命题是，如果一个项集是非频繁的，那么它的所有超集也是非频繁的。比如在图5-8中，已知阴影项集 \(\{\text{商品2}, \text{商品3}\}\) 是非频繁的。利用这个基础知识，我们可以知道项集 \(\{\text{商品0}, \text{商品2}, \text{商品3}\}\), \(\{\text{商品1}, \text{商品2}, \text{商品3}\}\) 以及 \(\{\text{商品0}, \text{商品1}, \text{商品2}, \text{商品3}\}\) 也是非频繁的，因为它们都是 \(\{\text{商品2}, \text{商品3}\}\) 的超集。

![Apriori 原理(非频繁项集用深灰色表示)](https://via.placeholder.com/150 "Apriori 原理(非频繁项集用深灰色表示)")

除了 Apriori 算法，挖掘关联规则的算法还有 FP-growth。FP-growth 算法基于 Apriori 算法构建，它采用优化的数据结构，减少扫描次数。FP-growth 算法只需对数据库进行两次扫描，大大加快了算法执行速度。Apriori 算法对于每个潜在的频繁项集，都会扫描数据集判定给定模式是否频繁。

文献①给出了一个实例，我们通过该实例来了解 Apriori 算法的执行过程。假设有如下的数据集，表示用户观看电影的活动。

| 交易号 | 电影1         | 电影2         | 电影3         | 电影4      | 电影5 |
| ------ | ------------- | ------------- | ------------- | ---------- | ----- |
| 1      | Sixth Sense   | LOTR1         | Harry Potter1 | Green Mile | LOTR2 |
| 2      | Gladiator     | Patriot       | Braveheart    |            |       |
| 3      | LOTR1         | LOTR2         |               |            |       |
| 4      | Gladiator     | Patriot       | Sixth Sense   |            |       |
| 5      | Gladiator     | Patriot       | Sixth Sense   |            |       |
| 6      | Gladiator     | Patriot       | Sixth Sense   |            |       |
| 7      | Harry Potter1 | Harry Potter2 |               |            |       |
| 8      | Gladiator     | Patriot       |               |            |       |
| 9      | Gladiator     | Patriot       | Sixth Sense   |            |       |
| 10     | Sixth Sense   | LOTR          | Gladiator     | Green Mile |       |

我们的目标是从这些数据中挖掘出用户观看电影的关联规则，购票观看某部(几部) 电影的用户中，有多少比例会去购票观看其他哪些电影。支持度阈值设定为 50%，置信度阈值设定为 80%。

根据上述数据，我们得到 1 项集，列表如下：

| 电影名称      | 同时出现在哪些交易中 | 出现次数 | 支持度     |
| ------------- | -------------------- | -------- | ---------- |
| Sixth Sense   | 1, 4, 5, 6, 9, 10    | 6        | 6/10 = 0.6 |
| LOTR1         | 1, 3                 | 2        | 2/10 = 0.2 |
| Harry Potter1 | 1, 7                 | 2        | 2/10 = 0.2 |
| Green Mile    | 1, 10                | 2        | 2/10 = 0.2 |
| LOTR2         | 1, 3                 | 2        | 2/10 = 0.2 |
| Gladiator     | 2, 4, 5, 6, 8, 9, 10 | 7        | 7/10 = 0.7 |
| Patriot       | 2, 4, 5, 6, 8, 9     | 6        | 6/10 = 0.6 |
| Braveheart    | 2                    | 1        | 1/10 = 0.1 |
| Harry Potter2 | 7                    | 1        | 1/10 = 0.1 |
| LOTR          | 10                   | 1        | 1/10 = 0.1 |

从这张表中可以看出，符合支持度 \(\geq 50\%\) 的只有如下三项，即有 3 个 1 项集是频繁的。

| 电影名称    | 同时出现在哪些交易中 | 出现次数 | 支持度     |
| ----------- | -------------------- | -------- | ---------- |
| Sixth Sense | 1, 4, 5, 6, 9, 10    | 6        | 6/10 = 0.6 |
| Gladiator   | 2, 4, 5, 6, 8, 9, 10 | 7        | 7/10 = 0.7 |
| Patriot     | 2, 4, 5, 6, 8, 9     | 6        | 6/10 = 0.6 |

在此基础上，通过自连接构造超集，构造出来的 2 项集为：

| 电影名称               | 同时出现在哪些交易中 | 出现次数 | 支持度     |
| ---------------------- | -------------------- | -------- | ---------- |
| Sixth Sense, Gladiator | 4, 5, 6, 9, 10       | 5        | 6/10 = 0.6 |
|Sixth Sense, Patriot | 4, 5, 6, 9 | 4 | 4/10 = 0.4 |
| Gladiator, Patriot | 2, 4, 5, 6, 8, 9 | 6 | 6/10 = 0.6 |

可以看出，符合支持度 \(\geq 50\%\) 的只有如下两项，即有 2 个 2 项集是频繁的。

| 电影名称               | 同时出现在哪些交易中 | 出现次数 | 支持度     |
| ---------------------- | -------------------- | -------- | ---------- |
| Sixth Sense, Gladiator | 4, 5, 6, 9, 10       | 5        | 5/10 = 0.5 |
| Gladiator, Patriot     | 2, 4, 5, 6, 8, 9     | 6        | 6/10 = 0.6 |

在此基础上，通过自连接构造超集，构造出来的 3 项集如下，支持度为 40%，是不频繁的。

| 电影名称                        | 同时出现在哪些交易中 | 出现次数 | 支持度     |
| ------------------------------- | -------------------- | -------- | ---------- |
| Sixth Sense, Gladiator, Patriot | 4, 5, 6, 9           | 4        | 4/10 = 0.4 |

Apriori 算法利用了上文讲述的 Apriori 原理。上述实例中，因为 2 项集 \(\{\text{Sixth Sense}, \text{Patriot}\}\) 是不频繁的(基于一定的支持度)，包含 \(\{\text{Sixth Sense}, \text{Patriot}\}\) 的 3 项集，必定是不频繁的，无须继续判断。

到这里，我们提取了如下关联规则。

| 规则                                  | 支持度 | 置信度          |
| ------------------------------------- | ------ | --------------- |
| Sixth Sense \(\Rightarrow\) Gladiator | 0.5    | 5/6 = 0.8333333 |
| Gladiator \(\Rightarrow\) Sixth Sense | 0.5    | 5/7 = 0.7142857 |
| Gladiator \(\Rightarrow\) Patriot     | 0.6    | 6/7 = 0.8571429 |
| Patriot \(\Rightarrow\) Gladiator     | 0.6    | 1.0             |

由于置信度的阈值为 80%，所以第二个关联规则不符合要求。最终提取的关联规则如下：

| 规则                                  | 支持度 | 置信度          |
| ------------------------------------- | ------ | --------------- |
| Sixth Sense \(\Rightarrow\) Gladiator | 0.5    | 5/6 = 0.8333333 |
| Gladiator \(\Rightarrow\) Patriot     | 0.6    | 6/7 = 0.8571429 |
| Patriot \(\Rightarrow\) Gladiator     | 0.6    | 1.0             |

对于关联规则，我们可以很容易地解释和理解。比如，对于上述实例，可以给出如下解释：

1. 购票观看 Sixth Sense (《第六感》) 的用户中，有 83% 会购票观看 Gladiator (《角斗士》)，同时购票观看这两部电影的用户占 50%。
2. 购票观看 Gladiator 的用户中，有 85.7% 会购票观看 Patriot (《爱国者》)，同时购票观看这两部电影的用户占 60%。
3. 购票观看 Patriot 的用户中，100% 会购票观看 Gladiator，同时购票观看这两部电影的用户占 60%。

### 5.2.5 EM 算法

EM (Expectation Maximization, 最大期望) 算法是为概率分布模型 (Probability Distribution Model) 寻找参数的最大似然估计的算法。这个概率模型包含无法观测的隐藏变量 (Latent Variable)。EM 算法用于机器学习的聚类 (Clustering)。下面我们通过实例①来了解最大似然估计以及 EM 算法。

1. **最大似然估计 (Maximum Likelihood Estimation)**

假设我们用硬币 A 和硬币 B 进行投掷硬币实验。这两个硬币在进行投掷实验时，正面朝上的概率分别为 \(\theta_A\) 和 \(\theta_B\)。我们进行了 5 轮投掷实验，每轮实验要么选择硬币 A，要么选择硬币 B，一共连续投掷 10 次，每次投掷结果要么正面朝上(用 H 表示)，要么背面朝上(用 T 表示)。于是我们得到 5 个正面/背面标志列表。

在实验过程中，我们记录了两个向量列表 \(x = (x_1, x_2, \ldots, x_5)\) 以及 \(z = (z_1, z_2, \ldots, z_5)\)。其中 \(x_i \in \{0, 1, \ldots, 10\}\)，记录第 \(i\) 轮投掷实验中正面朝上的次数。\(z_i \in \{A, B\}\)，则是第 \(i\) 轮投掷实验使用的硬币。假设实验的结果如表5-2所示。

| i    | x           | z    |
| ---- | ----------- | ---- |
| 1    | HTTTH HTHTH | B    |
| 2    | HHHHT HHHHH | A    |
| 3    | HTHHH HHTHH | A    |
| 4    | HTHTT THHTT | B    |
| 5    | THHHT HHHTH | A    |

目前，我们不知道 \(\theta_A\) 和 \(\theta_B\) 的具体取值，我们只有上述实验结果。在这里我们对 \(\theta_A\) 和 \(\theta_B\) 做出估计，我们依赖于完整的数据(拥有所有相关的随机变量的取值)，包括每轮投掷用硬币 A 还是硬币 B，每轮投掷的 10 次投掷的正面/背面情况。

那么对 \(\theta_A\) 和 \(\theta_B\) 做出估计的简单方法是，根据实验数据，计算硬币 A 和硬币 B 的正面朝上的比例。使用如下公式进行计算：

针对上述实例，我们的计算结果如表5-3所示。

| 硬币A  | 硬币B  | 参数估计                                  |
| ------ | ------ | ----------------------------------------- |
| 5H, 5T | 9H, 1T |                                           |
|        |        | \(\theta_A = \frac{24}{30} = 0.8\)        |
|        |        | \(\theta_B = \frac{9}{11} \approx 0.818\) |

上述方法即最大似然估计法。最大似然估计是参数估计的方法之一。已知某个随机样本满足某种概率分布，但是其中具体的参数不清楚，参数估计就是通过若干次试验，观察其结果，利用结果推出参数的大概值。最大似然估计的核心思想是，如果某个参数能使这个样本出现的概率最大，我们干脆就把这个参数作为估计的真实值。假设 \(\log P(x, z; \theta)\) 是 \(x\) 和 \(z\) 的联合分布的对数 (Logarithm)，对其最大化问题进行求解，那么上述对 \(\theta_A\) 和 \(\theta_B\) 进行估计的公式就是其解。

2. **EM 算法实例**

现在我们考虑参数估计的另外一种情形。我们仅仅获得了向量列表 \(x = (x_1, x_2, \ldots, x_5)\)，但是没有对应的 \(z = (z_1, z_2, \ldots, z_5)\)。也就是我们知道每轮投掷的 10 次投掷的正面/背面情况，但不知道每轮是用硬币 A 还是硬币 B。

我们把 \(z\) 称为隐藏变量 (Hidden Variable) 或者潜在因子 (Latent Factor)。在这种情况下，参数估计是在数据不全 (Incomplete Data) 的情况下进行的。

为了对 \(\theta_A\) 和 \(\theta_B\) 做出估计，需要知道每轮正面/背面序列是使用硬币 A 还是硬币 B。要知道每轮正面/背面序列是使用硬币 A 还是硬币 B，则需要对 \(\theta_A\) 和 \(\theta_B\) 有一个合理的估计，两者互为前提。事情好像陷入死锁了，必须打破这个循环依赖，才能开始参数的估计，这就需要用到 EM 算法。

EM 算法在两个步骤，即在 Expectation 步和 Maximization 步之间进行交替，经过若干次迭代后，对模型的参数给出合理的估计。

对于这个实例，具体的过程如下：

1. 首先，给出 \(\theta_A\) 和 \(\theta_B\) 两个参数的初始估计，比如 \(\theta_A = 0.6\)，\(\theta_B = 0.5\)。
2. 在 Expectation 步，使用当前参数，计算每轮投掷的硬币是 A 的概率/是 B 的概率，然后计算每轮投掷的正面朝上/背面朝上的次数。

需要使用贝叶斯定理

\[
P(A|x) = \frac{P(x|A)P(A)}{P(x|A)P(A) + P(x|B)P(B)}
\]

比如根据第一轮的投掷结果，我们不知道是硬币 A 还是硬币 B，给这两个硬币的概率设定为 0.5，即 \(P(A) = P(B) = 0.5\)。然后根据第一轮投掷结果 5 个正面朝上，5 个背面朝上，那么 \(P(x|A) = 0.6^5 \times 0.4^5\)，\(P(x|B) = 0.5^5 \times 0.5^5\) (注意 \(\theta_A = 0.6\)，\(\theta_B = 0.5\))，\(P(A) = 0.5\)，\(P(B) = 0.5\)，代入上述等式，得到 \(P(A|x) = 0.45\)，\(P(B|x) = 0.55\) (即图5-9中第二步的第一行数据)。

3. 在 Maximization 步，利用 Expectation 获得每轮投掷的硬币是 A 的概率/是 B 的概率，然后计算每轮投掷的正面朝上/背面朝上的次数，对 \(\theta_A\) 和 \(\theta_B\) 两个参数进行估计。也就是，针对每轮投掷，我们在观测到的 \(x\) 上，看正面朝上/背面朝上的概率是多少。

第一轮投掷硬币是 A 的概率为 0.45，硬币是 B 的概率为 0.55，按照第一轮投掷 5 个正面 5 个背面的比例，分配到硬币 A 和硬币 B 的正面/背面次数分别是 2.2H/2.2T，2.8H/2.8T。第 2, 3, 4, 5 轮的计算类似，请参考图5-9的第三部分的表格。

那么，我们可以汇总出硬币 A 正面朝上 21.3 次，背面朝上 8.6 次，\(\theta_A = \frac{21.3}{21.3 + 8.6} \approx 0.71\)，硬币 B 正面朝上 11.7 次，背面朝上 8.4 次，\(\theta_B = \frac{11.7}{11.7 + 8.4} \approx 0.52\)。

4. 经过多次 Expectation 步和 Maximization 步的循环迭代之后，\(\theta_A\) 和 \(\theta_B\) 两个参数收敛。整个过程如图5-9所示。经过 10 轮 Expectation 步和 Maximization 步迭代之后，\(\theta_A\) 和 \(\theta_B\) 分别为 0.80 和 0.52，和最大似然估计得出的结果已经比较接近了。

![EM算法实例](https://via.placeholder.com/150 "EM算法实例")

下面我们再举一个例子，这个例子根据观测数据，估计混合高斯模型的参数。

假设现在有数据 \(Y\)，用两个高斯分布 \(\phi_1(x)\)，\(\phi_2(x)\) 对密度建模，参数为 \(\theta = (\mu, \sigma^2)\)，那么 \(Y\) 的概率密度为 \(g(y) = (1 - \pi) \phi_1(y) + \pi \phi_2(y)\)，其参数为 \(\theta = (\pi, \mu_1, \sigma_1^2, \mu_2, \sigma_2^2)\)，\(\pi\) 为混合比例。

基于 \(N\) 个训练数据的对数似然函数是：

\[
L(\theta) = \sum_{i=1}^{N} \log \left( (1 - \pi) \phi_1(y_i) + \pi \phi_2(y_i) \right)
\]

直接最大化上述似然函数很难，对其进行变形。引入取值为 0 或者 1 的潜在变量 \(\Delta\)。如果 \(\Delta_i = 0\)，\(Y_i\) 取自模型 1，如果 \(\Delta_i = 1\)，则 \(Y_i\) 取自模型 2。对数似然函数写为：

\[
L(\theta) = \sum_{i=1}^{N} \left[ (1 - \Delta_i) \log \left( (1 - \pi) \phi_1(y_i) \right) + \Delta_i \log \left( \pi \phi_2(y_i) \right) \right]
\]

于是 \((\mu_1, \sigma_1^2)\) 的极大似然估计是 \(\Delta_i = 0\) 的那些数据的样本均值和方差，\((\mu_2, \sigma_2^2)\) 的极大似然估计是 \(\Delta_i = 1\) 的那些数据的样本均值和方差。

由于 \(\Delta_i\) 的实际值是未知的(也就是隐藏变量)，所以用迭代方式进行处理，用下面的期望代替上述 \(\Delta_i\)，也就是 \(\gamma_i(\theta) = E(\Delta_i | \theta, Z) = \Pr(\Delta_i = 1 | \theta, Z)\)。

二分量高斯参数估计的 EM 算法如下：

1. 初始化参数 \(\mu_1, \mu_2, \sigma_1^2, \sigma_2^2, \pi\)，其中 \(\mu_1, \mu_2\) 可以随机选择两个 \(y_i\)，\(\sigma_1^2, \sigma_2^2\) 可以取样本的方差，混合比例 \(\pi\) 取 0.5。
2. Expectation 步，上述参数代入，计算 \(\gamma_i(\theta) = \frac{\pi \phi_2(y_i)}{(1 - \pi) \phi_1(y_i) + \pi \phi_2(y_i)}\)，\(i = 1, \ldots, N\)。

表示数据 \(y_i\) 属于 \(\phi_2\) 的概率。注意上述计算中，分子为 \(\pi \phi_2(y_i)\)，那是因为 \(\gamma_i(\theta)\) 越接近 0，表示 \(y_i\) 越可能属于模型 1，\(\gamma_i(\theta)\) 越接近 1，则 \(y_i\) 越可能属于模型 2。

3. Maximization 步，计算加权均值和方差，以及混合比例。

\[
\mu_1 = \frac{\sum_{i=1}^{N} (1 - \gamma_i(\theta)) y_i}{\sum_{i=1}^{N} (1 - \gamma_i(\theta))}, \quad \mu_2 = \frac{\sum_{i=1}^{N} \gamma_i(\theta) y_i}{\sum_{i=1}^{N} \gamma_i(\theta)}
\]

\[
\sigma_1^2 = \frac{\sum_{i=1}^{N} (1 - \gamma_i(\theta)) (y_i - \mu_1)^2}{\sum_{i=1}^{N} (1 - \gamma_i(\theta))}, \quad \sigma_2^2 = \frac{\sum_{i=1}^{N} \gamma_i(\theta) (y_i - \mu_2)^2}{\sum_{i=1}^{N} \gamma_i(\theta)}
\]

\[
\pi = \frac{1}{N} \sum_{i=1}^{N} \gamma_i(\theta)
\]

4. 重复步骤 (2) 和 (3) 直到收敛。

Christopher D. Manning, Prabhakar Raghavan 和 Hinrich Schütze 合著的 An Introduction to Information Retrieval，在 16.5 节利用 EM 算法，对文档集 (Document Set) 进行基于模型的软聚类 (Soft Clustering)。比如，如果有一篇关于中国汽车的文档，聚类算法把该文档进行软分配 (Soft Assignment)，以 0.5 的概率，隶属于 (Membership) “中国”和“汽车”两个类簇。

Mitchell 著的 Machine Learning 一书给出了另外一个 EM 的实例。该实例将混搅在一起的男生和女生身高信息聚成两类。男生身高符合高斯分布，女生身高也符合高斯分布，但是参数不同。现在男女生的身高混合在一起，问题就变成了，如何估计每个样例是男生还是女生，然后在确定男女生的情况下，如何估计均值和方差。该书给出了具体的公式，有兴趣的读者可以进一步参考。

3. **通用 EM 算法**

给定训练样本集 \(\{x^{(1)}, x^{(2)}, \ldots, x^{(n)}\}\)，样本之间独立。这是从参数为 \(\theta\) 的分布的总体样本中，抽取到的若干样本。如果抽取各个样本是相互独立的，那么抽取到这些样本的概率是样本集 \(x\) 中各个样本的联合概率，表达为：

\[
P(x; \theta) = \prod_{i=1}^{n} P(x^{(i)}; \theta)
\]

在极大似然估计法中，我们需要找到参数 \(\theta\)，使得似然函数 \(L(\theta)\) 最大，称为 \(\theta\) 的最大似然估计 \(\theta = \arg \max L(\theta)\)。由于上述式子中各个概率值是连乘的，不便于分析，可以定义对数似然函数，变成：

\[
\ell(\theta) = \log L(\theta) = \sum_{i=1}^{n} \log P(x^{(i)}; \theta)
\]

最大似然函数可以通过求导和解方程进行求解。

如果模型中包含隐藏变量(类似于上文提到的投掷硬币的例子，不知道每一轮投掷的是硬币 A 还是硬币 B)，每个样本 \(i\) 对应的类别 \(z^{(i)}\) 是未知的，也即隐藏变量。

我们对每个样本的每个可能类别 \(z^{(i)}\) 求联合分布概率。我们知道样本符合某种分布，但是不知道分布参数 \(\theta\)。因为存在隐藏变量 \(z\)，所以直接求 \(\theta\) 比较困难，但是一旦确定了 \(z\)，求解 \(\theta\) 就容易了。那么，我们需要找到每个样本隐含的类别 \(z^{(i)}\)，使得 \(P(x, z)\) 最大，则 \(P(x, z)\) 的最大似然函数为：

\[
\ell(\theta) = \sum_{i=1}^{n} \log \left( \sum_{z^{(i)}} P(x^{(i)}, z^{(i)}; \theta) \right)
\]

对于每个样本 \(x^{(i)}\)，让 \(Q\) 表示该样本隐藏变量 \(z\) 的某种分布，\(Q\) 满足的条件是 \(\sum_{z} Q(z) = 1\)，\(Q(z) \geq 0\)。如果 \(z\) 是连续的，\(Q\) 是概率密度函数。比如，如果要将班上的学生聚类，假设隐藏变量 \(z\) 是身高，那么就是连续的高斯分布。如果隐藏变量是男/女，那么就是伯努利二项分布。

使用 Jensen 不等式，对上述似然函数进行变形：

1. \(\ell(\theta) = \sum_{i=1}^{n} \log \left( \sum_{z^{(i)}} Q_i(z^{(i)}) \frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} \right) \geq \sum_{i=1}^{n} \sum_{z^{(i)}} Q_i(z^{(i)}) \log \left( \frac{P(x^{(i)}, z^{(i)}; \theta)}{Q_i(z^{(i)})} \right)\)

2. 从式 (1) 到式 (2)，只需在分子分母同乘以一个相等的函数，从式 (2) 到式 (3)，利用了 Jensen 不等式。

基于上述推导过程，EM 算法设计如下。

EM 算法是一种从不完全数据或有数据丢失的数据集(存在隐藏变量)中，求解概率模型参数的最大似然估计的方法。通用 EM 算法的基本流程是：

1. 初始化分布的参数 \(\theta\)。
2. 重复 E 步骤和 M 步骤，直到收敛。

   - E 步骤，估计隐藏变量。即根据参数初始值或者上一次迭代的模型参数，来计算出隐藏变量的后验概率，也就是隐藏变量的期望值，作为隐藏变量的当前估计值。\(Q_i(z^{(i)}) = P(z^{(i)} | x^{(i)}; \theta)\)

   - M 步骤，估计其他参数。即根据计算得到的 \(Q\)，最大化含有 \(\theta\) 的似然函数，获得新的参数值 \(\theta\)。

3. 通过不断迭代，就可以得到使似然函数 \(L(\theta)\) 最大化的参数 \(\theta\)。本质上讲，EM 的 E 步骤、固定 \(\theta\)，优化 \(Q\)；M 步骤固定 \(Q\)，优化 \(\theta\)。这两个步骤交替，将极值推向最大。

4. **EM 算法的应用**

EM 算法是对数据进行聚类 (Clustering) 的常用方法。EM 算法的应用非常广泛，包括计算机视觉、自然语言处理、心理学、生物信息学等领域，都可以找到它的用武之地。

### 5.2.6 协同过滤推荐算法 (Collaborative Filtering Recommendation)

在互联网时代，特别是随着 Web 2.0 的发展，Web 已经变成数据分享的平台，每天都有大量的图片、博客、视频发布到网上。信息的极度爆炸，使得人们找到所需的信息越来越难。

面对海量的数据，用户需要更加智能的、更加了解他们需求、口味和偏好的信息检索机制，于是推荐系统应运而生。推荐算法能够根据用户的偏好，向用户推荐商品或者服务。在电子商务 (E-Commerce，比如 Amazon 等) 网站、音乐、电影和图书分享网站，推荐引擎取得了巨大的成功。

推荐引擎需要根据一定的数据进行分析，然后给出推荐结果。主要的数据源包括：

1. 要推荐的物品或者内容的描述信息；
2. 用户的基本信息，比如性别、年龄等；
3. 用户对物品或者内容的偏好。用户偏好可以分为两类，分别是显式的用户反馈和隐式的用户反馈。显式的用户反馈是用户在网站浏览之外，显式地提供的反馈信息，比如用户对物品的评分、评论等。隐式的用户反馈则是用户在使用网站时产生的数据，比如用户查看了某个物品的信息，用户购买了某个物品等。推荐引擎使用上述数据源，对用户对物品的偏好进行预测计算，然后推荐这些物品。

我们可以从不同的角度对推荐系统进行分类：

1. 根据是否为不同用户推荐不同的物品或者内容，推荐系统分为个性化推荐系统和大众化推荐系统。
2. 根据使用的数据源，推荐系统分为基于内容的推荐系统 (Content-Based Recommendation，它根据推荐物品或内容的描述，发现物品或者内容的相似性，进行推荐)、基于人口统计学的推荐系统 (Demographic-Based Recommendation，它根据用户的信息，发现用户之间的相似性，进行推荐)、基于协同过滤的推荐系统 (Collaborative Filtering-Based Recommendation，它根据用户对物品或者内容的偏好，发现物品或者内容之间的相似性，或者发现用户之间的相似性，进行推荐)。
3. 根据推荐模型的基本技术原理，推荐系统分为基于用户对物品的评价矩阵的推荐系统、基于关联规则的推荐系统 (Rule-Based Recommendation，它通过关联规则的挖掘，找到哪些物品经常被同时购买，或者用户购买了一些物品后通常会购买哪些其他的物品，进行推荐)、基于模型的推荐 (Model-Based Recommendation，将已有的用户偏好信息作为训练样本，训练出一个模型，用于预测用户的其他偏好。以后用户再进入系统时，可以基于这个模型进行推荐)。基于模型的推荐需要考虑如何利用用户近期或者实时的偏好信息，更新训练好的模型，以提高推荐的准确度。

1. **基于内容的推荐**

基于内容的推荐的基本思路是，根据物品或者内容的描述信息，发现它们之间的相似性，然后基于用户以往的偏好历史记录，推荐相似的物品或者内容。

比如在电影推荐系统里，我们首先需要对电影的描述信息(元数据)进行建模，这个模型可以包含电影的类型、电影的导演、电影的演员、电影的剧情介绍等。对于具体用户，根据他历史上喜欢看的电影，可以给他推荐类似的电影。需要根据上述描述信息，计算电影之间的相似度。

基于内容的推荐存在若干问题：

1. 推荐的质量依赖于物品模型的完整和全面程度；
2. 物品相似度的分析没有考虑人对物品的态度；
3. 需要基于用户以往的偏好历史做出推荐，于是存在“冷启动”(Cold Start) 问题。“冷启动”问题是模型刚开始运行时缺乏必要的历史数据。

虽然这个方法有这些不足，但是仍然在电影、音乐、图书推荐应用中取得成功。

2. **基于人口统计学的推荐**

基于人口统计学的推荐机制是一种最易于实现的推荐。它根据用户的基本信息发现用户的相似性，然后将相似用户喜爱的其他物品推荐给当前用户。具体来讲，系统对每个用户都有一个用户画像 (Profile)，这个画像包括用户的一些基本信息，包括年龄、性别、教育背景、收入、婚姻状况等。然后，系统根据用户的画像，计算用户的相似度。相似用户称为“近邻”，对于某个用户，利用其“近邻”用户群的偏好，就可以给他一些物品的推荐。

该方法的优势包括：

1. 对于系统的新用户来讲，系统没有“冷启动”问题，因为它不使用用户对物品的偏好历史数据；

2. 该方法不依赖于物品数据，因此它是领域独立的 (Domain

3. Independent)，也就是可以应用到不同领域。但是该方法过于粗糙，对品位要求较高的领域不适用，比如图书、电影和音乐等领域，推荐效果不是很好。

   3. **基于协同过滤的推荐**

   基于协同过滤的推荐，根据用户对物品或者内容的偏好，发现物品或者内容之间的相似性，或者发现用户之间的相似性，然后基于这些相似性进行推荐。基于协同过滤的推荐，又可以分为三个子类：

   - 基于用户的 (User-Based) 推荐；
   - 基于物品的 (Item-Based) 推荐；
   - 基于模型的 (Model-Based) 推荐。

   文献①②对基于协同过滤的推荐，进行了详细介绍，这里简述如下。

   (1) **基于用户的协同过滤推荐**

   基于用户的协同过滤推荐，是根据用户对物品或者内容的偏好，发现与某个用户偏好相似的 \(k\) 个“近邻”用户(可以使用 \(k\)NN 算法进行计算)，然后基于这 \(k\) 个“近邻”用户的历史偏好信息，为该用户进行推荐。以电商领域为例，比如我们现在要给用户 \(C\) 进行商品推荐。我们首先进行用户间相似度的计算，发现用户 \(C\) 和用户 \(D/E\) 的相似度较高，也就是说用户 \(D\) 和 \(E\) 是用户 \(C\) 的 “\(k\) 最近邻”。于是，我们可以给用户 \(C\) 推荐用户 \(D\) 和 \(E\) 浏览过或者购买过的商品。需要注意的是，我们只需推荐用户 \(C\) 还没有浏览过或者购买过的商品即可，对于用户 \(C\) 浏览过或者购买过的商品，无须重复推荐。

   如果有多个商品可以推荐，到底优先推荐哪个商品呢？需要对商品进行适当的排序。可以采用加权排序方法，举例如下。比如，用户 \(C\) 的近邻用户为 \(D\) 和 \(E\)，他们和用户 \(C\) 的相似度以及他们评价过的商品的评分如表5-4所示。我们把用户 \(D, E\) 对其他商品(包括商品 101, 102, 103)的评分，乘以用户 \(D, E\) 和用户 \(C\) 之间的相似度，得到带权评分。然后，计算带权评分的总计 \(T_{scor}\)，除以相似度总计 \(T_{sm}\)，以 \(T_{sw}/T_{sm}\) 作为排序标准，对这些商品进行排序，然后推荐给用户 \(C\)。比如，根据计算，商品 103 排名靠前，应该优先推荐。

   | \(k\)-近邻用户                 | 和 \(C\) 相似度 | 商品 101 评分 | 带权评分 | 商品 102 评分 | 带权评分 | 商品 103 评分 | 带权评分 |
   | ------------------------------ | --------------- | ------------- | -------- | ------------- | -------- | ------------- | -------- |
   | 用户 \(D\)                     | 0.98            | 3.4           | 3.332    | 4.4           | 4.312    | 5.8           | 5.684    |
   | 用户 \(E\)                     | 0.95            | 3.2           | 3.04     | /             | 0        | 4.1           | 3.895    |
   | 带权评分总计 \(T_{scor}\)      |                 |               | 6.372    |               | 4.312    |               | 9.579    |
   | 相似度总计 \(T_{sm}\)          | 1.93            |               |          |               |          |               |          |
   | \(T_{sw}/T_{sm}\) 作为排序标准 |                 |               | 3.30     |               | 2.23     |               | 4.96     |

   资料来源：http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudyl/index.html.

   用户 \(C\) 获得的推荐，是从与他偏好相似的用户 \(D, E\) 评价的商品里获得的。与用户 \(C\) 相似度高的用户评分高的商品，将被优先推荐。

   基于用户的协同过滤，需要找出用户的 \(k\) 最近邻，可以根据用户评分矩阵计算和推断。用户评分矩阵记录的是不同用户对不同的物品 (Item) 的评分。它的每一行对应一个用户，它的每一列对应一个物品，\(<i, j>\) 单元记录的是用户 \(i\) 对物品 \(j\) 的评分 \(R_{ij}\)。

   用户评分矩阵的具体形式如表5-5所示。

   |            | 物品 1     | 物品 2     | …    | 物品 \(n\) |
   | ---------- | ---------- | ---------- | ---- | ---------- |
   | 用户 1     | \(R_{11}\) | \(R_{12}\) | …    | \(R_{1n}\) |
   | 用户 2     | \(R_{21}\) | \(R_{22}\) | …    | \(R_{2n}\) |
   | :          | :          | :          | :    | :          |
   | 用户 \(m\) | \(R_{m1}\) | \(R_{m2}\) | …    | \(R_{mn}\) |

   这里的评分表示用户对物品的偏好程度，评分越高表示用户越偏好该物品。以电商领域为例，用户对商品的浏览、向朋友推荐、收藏、评论、购买等行为，都表现了用户对商品的偏好程度。可以对这些行为进行量化，形成量化指标，然后对这些行为的量化指标进行加权，计算最终评分。

   针对评分矩阵，基于用户的协同过滤推荐，是在每个用户对应的行向量上计算用户的相关性。度量向量之间相似度的方法有很多，包括欧式距离、向量夹角、Pearson 相关系数等。Pearson 相关系数的计算公式比欧式距离的计算公式要复杂一些，但是在评分数据不规范的情况下，Pearson 相关系数能够给出更好的结果。

   我们通过如下的实例了解用户之间的相似度，这里用的是欧式距离。假设用户对各个商品的评分如表5-6所示。

   | 用户 | 商品 1 | 商品 2 |
   | ---- | ------ | ------ |
   | A    | 3.32   | 6.51   |
   | B    | 5.78   | 2.62   |
   | C    | 3.59   | 6.29   |
   | D    | 3.42   | 5.78   |
   | E    | 5.19   | 3.11   |

   我们绘制一个散点图，以商品 1 得分作为横坐标，以商品 2 得分作为纵坐标。用户 A, B, C, D, E 在坐标系上的分布如图5-10所示。由此可以看出，用户 A, C, D 距离较近，用户 B, E 距离较近。

   ![用户对商品的评分的散点图](https://via.placeholder.com/150 "用户对商品的评分的散点图")

   从基本原理可以看到，该方法和基于人口统计学的推荐机制很类似。但是，基于人口统计学的推荐机制只考虑用户的特征，基于用户的协同过滤机制，是在用户的历史偏好数据上计算用户的相似度，它假设喜欢类似物品的用户可能具有相同或者相似的口味，这是合理的。

   (2) **基于项目的协同过滤推荐**

   基于项目的协同过滤推荐，是使用所有用户对物品或者内容的偏好信息，发现物品和物品之间的相似度，然后根据用户的历史偏好信息，将类似的物品推荐给用户。以电商领域为例，当需要对用户 \(C\) 基于商品 3 进行商品推荐时，首先寻找商品 3 的 \(k\) 近邻商品，也就是和商品 3 相似的商品，比如商品 3 的 \(k\) 近邻为商品 4 和商品 5。然后计算商品 4, 5 与其他商品的相似度，并且进行排序，然后向用户 \(C\) 推荐新的商品，也就是用户 \(C\) 没有浏览过或者购买过的商品。

   比如，表5-7列出了用户 \(C\) 购买过的商品 4, 5 与其他商品(包括商品 101, 102, 103)的相似度。我们将用户 \(C\) 对商品 4, 5 的评分作为权重，乘以其他商品和商品 4, 5 的相似度，得到带权相似度。然后，计算相似度总计 \(T_{sm}\)，除以评分总计 \(T_{scor}\)，以 \(T_{sm}/T_{scor}\) 作为排序标准，对商品 101, 102, 103 进行排序，然后推荐给用户 \(C\)。比如，根据计算，商品 103 排名靠前，应该优先推荐。

   | \(k\)-近邻商品                     | 评分 | 与商品 101 相似度 | 带权相似度 | 与商品 102 相似度 | 带权相似度 | 与商品 103 相似度 | 带权相似度 |
   | ---------------------------------- | ---- | ----------------- | ---------- | ----------------- | ---------- | ----------------- | ---------- |
   | 商品 4                             | 4.2  | 0.2               | 0.84       | 0.65              | 2.73       | 0.95              | 3.99       |
   | 商品 5                             | 4.5  | 0.3               | 1.35       | 0.40              | 1.8        | 0.78              | 3.51       |
   | 相似度总计 \(T_{sm}\)              |      |                   | 2.19       |                   | 4.53       |                   | 7.5        |
   | 评分总计 \(T_{scor}\)              | 8.7  |                   |            |                   |            |                   |            |
   | \(T_{sm}/T_{scor}\) 作为排序的标准 |      |                   | 0.25       |                   | 0.52       |                   | 0.86       |

   资料来源：http://www.ibm.com/developerworks/cn/web/1103_zhaoct_recommstudy2/index.html.

   用户 \(C\) 获得的推荐是从与他购买过的商品相似度较高的商品中选出的。与用户 \(C\) 评分高的商品相似度高的商品被优先推荐。

   针对评分矩阵，基于项目的协同过滤推荐，是在每个物品对应的列向量上，计算物品的相关性。

   从基本原理可以看到，该方法和基于内容的推荐，都是基于物品相似度进行推荐，但是它们的相似度计算方法不一样。基于内容的推荐，仅仅基于物品本身的属性信息进行相似度计算，基于项目的协同过滤推荐，则是从用户的历史偏好进行相似度计算。

   如何在基于用户的协同过滤推荐与基于项目的协同过滤推荐之间做出选择，需要根据应用场景的特点。比如，在电商领域，一般来讲，物品的个数是远远小于用户的数量的，而且物品的个数和相似度相对比较稳定，基于项目的机制比基于用户的机制更加适合，它的实时性也更好。物品的相似度可以离线先算好，定期更新即可。在新闻推荐系统中，新闻的个数(物品数)可能大于用户的数量，新闻更新也非常快，存在话题迁移，新闻的相似度不稳定，这时候使用基于用户的协同过滤推荐算法，效果会更好。

   基于协同过滤的推荐机制是应用最为广泛的推荐机制。该方法的优势包括：

   1. 它无须对用户、物品进行严格的建模，它是领域无关的；
   2. 该方法支持用户发现潜在的兴趣偏好。

   同时我们也需要了解到，该方法存在若干问题：

   1. 该方法基于历史数据做出推荐，对新用户和新物品存在“冷启动”问题；
   2. 推荐效果依赖于用户历史偏好数据的数据量及其准确性；
   3. 少部分人的错误偏好，可能会对推荐的准确度产生很大的影响；
   4. 不能照顾特殊偏好和品位的用户，不能给予精细的推荐。

   ### 5.2.7 \(k\)NN (\(k\) 近邻) 算法

   \(k\)NN (\(k\) Near Neighbors) 算法是一种分类算法，它根据某个数据点周围的最近 \(k\) 个邻居的类别标签情况，赋予这个数据点一个类别。具体的过程是，给定一个测试数据点，计算它与数据集中其他数据点的距离；找出距离最近的 \(k\) 个数据点，作为该数据点的近邻数据点集合；根据这 \(k\) 个近邻所归属的类别，来确定当前数据点的类别。

   比如，在图5-11中，采用欧式距离，\(k\) 的值确定为 7，正方形表示类别一，三角形表示类别二。现在要确定灰色方块的类别，图中的圆圈表示其 \(k\) 最近邻所在的区域。在圆圈里面，其他数据点的分类情况是，类别一有 5 个，类别二有 2 个。采用投票法分类，根据多数原则，灰色数据点的分类确定为类别一。

   ![\(k\)NN 算法实例](https://via.placeholder.com/150 "\(k\)NN 算法实例")

   \(k\)NN 算法中，可用的距离包括欧式距离、夹角余弦等。一般对于文本分类来说，用夹角余弦计算距离(相似度)，比欧式距离更为合适。距离越小(距离越近)，表示两个数据点属于同一类别的可能性越大。下面为距离公式 (\(x\) 为需要分类的数据点(向量)，\(p\) 为近邻数据点)。

   \[
   d(x, p) = \sqrt{\sum_{i=1}^{n} (x_i - p_i)^2}
   \]

   当 \(k\) 个最近邻居确定之后，当前数据点的类别确定，可以采用投票法或者加权投票法。投票法即根据少数服从多数的原则，近邻中哪个类别的数据点越多，当前数据点就属于该类。加权投票法则根据距离的远近，对近邻的投票进行加权，距离越近权重越大，权重为距离平方的倒数，最后确定当前数据点的类别。权重的计算公式为（\(k\) 个近邻的权重之和正好是 1）：

   \[
   w_i = \frac{1}{d(x, p_i)^2} \Bigg/ \sum_{j=1}^{k} \frac{1}{d(x, p_j)^2}
   \]

   \(k\)NN 算法容易理解，也容易实现，无须进行参数估计，也无须训练过程，有了标注数据之后，直接进行分类即可。\(k\)NN 算法可以对稀有的事件进行分类，比如客户流失预测、欺诈侦测等。该算法也适用于多类别分类，也就是对象具有多个类别标签，比如某个基因序列有多个功能，一段文本有多个分类标签等。虽然具有这么多的优点，\(k\)NN 算法也有缺点，主要的缺点是该算法在进行数据点分类时计算量大，内存开销大，执行速度慢。另外，该算法无法给出类似决策树的规则，结果的可解释性差。

   \(k\)NN 算法中，\(k\) 值的选择非常重要。如果 \(k\) 值太小，那么分类结果容易受到噪声数据点影响；\(k\) 值太大，则近邻中可能包含太多其他类别的数据点。上述加权投票法可以降低 \(k\) 值设定不适当的一些影响。根据经验法则，一般来讲 \(k\) 值可以设定为训练样本数的平方根。

   \(k\)NN 分类算法的应用非常广泛，人们把它应用到协同过滤推荐 (Collaborative Filtering)、手写体识别 (Digit Recognition) 等领域。

   ### 5.2.8 朴素贝叶斯 (Naive Bayes) 算法

   贝叶斯分类是一类分类算法的总称，它们都以贝叶斯定理为基础。下面我们首先介绍贝叶斯定理，然后结合实例讨论朴素贝叶斯分类，它是贝叶斯分类中最简单的一种方法。

   1. **贝叶斯定理**

   \(P(B|A)\) 表示在事件 \(A\) 已经发生的前提下，事件 \(B\) 发生的概率，称为事件 \(A\) 发生情况下，事件 \(B\) 发生的条件概率。

   在实际应用中经常遇到这样的情况，我们可以很容易计算 \(P(A|B)\)，但是 \(P(B|A)\) 则很难直接得出。我们要计算的目标是 \(P(B|A)\)，贝叶斯定理为我们从 \(P(A|B)\) 计算 \(P(B|A)\) 提供了一种途径。贝叶斯定理的具体形式为：

   \[
   P(B|A) = \frac{P(A|B)P(B)}{P(A)}
   \]

   该公式的证明过程，可以参考概率论的相关教材。

   2. **朴素贝叶斯分类**

   朴素贝叶斯分类是运用上述贝叶斯定理，并且假设特征属性 (Feature Attribute) 是条件独立的一种分类方法，即朴素贝叶斯分类器假设样本的每个特征与其他特征都不相关。

   假设我们有如下的分类问题(在下面的描述中涉及 \(N\) 个样本，下标用 \(s\)，\(K\) 个类，下标用 \(i\)，\(M\) 个特征属性，下标用 \(j\)，某个属性 \(a_j\) 有 \(L_j\) 个划分，下标为 \(l\))：

   1. 假设 \(x = \{a_1, a_2, \ldots, a_m\}\) 为一个待分类项(即一个向量)，\(a_1, a_2, \ldots, a_m\) 为 \(x\) 的特征属性。
   2. 类别集合 \(C = \{y_1, y_2, \ldots, y_k\}\)，总共有 \(K\) 个分类。
   3. 我们要判断 \(x\) 属于哪个分类，于是计算 \(P(y_1 | x), P(y_2 | x), \ldots, P(y_k | x)\)。
   4. 如果 \(P(y_i | x) = \max\{P(y_1 | x), P(y_2 | x), \ldots, P(y_k | x)\}\)，那么 \(x \in y_i\)。也就是 \(P(y_i | x)\)，\(i = 1, \ldots, K\)，哪个最大，\(x\) 就最可能属于哪个类别。

   问题就转换成计算 \(P(y_i | x)\)，也就是 \(x\) 属于各个类别的概率。

   其具体计算过程如下：

   1. 创建一个已经知道其分类的待分类项集合，这个集合称为训练样本集，样本集包含 \(N\) 个样本。\(P(y_i) = \frac{\text{count}(y_i)}{N}\)，式中，\(\text{count}(y_i)\) 为类别 \(y_i\) 的样本数量。
   2. 根据训练样本集，统计得到各个类别下各个特征属性的条件概率估计。也就是计算 \(P(a_1 | y_1), P(a_2 | y_1), \ldots, P(a_m | y_1)\)；\(P(a_1 | y_2), P(a_2 | y_2), \ldots, P(a_m | y_2)\)；\(\ldots\)；\(P(a_1 | y_k), P(a_2 | y_k), \ldots, P(a_m | y_k)\) 等，\(a_1, a_2, \ldots, a_m\) 是 \(M\) 维特征向量的各个维度。

   当计算 \(P(a_1 | y_1)\) 元素时，就是计算在分类为 \(y_1\) 的样本上，\(a_1\) 的值域的各个划分的概率，比如 \(y_1\) 类样本有 100 个，\(a_1\) 的值域划分成 3 个子划分，各个子划分的样本分别包含 10, 70, 20 个样本，那么 \(P(a_1 \in \text{划分1} | y_1) = 0.1\)，\(P(a_1 \in \text{划分2} | y_1) = 0.7\)，\(P(a_1 \in \text{划分3} | y_1) = 0.2\)。总结起来，

   \[
   P(a_j \in \text{划分}l | y_i) = \frac{\text{count}(a_j \in \text{划分}l \land y_i)}{\text{count}(y_i)}
   \]

   式中，\(l \in \{1, \ldots, L_j\}\) 为 \(a_j\) 的值域的划分的个数。其他 \(P(a_j | y_i)\) 的根据同样道理，进行计算。

   3. 假设各个特征属性是条件独立的，根据贝叶斯定理，有如下的推导：

   \[
   P(y_i | x) = \frac{P(x | y_i) P(y_i)}{P(x)} = \frac{P(a_1 | y_i) P(a_2 | y_i) \cdots P(a_m | y_i) P(y_i)}{P(x)}
   \]

   式中，分母对于所有类别为常数，我们只需将分子最大化即可。由于各个特征属性是条件独立的，所以

   \[
   P(y_i | x) \propto P(a_1 | y_i) P(a_2 | y_i) \cdots P(a_m | y_i) P(y_i)
   \]

   整个朴素贝叶斯分类分为三个阶段，分别是准备阶段、训练阶段和应用阶段。

   1. 准备阶段的任务是为朴素贝叶斯分类做必要的准备。主要工作是根据具体情况，确定特征属性，并对每个特征属性进行适当划分，然后对一部分待分类项进行人工分类，形成训练样本集合。第一个阶段的数据质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分以及训练样本质量决定。
   2. 训练阶段的主要任务是生成分类器。主要工作是计算每个类别在训练样本中的出现频率(上式中的 \(P(y_i)\))，以及每个特征属性划分对每个类别的条件概率估计(上式中的 \(P(a_j | y_i)\))，并且记录结果。
   3. 应用阶段的主要任务是使用分类器，对待分类项进行分类，也就是对新数据进行分类。

   3. **朴素贝叶斯分类实例**

   文献①给出了一个实例。通过朴素贝叶斯分类来检测 SNS(Social Networking Service) 社区中的不真实账号。在 SNS 社区中，不真实账号是一个普遍存在的问题。SNS 社区的运营商希望检测出这些不真实账号，从而加强对 SNS 社区的监管和治理。使用人工检测方法，需要耗费大量的人力，效率低下。如果能够设计和使用某种自动检测方法，将大大提高工作效率。

   这个工作的目的是根据账号的一些属性，把它们划分成真实账号和不真实账号两类。那么目标分类集合 \(C = \{0, 1\}\)，0 表示真实账号，1 表示不真实账号。使用朴素贝叶斯分类方法，对账号进行分类的具体过程如下：

   1. 确定特征属性以及属性值域的划分。在实际应用中，特征属性的数量是很多的，划分也会比较细致。在这里主要目的是对朴素贝叶斯分类方法进行说明，仅仅使用少量的特征属性以及较粗的划分。

   在本实例中使用三个属性，\(a_1\) 是日志数量/注册天数，\(a_2\) 是好友数量/注册天数，\(a_3\) 表示是否使用真实头像。每个账号的这三个属性，都可以从系统中查询出来，或者计算出来。这三个属性的值域的划分如下，\(a_1\)：\(\{ [-\infty, 0.05], (0.05, 0.2], [0.2, +\infty) \}\)，\(a_2\)：\(\{ [-\infty, 0.1], (0.1, 0.8], [0.8, +\infty) \}\)，\(a_3\)：\(\{0, 1\}\)，0 表示未使用真实头像，1 表示使用真实头像。

   2. 获取训练样本，可以使用运维人员曾经检测的 1 万个账号作为训练样本。
   3. 利用训练样本中真实账号和不真实账号，计算各个类别的概率。比如，真实账号 \(P(c = 0) = 8900 / 10000 = 0.89\)，不真实账号 \(P(c = 1) = 1100 / 10000 = 0.11\)。
   4. 计算每个类别下，各个特征属性划分的概率。比如：

   \[
   P(a_1 \in [-\infty, 0.05) | c = 0) = 0.3, \quad P(a_1 \in (0.05, 0.2] | c = 0) = 0.5, \quad P(a_1 \in [0.2, +\infty) | c = 0) = 0.2
   \]

   \[
   P(a_1 \in [-\infty, 0.05) | c = 1) = 0.8, \quad P(a_1 \in (0.05, 0.2] | c = 1) = 0.1, \quad P(a_1 \in [0.2, +\infty) | c = 1) = 0.1
   \]

   \[
   P(a_2 \in [-\infty, 0.1] | c = 0) = 0.1, \quad P(a_2 \in (0.1, 0.8] | c = 0) = 0.7, \quad P(a_2 \in [0.8, +\infty) | c = 0) = 0.2
   \]

   \[
   P(a_2 \in [-\infty, 0.1] | c = 1) = 0.7, \quad P(a_2 \in (0.1, 0.8] | c = 1) = 0.2, \quad P(a_2 \in [0.8, +\infty) | c = 1) = 0.1
   \]

   \[
   P(a_3 = 0 | c = 0) = 0.2, \quad P(a_3 = 1 | c = 0) = 0.8
   \]

   \[
   P(a_3 = 0 | c = 1) = 0.9, \quad P(a_3 = 1 | c = 1) = 0.1
   \]

   5. 使用分类器进行分类。假设现在有一个账号 \(x\)，该账号的属性 \(a_1 = 0.11\)，\(a_2 = 0.22\)，\(a_3 = 0\)，那么

   \[
   P(C = 0) P(x | C = 

   0) = P(C = 0) P(a_1 \in (0.05, 0.2] | C = 0) P(a_2 \in (0.1, 0.8] | C = 0) P(a_3 = 0 | C = 0) = 0.89 \times 0.5 \times 0.7 \times 0.2 = 0.0623
   \]

   \[
   P(C = 1) P(x | C = 1) = P(C = 1) P(a_1 \in (0.05, 0.2] | C = 1) P(a_2 \in (0.1, 0.8] | C = 1) P(a_3 = 0 | C = 1) = 0.11 \times 0.1 \times 0.2 \times 0.9 = 0.00198
   \]

   由于前者大于后者，所以该账号属于 \(C = 0\) 类的概率更大，即该账号为真实账号类别。

   4. **属性值为连续值的处理方法**

   当某个特征属性为连续的值时，通常假设其服从正态分布，即

   \[
   P(a_j | y_i) = g(a_j, \mu_{ij}, \sigma_{ij}^2) = \frac{1}{\sqrt{2\pi}\sigma_{ij}} \exp\left(-\frac{(a_j - \mu_{ij})^2}{2\sigma_{ij}^2}\right)
   \]

   即 \(P(a_j | y_i) = g(a_j, \mu_{ij}, \sigma_{ij}^2)\)。

   只要计算出训练样本中各个类别中这个特征属性的值域划分的均值和标准差，代入上述公式，就可以得到需要的估计值。

   这里举另外一个实例，该实例来自维基百科，是一个处理连续变量的例子。

   下面是一组人类身体特征的统计资料(见表5-8)。

   | \(x\)                      | \(y\)                    |
   | -------------------------- | ------------------------ |
   | 身高(英尺) \(x \cdot a_1\) | 体重(磅) \(x \cdot a_2\) |
   | 6                          | 180                      |
   | 5.92                       | 190                      |
   | 5.58                       | 170                      |
   | 5.92                       | 165                      |
   | 5                          | 100                      |
   | 5.5                        | 150                      |
   | 5.42                       | 130                      |
   | 5.75                       | 150                      |

   现在知道某人身高 6 英尺、体重 130 磅、脚掌 8 英寸，请问该人是男是女？

   根据朴素贝叶斯分类器的原理，我们需要计算，\(P(\text{身高} | \text{性别}) \times P(\text{体重} | \text{性别}) \times P(\text{脚掌} | \text{性别}) \times P(\text{性别})\)。现在的困难在于由于身高、体重、脚掌都是连续变量，不能采用离散变量的方法计算概率，而且由于样本太少，也无法分成区间计算。这时可以假设男性和女性的身高、体重、脚掌都是正态分布，通过样本计算出均值和方差，也就是得到正态分布的密度函数，具体如表5-9所示。此外，我们认为 \(P(\text{男}) = P(\text{女}) = 0.5\)。

   | 性别 | 均值(身高) | 方差(身高) | 均值(体重) | 方差(体重) | 均值(脚掌) | 方差(脚掌) |
   | ---- | ---------- | ---------- | ---------- | ---------- | ---------- | ---------- |
   | 男   | 5.855      | 3.5033e-02 | 176.25     | 1.2292e+02 | 11.25      | 9.1667e-01 |
   | 女   | 5.4175     | 9.7225e-02 | 132.5      | 5.5833e+02 | 7.5        | 1.6667e+00 |

   有了密度函数，就可以把值代入，算出某一点的密度函数的值。比如，男性的身高是均值 5.855、方差 0.035 的正态分布。男性的身高为 6 英尺的概率的相对值等于 1.5789。

   最后，我们计算得到：

   \[
   P(\text{身高} = 6 | \text{男}) \times P(\text{体重} = 130 | \text{男}) \times P(\text{脚掌} = 8 | \text{男}) \times P(\text{男}) = 6.1984 \times 10^{-9}
   \]

   \[
   P(\text{身高} = 6 | \text{女}) \times P(\text{体重} = 130 | \text{女}) \times P(\text{脚掌} = 8 | \text{女}) \times P(\text{女}) = 5.3778 \times 10^{-4}
   \]

   可以看到，女性的概率比男性要高出将近 10000 倍，因此判断该人为女性。

   5. **Laplace 校准**

   当出现 \(P(a_j | y_i) = 0\) 等情况，即某个类别下某个特征属性没有出现时，分类器的质量将大大降低。为了解决这个问题，一般引入 Laplace 校准。

   比如，\(P(a_j \in \text{划分}l | y_i) = \frac{\text{count}(a_j \in \text{划分}l \land y_i) + 1}{\text{count}(y_i) + L_j}\)，其中 \(L_j\) 为 \(a_j\) 的值域的划分数量，如果 \(a_j\) 的值域划分成 3 个子域，那么 \(L_j\) 就是 3。其他 \(P(a_j | y_i)\) 同理计算。当训练样本集合足够大时，不会对结果产生影响，同时解决了 \(P(a_j | y_i) = 0\) 的问题。此外，各个类别的概率的计算也需要调整，比如，\(P(y_i)\) 的计算公式调整为 \(P(y_i) = \frac{\text{count}(y_i) + 1}{N + K}\)，\(K\) 为类别数量，其他各类别概率同理计算。

   ### 5.2.9 AdaBoost 算法

   Boosting 算法系列的思想来自 PAC 可学习性 (Probably Approximately Correct Learnability) 理论。该理论研究什么时候一个问题是可被学习的，以及可学习问题的具体学习方法。Valiant 和 Kearns 首次提出了 PAC 学习模型中弱学习算法和强学习算法的等价性问题，即任意给定仅比随机猜测稍微好一点的弱学习算法，是否可以将其提升为强学习算法？如果二者等价，那么只需找到一个比随机猜测略好的弱学习算法，就可以将其提升为强学习算法而不必寻找很难获得的强学习算法。

   AdaBoost 是英文 “Adaptive Boosting” (适应性提升) 的缩写，由 Yoav Freund 和 Robert E. Schapire 在 1995 年提出，回答了上述问题。他们利用 AdaBoost 算法，把多个不同的决策树用一种非随机的方式组合起来，表现出惊人的性能。首先，决策树的准确率大大地提高了，可以与 SVM 媲美。其次，运行速度快且基本不用调参数。最后，该组合分类器几乎不产生过拟合 (Over Fitting) 现象。

   Boosting 算法是一种把多个分类器整合为一个分类器的方法。在 Boosting 算法产生之前还出现过两种比较重要的类似方法，Bootstrapping 方法和 Bagging 方法，读者可以参考相关资料。

   1. **算法思想**

   AdaBoost 是一种迭代算法，其核心思想是针对同一个训练集训练不同的分类器，即弱分类器，然后把这些弱分类器集合起来，构造一个更强的最终分类器。算法本身是通过改变数据分布实现的，它根据每次训练集之中的每个样本的分类是否正确，以及上次的总体分类的准确率，来确定每个样本的权值。将修改了权值的新数据送给下层分类器进行训练，然后将每次训练得到的分类器融合起来，作为最后的决策分类器。

   AdaBoost 的适应性在于前一个基本分类器分错的样本会得到加强，加权后的全体样本再次用来训练下一个基本分类器。同时，在每一轮中加入一个新的弱分类器，直至达到某个预定的足够小的错误率或达到预先指定的最大迭代次数。

   具体来讲，整个 AdaBoost 迭代算法包含 3 个主要步骤：

   1. 初始化训练数据的权值分布。如果有 \(M\) 个样本，则每一个训练样本最开始时都被赋予相同的权值：\(1/M\)。
   2. 训练弱分类器。在训练过程中，如果某个样本点已经被准确地分类，那么在构造下一个训练集中它的权值就被降低；相反，如果某个样本点没有被准确地分类，那么它的权值就得到提高。在第 \(t\) 轮训练结束后，根据得到的弱分类器 \(h_t\) 的性能，计算该分类器对应的权值 \(\alpha_t\)，并由 \(h_t\) 在训练集上的分类结果对权重向量 \(W_t \rightarrow W_{t+1}\) 进行更新。接着，权值更新过的样本集用于训练下一个分类器，整个训练过程如此迭代地进行下去。
   3. 将各个训练得到的弱分类器组合成强分类器。各个弱分类器的训练过程结束后，加大分类误差率小的弱分类器的权重，使其在最终的分类函数中起较大的决定作用，降低分类误差率大的弱分类器的权重，使其在最终的分类函数中起较小的决定作用。换言之，误差率低的弱分类器在最终分类器中占的权重较大，否则较小。

   具体的算法流程如下：

   给定：\((x_1, y_1), \ldots, (x_m, y_m)\)，\(x_i \in X\)，\(y_i \in Y = \{-1, +1\}\)

   1. 为训练集中每个样本，初始化权重 \(W_1(i) = 1/m\)。
   2. 从 \(t = 1, \ldots, T\) 迭代

      2.1 使用样本分布 \(W_t\) 对弱分类器 \(h_t\) 进行训练

      2.2 计算弱分类器 \(h_t: X \rightarrow \{-1, +1\}\) 的带权分类误差 \(E_t = \sum_{i=1}^{m} W_t(i) I[h_t(x_i) \neq y_i]\)

      2.3 计算弱分类器对应的权重

      \[
      \alpha_t = \frac{1}{2} \ln \left( \frac{1 - E_t}{E_t} \right)
      \]

      2.4 更新样本权重

      \[
      W_{t+1}(i) = \frac{W_t(i)}{Z_t} \exp(-\alpha_t y_i h_t(x_i))
      \]

      其中，\(Z_t\) 是一个规范化因子(从而使得 \(W_{t+1}\) 是一个分布)

   3. 得到 \(T\) 个不同的弱分类器及其对应的权重，输出最终的分类器

   \[
   H(x) = \text{sign} \left( \sum_{t=1}^{T} \alpha_t h_t(x) \right)
   \]

   利用这个分类器，对样本数据进行分类。

   2. **2 步，分类器 \(h_t\) 的性能度量**，即该分类器在训练集上的结果，通过计算该分类器在训练集上的带权分类误差来计算。带权分类误差是指将待分类的样本包含的权重(初始化的样本权重或者前一次迭代以后调整的权重)，结合该数据集上的分类误差，得到分类器在该数据集上的一个考虑样本权重的分类误差。计算公式为：

   \[
   E_t = \sum_{i=1}^{m} W_t(i) I[h_t(x_i) \neq y_i]
   \]

   式中，\(E_t\) 为第 \(t\) 个弱分类器的带权分类误差值；\(W_t(i)\) 为第 \(t\) 次更新后样本 \(i\) 的权重；\(h_t(x_i)\) 为使用第 \(t\) 个弱分类器对样本 \(i\) 的分类结果；\(y_i\) 为样本 \(i\) 的真实标签；\(I[h_t(x_i) \neq y_i]\) 是一个指示函数，它的值是

   3. **3 步，弱分类器

   4. \( h_t \) 对应的权重 \(\alpha_t\) 与其带权分类误差有关，计算公式为：

      \[
      \alpha_t = \frac{1}{2} \ln \left( \frac{1 - E_t}{E_t} \right)
      \]

      通过绘制分类器的权重函数的图像，我们可以看到，带权分类误差的范围是 \([0, 1]\)。弱分类器的权重与其对应的带权分类误差呈反比关系，也就是带权分类误差越小，该分类器对应的权值越大，或相反。

      4. **4 步，更新样本权值**。该式定义了计算弱分类器 \( h_t \) 对应的权值 \(\alpha_t\) 后，对样本 \( i \) 的权重更新过程。如果该分类器在该样本上分类正确，则降低该样本的权值；如果分类错误，则提高该样本的权值。公式前半部分主要用于对整个权重向量进行规范化处理，以使其和为 1。

      从上述过程可以看出，每轮训练结束后，AdaBoost 算法对样本的权重进行调整，该调整的结果是越到后面被错误分类的样本权重会越高。于是，到后面单个弱分类器为了达到较低的带权分类误差，都会把样本权重高的样本分类正确。最终的结果是，虽然每个弱分类器可能都有分错的样本，然而整个 AdaBoost 框架却能保证对每个样本进行正确分类。

      2. **AdaBoost 算法的特点**

      AdaBoost 是一种具有很高精度的分类器，其算法具有如下特点：

      1. 可以使用各种方法构建子分类器，AdaBoost 算法提供对其进行组合以及提升的框架。
      2. 当使用简单分类器时，计算出的结果是可以理解的。
      3. 弱分类器构造极其简单，无须做特征筛选。
      4. AdaBoost 算法简单，不用调整分类器，不会导致过拟合。

      3. **AdaBoost 算法的应用**

      AdaBoost 算法的应用场景包括：

      1. 用于二值分类或多分类的应用场景。
      2. 用于特征选择 (Feature Selection)。
      3. 无须变动原有分类器，而是通过组合出新的分类器，提升分类器的性能。

      4. **AdaBoost 实例**

      我们通过如下的实例来深入把握 AdaBoost 算法的思想及其产生的效果。

      (1) 如图5-13所示，\(W_1\) 表示样本的初始权重分配，数据点包含两类数据，分别用 “+” 号和 “一” 号表示。在 AdaBoost 算法运行过程中，我们使用水平或者垂直的直线作为分类器来进行分类。算法最开始给了一个均匀分布 \(D\)。因此，\(h\) 里的每个点的权重是 0.1。

      (2) 利用第一个分类器进行划分，有三个数据点划分错了，根据误差公式，计算得到带权的误差为：\(E = (0.1 + 0.1 + 0.1) = 0.3\)。第一个分类器的权重 \(\alpha_1\) 为 0.42。根据算法要求，把分错的数据点的权值变大(图5-14中，圆圈的灰度变深表示权值变大，因为分类器对其分类错误)，得到新的权重分布。

      至此，根据分类的正确率得到一个新的样本权重分布 \(W_2\)，一个子分类器 \(h\)。

      ![AdaBoost实例](https://via.placeholder.com/150 "AdaBoost实例")

      (3) 进行第 2 次迭代，根据分类的正确率，得到一个新的样本权重分布 \(W_3\) 以及一个子分类器 \(h_2\) (见图5-15)。

      ![AdaBoost第2次迭代](https://via.placeholder.com/150 "AdaBoost第2次迭代")

      (4) 计算最后一个分类器的错误率和权重，得到最后一个分类器的权重为 \(h_3\) (见图5-16)。

      ![AdaBoost第3次迭代](https://via.placeholder.com/150 "AdaBoost第3次迭代")

      (5) 整合所有子分类器，即对其进行加权求和。从结果中看，即使简单的分类器，组合起来也能获得很好的分类效果(见图5-17)。

      ![AdaBoost分类效果](https://via.placeholder.com/150 "AdaBoost分类效果")

      资料来源：http://erinshellmangithub.io/data-mining-starter-kit/#/108.

      ### 5.2.10 线性回归、Logistic 回归

      1. **线性回归与多元线性回归**

      回归分析是应用广泛的统计分析方法，用于分析事物之间的相关关系。其中一元线性回归模型指的是只有一个解释变量的线性回归模型，多元线性回归模型则是包含多个解释变量的线性回归模型。解释变量就是自变量，被解释变量则是因变量。回归模型就是描述因变量和自变量之间依存的数量关系的模型。

      一元线性回归模型具有 \(y = ax + b\) 的简单形式，\(a\) 称为自变量 \(x\) 的系数，\(b\) 称为截距，\(y = ax + b\) 对应到图形则是二维平面上的一条直线。扩展到多元线性回归模型，其形式为

      \[
      y = a_1 x_1 + a_2 x_2 + \cdots + a_n x_n + b
      \]

      方程中包含 \(n\) 个自变量 \(x_1, x_2, \ldots, x_n\)，其系数分别是 \(a_1, a_2, \ldots, a_n\)。

      文献①给出了一个多元线性回归实例，我们通过该实例，具体了解多元线性回归模型的建立和应用。现有 12 名大学一年级女生的身高、体重和肺活量数据，如表5-10所示。现在我们希望在这些数据上建立一个回归模型。这个模型有两个目的：一个是解释这些数据，也就是肺活量和身高、体重有什么关系；另一个是进行预测，假设我们获得另外一个女生的身高、体重数据，我们希望用这个模型预测出她的肺活量应该是多少。

      | 编号 | 身高(cm) | 体重(kg) | 肺活量(L) |
      | ---- | -------- | -------- | --------- |
      | 1    | 161      | 42       | 2.55      |
      | 2    | 162      | 42       | 2.2       |
      | 3    | 165      | 46       | 2.75      |
      | 4    | 162      | 46       | 2.4       |
      | 5    | 166      | 46       | 2.8       |
      | 6    | 167      | 50       | 2.81      |
      | 7    | 165      | 50       | 3.41      |
      | 8    | 166      | 50       | 3.1       |
      | 9    | 168      | 52       | 3.46      |
      | 10   | 165      | 52       | 2.85      |
      | 11   | 170      | 58       | 3.5       |
      | 12   | 168      | 58       | 3         |

      我们把身高作为第一个自变量 \(x_1\)，体重作为第二个自变量 \(x_2\)，肺活量则作为因变量 \(y\)。我们要建立的方程为 \(y = a_1 x_1 + a_2 x_2 + b\)。经过计算(使用最小二乘法估计)，得出

      \[
      b = -0.5657, \quad a_1 = 0.005017, \quad a_2 = 0.05406
      \]

      于是，多元线性回归方程为：

      \[
      y = 0.005017 x_1 + 0.05406 x_2 - 0.5657
      \]

      \(a_1 = 0.005017\) 表示在 \(x_2\) 即体重不变的情况下，身高每增加 1 cm，肺活量增加 0.005017 L。

      建立多元线性回归模型的目的是解释数据以及进行预测。比如，现在遇到一个新的大学一年级女生，身高 166 cm，体重 46 kg，把这两个数据代入上述方程，得到 \(y = 2.75\)，表示对于这样身高和体重的女生，估计的肺活量为 2.75 L。

      2. **多元线性回归模型的检验**

      多元线性回归模型建立以后需要从几个角度进行检验，以了解模型的解释能力和预测能力。这些检验包括拟合优度检验、回归方程显著性检验、回归系数的显著性检验。

      我们把因变量的总变差 (SST) 分解成自变量变动引起的变差 (SSR) 和其他因素造成的变差 (SSE)。用数学语言表达为：

      \[
      SST = \sum (y - \bar{y})^2 = \sum (\hat{y} - \bar{y})^2 + \sum (y - \hat{y})^2 = SSR + SSE
      \]

      式中，\(\bar{y}\) 为样本均值；\(\hat{y}\) 为模型预测值；\(y\) 为因变量的实际值。

      (1) **拟合优度检验**。回归方程的拟合优度指的是回归方程对样本的各个数据点的拟合程度。拟合优度的度量一般使用判定系数 \(R^2\)，它是在因变量的总变差中由回归方程解释的变动(回归平方和)所占的比重。\(R^2\) 越大，方程的拟合程度越高。\(R^2\) 的计算公式为：

      \[
      R^2 = \frac{SSR}{SST}
      \]

      当一个多元线性回归模型的判定系数接近 1.0，说明其拟合优度较高。

      (2) **回归方程显著性检验**。回归方程的显著性检验，目的是评价所有自变量和因变量的线性关系是否密切。常用 \(F\) 检验统计量进行检验，\(F\) 检验是对模型整体回归显著性的检验。\(F\) 统计量的计算公式为：

      \[
      F = \frac{SSR / k}{SSE / (n - k - 1)}
      \]

      式中，\(n\) 为样本容量；\(k\) 为自变量个数。

      \(F\) 检验的原假设 (\(H_0\)) 为，自变量和因变量的线性关系不显著；备择假设 (\(H_1\)) 为，自变量和因变量的线性关系显著。在给定的显著性水平(一般选 0.05)下，查找自由度为 \((k, n - k - 1)\) 的 \(F\) 分布表，得到相应的临界值 \(F_a\)。如果上述计算公式算得的 \(F > F_a\)，那么拒绝原假设，回归方程具有显著意义，回归效果显著，否则，\(F < F_a\)，那么接受原假设，回归方程不具有统计上的显著意义，回归效果不显著。我们也可以通过概率 \(P\) 值来进行判断，概率 \(P\) 值表示 \(H_0\) 成立的可能性有多大。当 \(P < 0.05\)，表示概率极低，那么拒绝原假设，回归方程具有显著意义，回归效果显著，否则，\(P > 0.05\)，在给定显著性水平下，我们不能轻率地拒绝原假设，而是接受它，即自变量和因变量的线性关系不显著。

      (3) **回归系数的显著性检验**。使用 \(t\) 检验，分别检验回归模型中的各个回归系数是否具有显著性，以便使模型中只保留那些对因变量有显著影响的因素。\(t\) 检验是对单个解释变量回归系数的显著性检验。回归系数 \(i\) 的 \(t\) 检验统计量为，其中 \(S_B\) 表示回归系数 \(\beta\) 的标准误差，具体计算方式可以参考相关资料。

      \(t\) 检验的原假设 (\(H_0\)) 为，\(a_i\) 的值为 0，即对应变量 \(x_i\) 的系数为 0，该变量无须进入方程；备择假设 (\(H_1\)) 为，\(a_i\) 的值不为 0，即对应变量 \(x_i\) 的系数不为 0，该变量需要进入方程。给定显著性水平 \(\alpha\) (一般选 0.05)，查找自由度为 \(n - k - 1\) 的 \(t\) 分布表，得到临界值 \(t_a\)，如果 \(t_i > t_a\)，拒绝原假设，回归系数 \(a_i\) 与 0 有显著差异，对应的自变量 \(x_i\) 对因变量 \(y\) 有解释作用；否则 \(t_i < t_a\)，接受原假设，回归系数 \(a_i\) 与 0 没有显著差异，对应的自变量 \(x_i\) 对因变量 \(y\) 没有解释作用。我们也可以通过概率 \(P\) 值来进行判断，概率 \(P\) 值表示 \(H_0\) 成立的可能性有多大。当 \(P < 0.05\)，表示概率极低，那么拒绝原假设，\(a_i\) 对应的变量 \(x_i\) 系数不为 0，该变量需要进入方程；否则，\(P > 0.05\)，在给定显著性水平下，我们不能轻率地拒绝原假设而是接受它，即 \(ai) 对应的变量 *x**i* 系数为 0，该变量无须进入方程。

