 

## 第12章 数据的存储与管理

### 12.1 数据的存储

#### 12.1.1 数据存储的发展

1725年时，法国纺织机械师布乔提出了“穿孔纸带”的构想(图12-1)。他的设想是，首先设法用一排编织针控制所有的经线运动，然后在一卷纸带上根据编织图案打出一排排小孔。启动机器后，正对着小孔的编织针能穿过去钩起经线，其他的针则被纸带挡住不动。这样一来，编织针就自动按照预先设计的图案去挑选经线。
通过这种方式，布乔的“思想”于是“传递”给了编织机，而编织图案的“程序”也就“储存”在穿孔纸带的小孔之中。
1805年时，法国机械师杰卡德根据布乔“穿孔纸带”的构想完成了“自动提花编织机”的设计制作，如图12-2所示。现在，把“程序设计”俗称为“编程序”，就引申自“编织花布”的词义。

![图12-1 布乔的构想](图12-1.png)
![图12-2 自动提花编织机](图12-2.png)

历史有记载的最早的数据存储媒介应该算是打孔纸卡。虽然这个概念1725年由布乔发明，但第一个真正的专利权，是赫尔曼·霍尔瑞斯在1884年9月23日申请的。这个发明用了将近100年，一直用到了20世纪70年代中期。
图12-3所示的打孔纸卡制成于1972年，上面可以打90列孔。能存储的数据少得可怜，事实上几乎没有人真的用它来存储数据。一般它是用来保存不同计算机的设置参数的。

![图12-3 打孔纸卡](图12-3.png)

亚历山大·拜恩(传真机和电传电报机的发明人)在1846年最早使用了穿孔纸带作为存储设备。纸带上每一行代表一个字符。穿孔纸带(图12-4)的容量比打孔纸卡大多了。

![图12-4 穿孔纸带](图12-4.png)

1946年RCA公司启动了对计数电子管(图12-5)的研究，这是用在早期巨大的电子管计算机中的一种存储设备。一个管子长达10英寸①，能够保存4096比特的数据。糟糕的是，它极其昂贵，所以在市场上昙花一现，很快就消失了。

![图12-5 计数电子管](图12-5.png)

①1英寸=2.54厘米。

在20世纪50年代，IBM最早把盘式磁带(图12-6)用在数据存储上。当时，一卷磁带可以代替1万张打孔纸卡，于是它马上获得了成功。直到20世纪80年代之前，盘式磁带都是最为普及的计算机存储设备。

![图12-6 盘式磁带](图12-6.png)

盒式录音磁带(图12-7)是飞利浦公司在1963年发明的，直到20世纪70年代才开始流行。一些计算机，如ZX Spectrum, Commodore 64和Amstrad CPC使用它来存储数据。一盘时长为90分钟的录音磁带，每一面可以存储700 KB～1M的数据。现在的一张DVD9光盘，可以保存4500张这样磁带的数据，如果现在要把这些数据全部读出来，那要整整播放281天。

![图12-7 盒式录音磁带](图12-7.png)

如图12-8所示的磁鼓有12英寸长，一分钟可以转12500转。它在IBM 650系列计算机中被作为主存储器，每支可以保存1万个字符(不到10 KB)。
第一张软盘(图12-9)，发明于1969年，当时是一张8英寸的大家伙，可以保存80 KB的只读数据。4年以后的1973年，一种小一号但是容量为256 KB的软盘诞生了——它的特点是可以反复读写。从此形成了一个趋势——磁盘直径越来越小，而容量却越来越大。到了20世纪90年代后期，可以找到容量为250 MB的3.5英寸软盘。

![图12-8 磁鼓](图12-8.png)
![图12-9 软磁盘](图12-9.png)

1956年9月13日，IBM发布了305 RAMAC硬盘机(图12-10)。它的出现，可以说是在存储容量方面的一个革命性的变化——它可以存储“海量”的数据，“高达”4.4 MB(500万个字符)，这些数据保存在50个24英寸的硬磁盘上。1961年，IBM生产了1000台305 RAMAC计算机，IBM出租这些计算机的价格是每个月3500美元(因为在那个时代，很少有客户买得起计算机，所以IBM发明了出租的办法)。
图12-11所示的是人们最熟悉的一种存储设备——硬盘。硬盘存储技术是现在还在发展中的一种技术。图12-11中的是日立Deskstar 7K500硬盘，是第一个达到500 G容量的硬盘——它的容量是最早的IBM 305 RAMAC的12万倍。硬盘发展趋势也很明显：价格越来越便宜，容量越来越巨大。

![图12-10 305 RAMAC硬盘机](图12-10.png)
![图12-11 日立Deskstar 7K 500硬盘](图12-11.png)

早在1958年光盘技术就发明了，可是直到1972年，第一张视频光盘才问世，6年后的1978年LD光盘开始在市场上销售。那个时候的光盘是只读的，虽然不能写，但是能够保存达到VHS录像机水准的视频，这使光盘很有吸引力(图12-12)。
常见的5英寸光盘，是从LD光盘发展来的，可是它更小、容量更大。它是SONY公司和飞利浦公司在1979年联合发布的，在1982年上市。一张典型的5英寸光盘，可以保存700 MB数据(图12-13)。

![图12-12 光盘](图12-12.png)
![图12-13 CD光盘](图12-13.png)

DVD光盘(图12-14)是使用了不同激光技术的CD，它采用了780 nm的红外激光(标准CD则采用625～650 nm的红色激光)，这种激光技术使DVD可以在同样的面积中保存更多的数据。一张双层DVD容量可达8.5 GB。

![图12-14 DVD光盘](图12-14.png)

#### 12.1.2 大数据对存储带来的挑战

大数据时代的来临，给数据存储带来了新的挑战：

1. **容量问题**：
海量数据存储系统一定要具有相应等级的扩展能力，而且扩展的方式一定要简便，如通过增加模块或磁盘柜来增加容量，最好不需要停机。
2. **延迟问题**：
大数据应用往往存在实时性的问题，特别是涉及网上交易或者金融类相关的应用，同时，高性能计算和服务器虚拟化也要求实现高速吞吐。
3. **安全问题**：
金融数据、医疗信息以及政府情报等特殊行业都有自己的安全标准和保密性需求。大数据分析往往需要多类数据相互参考，而在过去并不会有这种数据混合访问的情况，因此大数据应用催生出一些新的、需要考虑的安全性问题。
4. **成本问题**：
成本控制是使用大数据环境的企业要考虑的一个核心问题。要让每一台设备都实现更高的“效率”，同时还要减少昂贵的部件，提升存储的效率。
5. **数据的积累**：
任何数据都是历史记录的一部分，数据的分析大都是基于时间段进行的。一定要保证数据可以长期保存，实现数据一致性检测功能，保证其长期高可用性。同时，还要具备原位更新功能。
6. **灵活性**：
大数据存储系统的基础设施规模通常都很大。但应用确实千变万化，对于存储能力，要求其能够随着应用分析软件一起扩展，即具备适应各种不同的应用类型和数据场景的能力。
7. **应用感知**：
目前，已有一些针对应用定制的基础存储设施。在主流存储系统领域，应用感知技术的使用也越来越普遍，它也是改善系统效率和性能的重要手段，也将会应用在大数据存储领域。
8. **针对小用户**：
小企业、个人也会有大数据应用需求，大数据不是大企业的特权。那么，该如何吸引这部分群体?

#### 12.1.3 云存储方式

云存储(图12-15)即参考云状的网络结构，创建一个新型的云状结构的存储系统系统，这个存储系统由多个存储设备组成，通过集群功能、分布式文件系统或类似网格计算等功能联合起来协同工作，并通过一定的应用软件或应用接口，对用户提供一定类型的存储服务和访问服务。
云存储是在大数据时代下，应对存储新需求而发展起来的一种新的模式。大数据时代下，对数据库存在高并发读写的需求，要实现对海量数据的高效率存储和访问，不仅要支持对数据库的高可扩展性和高可用性的需求，还要满足非结构化数据的处理能力的需求。
严格说来，云存储其实不是一种存储媒介，而是一种服务。云存储对使用者来讲，不是指某一个具体的设备，而是指一个由许许多多个存储设备和服务器所构成的集合体。使用者使用云存储，并不是使用某一个存储设备，而是使用整个云存储系统带来的一种数据访问服务。云存储的核心是应用软件与存储设备相结合，通过应用软件来实现存储设备向存储服务的转变。
云存储与传统存储有着很多不同。首先，在功能需求方面，云存储系统面向多种类型的网络在线存储服务，而传统存储系统则面向高性能计算、事务处理等应用；其次，在性能需求方面，云存储要面对数据的安全性、可靠性、效率等新的技术挑战；最后，在数据管理方面，云存储系统不仅要提供传统文件访问，还要能够支持海量数据管理并提供公共服务支撑功能，以方便云存储系统后台数据的维护。
总的说来，云存储的优点在于：

1. **可扩容能力强**：
云存储采取的架构是并行扩容，容量不够了，只要采购新的存储服务器即可，容量立即增加，几乎是没有限制的。
2. **易于管理**：
大部分数据迁移到云存储上去后，所有的升级维护任务都由云存储服务提供商来完成，节约了企业存储系统管理员的成本压力。
3. **成本低廉**：
许多企业宁可冒着数据丢失的危险，也要将大部分数据转移到云存储上，让云存储服务提供商来为他们解决数据存储的问题。这样就能花很少的钱获得最优的数据存储服务。
4. **可以实现量身定制**：
这个主要是针对私有云。云服务提供商专门为单一的企业客户提供一个量身定制的云存储服务方案，或者可以是企业自己的IT机构来部署一套私有云服务架构。

![图12-15 云存储](图12-15.png)

### 12.2 数据的管理

#### 12.2.1 数据管理的发展阶段

数据的管理大致经历了三个阶段：人工管理阶段一文件系统阶段一数据库管理系统阶段。

##### 12.2.1.1 人工管理阶段

20世纪50年代中期以前，数据的管理都是处于人工管理阶段。在那个时代，计算机主要用于科学计算，外部存储器只有磁带、卡片和纸带等，还没有磁盘等直接存取存储设备。软件也处于初级阶段，只有汇编语言，无操作系统(OS)和数据管理方面的软件。数据处理方式基本是批处理。
在那个时代，数据几乎是不保存的。因为当时计算机主要用于科学计算，对于数据保存的需求尚不迫切。系统也没有专用的软件对数据进行管理，每个应用程序都要包括数据的存储结构、存取方法和输入方法等。程序员在编写应用程序时，还要安排数据的物理存储，因此程序员负担很重。而且，数据是不共享的，即数据是面向程序的，一组数据只能对应一个程序。当然，数据也不具有独立性。程序依赖于数据，如果数据的类型、格式或输入/输出方式等逻辑结构或物理结构发生变化，则必须对应用程序做出相应的修改。

##### 12.2.1.2 文件系统阶段

文件系统阶段一般是指20世纪50年代后期到20世纪60年代中期。
在这段时间，有了一些新的变化。计算机开始不仅用于科学计算，还大量用于管理。外存储器有了磁盘等直接存取的存储设备。软件方面，操作系统中已有了专门的管理数据软件，称为文件系统。从处理方式上讲，不仅可以进行文件批处理，而且能够进行联机实时处理，可在需要的时候随时从存储设备中查询、修改或更新，因为操作系统的文件管理功能提供了这种可能。
这个时代的特点包括：

1. **数据开始需要长期保留**：数据可以长期保留在外部存储器上反复处理，即可以经常进行查询、修改和删除等操作。所以计算机大量用于数据处理。

2. **程序与数据有了一定的独立性**：数据的改变不一定要引起程序的改变。由于有了操作系统，可以利用文件系统进行专门的数据管理，这就使程序员可以将精力集中在算法设计上，而不必过多地考虑细节。在保存数据

3. ## 时，只需给出保存指令，而不必控制计算机，物理地实现数据保存。读取数据时，只要给出文件名，而不必知道文件的具体存放地址。文件的逻辑结构和物理存储结构由系统进行转换。
   3. **可以实时处理**：由于有了直接存取设备，也有了索引文件、链接存取文件、直接存取文件等，所以既可以采用顺序批处理的方式，也可以采用实时处理的方式。数据的存取以记录为基本单位。

   这个阶段对数据的管理相对之前有了很大的进步，但仍然存在很多问题：

   1. **编写应用程序不方便**：程序员不得不记住文件的组织形式和包含的内容。
   2. **数据冗余大**：文件之间缺乏联系，造成每个应用程序都有对应的文件，有可能同样的数据在多个文件中重复存储。数据冗余不仅浪费了空间，还导致数据的潜在的不一致性和修改数据的困难。
   3. **易造成不一致性**：不一致性往往由数据冗余造成。在进行更新操作时，稍不谨慎，就可能使同样的数据在不同的文件中不一样。
   4. **数据独立性差**：如果存储文件的逻辑结构发生了变化或存储结构发生了变化，那么就不得不修改程序，所以程序和数据之间的独立性仍然较差。
   5. **不支持对文件的并发访问**。
   6. **数据间的联系较弱**：这是由文件之间相互独立、缺乏联系的特性决定的。
   7. **难以按不同用户的需要来表示数据**。
   8. **安全控制功能较差**。

   当时美国的阿波罗登月计划的数据管理就遇到了很大问题。阿波罗飞船由约200万个零部件组成，是分散在世界各地的厂商制造的。为了掌握计划进度及协调工程进展，阿波罗计划的主要合约者罗克威尔公司曾研制了一个计算机零件管理系统。该系统共用了18盘磁带，虽然可以工作，但效率极低，维护困难。18盘磁带中60%是冗余数据。一度成为实现阿波罗计划的严重障碍。为了应对这个挑战，罗克威尔公司在实现阿波罗计划中与IBM公司合作开发了最早的数据库管理系统之一IMS，从而保证了阿波罗飞船1969年顺利登月。

   ##### 12.2.1.3 数据库管理系统阶段

   从20世纪60年代后期开始，数据的管理进入了数据库管理系统阶段。
   当时，采用计算机来进行管理的规模日益庞大，应用越来越广泛，数据量急剧增长，数据共享的呼声越来越强。而且，计算机有了大容量磁盘，计算能力也非常强。硬件价格不断下降，编制软件和维护软件的费用相对增加。联机实时处理的要求更多，并开始提出和考虑并行处理。
   为了解决数据冗余问题，实现数据独立和数据共享，解决由于数据共享而带来的数据完整性、安全性及并发控制等一系列问题，数据库管理系统应运而生。
   数据库管理系统的出现，带来了很多优点：

   1. **数据结构化**：在描述数据的时候，不仅要描述数据本身，还要描述数据之间的联系，这样就把相互关联的数据集成了起来。
   2. **数据共享**：数据不再面向特定的某个或多个应用，而是面向整个应用系统。
   3. **大大降低了数据冗余的可能性**。
   4. **有较高的数据独立性**：存储在数据库中的数据与应用程序之间不存在依赖关系，而是相互独立的。
   5. **保证了安全可靠性和正确性**：通过对数据的完整性控制、安全性控制、并发控制和数据的备份与恢复策略，使存储在数据库中的数据有了更大的保障。
   6. **为用户提供了方便的用户接口**：用户可以使用查询语言或终端命令操作数据库，也可以用程序方式(如用C语言一类高级语言和数据库语言联合编制的程序)操作数据库。

   数据管理三个阶段的比较如表12-1所示。

   表12-1 数据管理三个阶段的比较

   | 项目 | 人工管理阶段   | 文件系统阶段           | 数据库系统阶段           |
   | ---- | -------------- | ---------------------- | ------------------------ |
   | 背景 | 应用背景       | 科学计算               | 科学计算、管理           |
   |      | 硬件背景       | 无直接存取存储设备     | 磁盘、磁鼓               |
   |      | 软件背景       | 没有操作系统           | 有文件系统               |
   |      | 处理方式       | 批处理                 | 联机实时处理 批处理      |
   | 特点 | 数据的管理者   | 用户(程序员)           | 文件系统                 |
   |      | 数据面向的对象 | 某一应用程序           | 某一应用                 |
   |      | 数据的共享程度 | 无共享，冗余度大       | 共享性差，冗余度大       |
   |      | 数据的独立性   | 不独立，完全依赖于程序 | 独立性差                 |
   |      | 数据的结构化   | 无结构                 | 记录内有结构，整体无结构 |
   |      | 数据控制能力   | 应用程序自己控制       | 应用程序自己控制         |

   #### 12.2.2 大数据时代数据管理的特点

   随着网民参与互联网产品和应用程序的程度越来越深，互联网将更加智能，互联网的数据量也将呈爆炸式增长(图12-16)。

   ![图12-16 互联网数据量爆炸式增长](图12-16.png)

   在大数据时代，数据量异常巨大，数据结构复杂、多样，半结构化、非结构化和结构化数据掺杂，数据产生速率非常快，实时性要求高，且数据价值密度低，数据存疑。这些特点，对大数据环境下的数据管理提出了新的要求，传统数据库管理系统难以满足大数据存储的管理需求。
   传统的关系型数据库是建立在关系模型基础上的数据库，借助于集合代数等数学概念和方法来处理数据库中的数据。现实世界中的各种实体以及实体之间的各种联系均用关系模型来表示。关系模型由关系数据结构、关系操作集合、关系完整性约束三部分组成。
   关系型数据库有很多优点：

   1. **操作方便**：通过应用程序和后台连接，方便了用户，特别是没有编程基础的人对数据的操作。
   2. **易于维护**：丰富的完整性，包括实体完整性、参照完整性和用户定义完整性，大大降低了数据冗余和数据不一致的概率。
   3. **便于访问数据**：提供了诸如视图、存储过程、触发器、索引等对象。
   4. **更安全、更快捷**：权限分配和管理，使其较以往的数据库在安全性上要强得多。

   但进入大数据时代，关系型数据库遇到了发展瓶颈：

   1. **关系数据库所采用的二维表格数据模型不能有效地处理多维数据**，不能有效处理互联网应用中半结构化和非结构化的海量数据，如Web页面、电子邮件、音频、视频等。
   2. **高并发，读写性能低**。关系数据库达到一定规模时，非常容易发生死锁等并发问题，导致其读写性能下降非常严重。未来大数据应用并发负载非常高，往往要达到每秒上万次读写请求。关系型数据库勉强可以应付上万次SQL查询，但硬盘I/O往往无法承担上万次的SQL读写数据请求。
   3. **支撑容量有限**。类似人人网，新浪微博，Facebook, Twitter这样的网站，每天用户产生海量的动态信息。以Facebook为例，一个月就要存储1350亿条用户动态，对于关系数据库来说，在一张1350亿条记录的表里进行SQL查询，效率是极其低下乃至不可忍受的。再例如大型Web网站或IM的用户登录系统，例如腾讯，Skype，动辄数以亿计的账号登录，关系数据库也很难应付。
   4. **数据库的可扩展性和可用性低**。当一个应用系统的用户量和访问量与日俱增的时候，传统的关系型数据库就无法像Web Server那样简单地通过添加更多的硬件和服务节点来扩展性能和负载能力。对于很多需要提供不间断服务的系统来说，对数据库系统进行升级和扩展往往需要停机维护和数据迁移。
   5. **建设和运行维护成本高**。企业级关系数据库的价格很高，并且随着系统的规模增大而不断上升。高昂的建设和运行维护成本无法满足云计算应用对数据库的需求。

   由此，人们需要新的数据管理方式来应对大数据时代的挑战，非关系型数据库正是人们的选择。

   #### 12.2.3 非关系型数据

   非关系型数据库(NoSQL)是一种与关系型数据库管理系统截然不同的数据库管理系统，它的数据存储格式可以是松散的，并且易于横向扩展。
   这里NoSQL是指Not only SQL，而不是Not SQL的意思。意指不一定遵循传统数据库的一些基本要求，比如说符合SQL标准、ACID属性、表结构等。也可称为分布式数据管理系统，数据存储被简化，变得更灵活，重点被放在了分布式数据管理上。
   NoSQL的优势在于：

   1. **易扩展**：
   NoSQL数据库种类繁多，但是一个共同的特点就是去掉关系数据库的关系型特性。数据之间无关系，这样就非常容易扩展。无形之间，在架构的层面上带来了可扩展的能力。
   2. **大数据量，高性能**：
   NoSQL数据库都具有非常高的读写性能，尤其在大数据量下，同样表现优秀。这得益于它的无关系性，数据库的结构简单。一般MySQL使用Query Cache。NoSQL的Cache是记录级的，是一种细粒度的Cache，所以NoSQL在这个层面上来说性能就要高很多。
   3. **灵活的数据模型**：
   NoSQL无须事先为要存储的数据建立字段，随时可以存储自定义的数据格式。而在关系数据库里，增删字段是一件非常麻烦的事。如果是数据量巨大的表格，增加字段简直就是一个噩梦。这点在大数据量的Web 2.0时代尤其明显。
   4. **高可用性**：
   NoSQL在不太影响性能的情况下，就可以方便地实现高可用的架构。比如Cassandra, HBase模型，通过复制模型也能实现高可用性。

   #### 12.2.4 开源的NoSQL数据库软件

   ##### 12.2.4.1 Membase

   Membase是NoSQL家族的一个新的重量级成员。Membase是开源项目，源代码采用了Apache2.0的使用许可。该项目托管在GitHub.Source tarballs上，可以下载Beta版本的Linux二进制包。该产品主要是由North Scale的Memcached核心团队成员开发完成的，其中还包括Zynga和NHN这两个主要贡献者，这两个组织都是很大的在线游戏和社区网络空间供应商。
   Membase容易安装、操作，可以从单节点方便地扩展到集群，而且为Memcached(有线协议的兼容性)实现了即插即用功能，在应用方面为开发者和经营者提供了一个较低的门槛。作为缓存解决方案，Memcached已经在不同类型的领域(特别是大容量的Web应用)有了广泛的使用，其中Memcached的部分基础代码被直接应用到了Membase服务器的前端。
   通过兼容多种编程语言和框架，Membase具备了很好的复用性。在安装和配置方面，Membase提供了有效的图形化界面和编程接口，包括可配置的报警信息。
   Membase的目标是提供对外的线性扩展能力，包括为了增加集群容量，可以针对统一的节点进行复制。另外，对存储的数据进行再分配仍然是必要的。
   这方面的一个有趣特征是，NoSQL解决方案所承诺的可预测性能，通过如下方式可以获得：

   1. 自动将在线数据迁移到低延迟的存储介质的技术(内存，固态硬盘，磁盘)。
   2. 可选的写操作——异步、同步(基于复制，持久化)。
   3. 反向通道再平衡。
   4. 多线程低锁争用。
   5. 尽可能使用异步处理。
   6. 自动实现重复数据删除。
   7. 动态再平衡现有集群。
   8. 通过把数据复制到多个集群单元和支持快速失败转移来提供系统的高可用性。

   ##### 12.2.4.2 MongoDB

   MongoDB是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库中功能最丰富，最像关系数据库的。它支持的数据结构非常松散，是类似Json的Bjson格式，因此可以存储比较复杂的数据类型。MongoDB最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，还支持为数据建立索引。它的特点是高性能、易部署、易使用、存储数据非常方便。
   主要功能特性：

   1. **面向集合存储，易存储对象类型的数据**：
   “面向集合”(Collenction-oriented)，意思是数据被分组，存储在数据集中，被称为一个集合。每个集合在数据库中都有一个唯一的标识名，并且可以包含无限数目的文档。集合的概念类似关系型数据库里的表，不同的是它不需要定义任何模式(Schema)。
   2. **模式自由**：
   模式自由，意味着对于存储在Mongodb数据库中的文件，我们不需要知道它的任何结构定义。如果需要的话，你完全可以把不同结构的文件存储在同一个数据库里。
   3. **支持动态查询**。
   4. **支持完全索引，包含内部对象**。
   5. **支持查询**。
   6. **支持复制和故障恢复**。
   7. **使用高效的二进制数据存储，包括大型对象(如视频等)**。
   8. **自动处理碎片，以支持云计算层次的扩展性**。
   9. **支持Ruby, Python, Java, C++, Php等多种语言**。
   10. **文件存储格式为BSON(Binary Serialized Document Format)(一种JSON的扩展)**。BSON存储形式是指存储在集合中的文档，被存储为键—值对的形式。键用于标识一个文档，为字符串类型，而值则可以是各种复杂的文件类型。
   11. **可通过网络访问**。

   MongoDB服务端可运行在Linux、Windows或OSX平台，支持32位和64位应用，默认端口为27017。推荐运行在64位平台，因为MongoDB在32位模式运行时支持的最大文件尺寸为2 GB。
   MongoDB把数据存储在文件中(默认路径为：/data/db)，为提高效率，使用内存映射文件进行管理。

   ##### 12.2.4.3 Hypertable

   Hypertable是一个开源、高性能、可伸缩的数据库，它采用与谷歌的Bigtable相似的模型。在过去数年中，谷歌为在PC集群上运行的可伸缩计算基础设施设计建造了三个关键部分。

   第一个关键的基础设施是Google File System(GFS)，这是一个高可用性的文件系统，提供了一个全局的命名空间。它通过跨机器(和跨机架)的文件数据复制来达到高可用性，并因此免受传统文件存储系统无法避免的许多失败的影响，比如电源、内存和网络端口等的失败。

   第二个基础设施是名为MapReduce的计算框架，它与GFS紧密协作，帮助处理收集到的海量数据。

   第三个基础设施是Bigtable，它是传统数据库的替代。Bigtable让用户可以通过一些主键来组织海量数据，并实现高效的查询。Hypertable是Bigtable的一个开源实现，并且根据人们的想法进行了一些改进。

   ##### 12.2.4.4 Apache Cassandra

   Apache Cassandra是一套开源分布式Key-Value存储系统。它最初由Facebook开发，用于储存特别大的数据。Facebook在使用此系统。

   主要特性：

   1. **分布式**：
   Cassandra是一个由一堆数据库节点共同构成的一个分布式网络服务，对Cassandra的一个写操作，会被复制到其他节点上去，对Cassandra的读操作，也会被路由到某个节点上面去读取。对于一个Cassandra群集来说，扩展性能是比较简单的事情，只要在群集里添加节点就可以了。
   2. **基于Column的结构化**。
   3. **高伸展性**。

   Cassandra的主要特点就是它不是一个数据库，而是由一堆数据库节点共同构成的一个分布式网络服务。Cassandra是一个混合型的非关系数据库，类似于谷歌的BigTable。其主要功能比Dynomite(分布式的Key-Value存储系统)更丰富，但支持度却不如文档存储MongoDB(介于关系数据库和非关系数据库之间的开源产品，是非关系数据库当中功能最丰富，最像关系数据库的)。Cassandra最初由Facebook开发，后转变成了开源项目，它是一个网络社交云计算方面理想的数据库。以Amazon专有的完全分布式的Dynamo为基础，结合了Google BigTable基于列族(Column Family)的数据模型以及P2P去中心化的存储。很多方面都可以称为Dynamo 2.0。
