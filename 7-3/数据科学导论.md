# **第1章 引论**
## **1.1 序言**
- **谷歌首席经济学家哈尔·瓦里安的观点**：
  - 与数据相关的能力（获取、理解、处理、提取价值、可视化、交流）将成为未来关键能力。
  - 数据科学应普及至小学、中学和大学。
- **本书编著目的**：
  - 数据科学涵盖数学、统计学、计算机科学、人工智能等领域。
  - 培养人们与数据打交道的能力，应对大数据时代的挑战。

## **1.2 数据科学简述**
### **1.2.1 数据科学的定义**
- **科学的定义**：
  - 达尔文：整理事实，发现规律，得出结论。
  - 《辞海》：关于自然界、社会和思维的知识体系，实践经验结晶。
  - 维基百科：系统性工程，通过验证和测试的解释和预测，创造、构建和组织知识体系。
- **数据科学的定义**：
  - 通过系统性研究获取与数据相关的知识体系。
  - **两个层面**：
	1. 研究数据本身（类型、结构、状态、属性及变化形式和规律）。
	2. 通过数据研究，为自然科学和社会科学研究提供新方法（科学研究的数据方法），揭示自然界和人类行为的现象和规律。

### **1.2.2 数据科学的由来**
- **起源**：
  - 1960年，丹麦人、前图灵奖得主、计算机科学领域先驱彼得·诺尔首次提出“数据科学”。
  - 1974年，彼得·诺尔出版《Concise Survey of Computer Methods》，多次提及“数据科学”。
- **发展**：
  - 1997年，国际知名统计学家吴建福在美国密西根大学做讲座“统计学是否等同于数据科学”，认为统计学应重命名为“数据科学”。
  - 2002年，《Data Science Journal》创刊。
  - 2003年，《The Journal of Data Science》创刊。
- **现状**：
  - 随着大数据时代的来临，数据科学受到越来越多的关注。

### **1.2.3 数据科学的研究范畴**
- **涉及范围**：
  - 数据科学虽已有近60年历史，但仍属新兴学科，涉及范围广泛。
- **主要涵盖**：
  1. **数据与统计学相关知识**：数据模型、数据过滤、数据统计和分析、数据结构优化等。
  2. **计算机科学相关知识**：数据获取技术、数据处理方法、数据存储和安全性保障等。
  3. **图形学相关知识**：数据可视化、数据协同仿真、虚拟环境实现等。
  4. **人工智能相关知识**：机器学习算法应用、神经网络运用等。
  5. **领域相关知识**：处理特定领域数据分析和解读所需的理论和方法等。
- **未来展望**：
  - 数据科学将深入许多目前未知的领域，探索仍在继续。
- **与其他学科的关系**：
  - **研究对象**：数据本身，通过研究数据获取对自然、生命和行为的认识。
  - **与计算机科学、信息科学和知识科学的区别**：研究对象、研究目的和研究方法本质不同。
  - **对自然科学和行为科学的支持**：数据科学支持自然科学和行为科学的研究工作，随着数据科学的发展，越来越多的科学研究工作将直接针对数据进行。
- **具体研究内容**：
  1. **基础理论研究（科学）**：
	 - 数据的观察方法和数据推理的理论，包括数据的存在性、数据测度、数据代数、数据相似性与簇论、数据分类与数据百科全书等。
  2. **实验和逻辑推理方法研究（工程）**：
	 - 建立数据科学的实验方法，建立科学假说和理论体系，通过实验方法和理论体系开展对数据的探索研究，认识数据的各种类型、状态、属性及其变化形式和规律，揭示自然界和人类行为的现象和规律。
  3. **数据资源的开发利用方法和技术研究（技术）**：
	 - 研究数据挖掘、清洗、存储、处理、分析、建模、可视化、展现等一系列过程中遇到的技术难题和挑战。
  4. **领域数据科学研究（应用）**：
	 - 将数据科学的理论和方法应用于各种领域，形成针对专门领域的数据科学，如脑数据科学、行为数据科学、生物数据科学、气象数据科学、金融数据科学、地理数据科学等。

### **1.2.4 数据科学的学习意义**
- **培养目标**：
  - 培养数据科学家或数据工程师。
  - **数据科学家**：数据科学的从业者。
  - **数据工程师**：熟练运用数据科学的工程人员。
- **市场需求**：
  - 根据麦肯锡报告，仅美国未来就需要超过19万个深度解析数据科学家和150万个初级数据管理人员，目前职位空缺大。
- **职业前景**：
  - 谷歌首席经济学家哈尔·瓦里安称：“数据科学家将会是21世纪最性感的工作。”

## **1.3 本书结构**
- **大数据时代背景**：
  - 数据在人们生活中占据越来越重要的地位，做决定时越来越多地依赖数据分析。
- **数据科学的作用**：
  - 数据科学作为一门蓬勃发展的新学科，关注如何在大数据时代背景下，运用与数据相关的技术和理论服务于社会，让人们更好地利用身边的数据，使生活更美好。
  - 数据科学已渗透到人们生活和工作的方方面面，政府和企业未来都需要大量懂得数据科学相关知识的人才。
- **本书内容**：
  - 系统讲述与数据科学相关的知识，着重培养数据科学所需的技能与思维方法。
  - 作为数据类课程的基础教材，结合大量翔实案例讲解相关知识要点。
	- **生动具体**：大量案例阐述数据科学知识的运用方式，让学生更容易接受。
	- **技术传授**：从案例中提取数据科学各领域的特色，寓技术于案例之中，讲解案例的同时传授技术细节。
	- **思维模式介绍**：将数据科学学科中的各种新兴思维模式和技术方法的介绍穿插到案例分析过程中。
- **本书结构**：
  - 包含五个部分，依次回答与数据科学相关的五个基本问题：
	1. **第一部分（引论部分）**：讲解数据科学的具体概念和研究范畴。
	2. **第二部分**：介绍大数据及其产生根源，从数据定义谈起，结合数据演化，阐述大数据的概念和特征，并探究大数据的产生根源。
	3. **第三部分**：讲解大数据研究的重要性，从世界范围内大数据的研究现状谈起，结合丰富翔实的案例分析，穿插一些技术知识点的讲解，形象生动地引导学生初步了解大数据的研究方法、内容，以及理解数据科学研究的重要性。
	4. **第四部分**：讲解数据科学的研究方法，结合数据获取、存储、管理、处理、分析、建模及可视化的全过程，系统地、有序地讲解数据科学的研究方法，注重与工程实践相结合。
	5. **第五部分**：探索数据科学与生活的关系，从智慧城市的建设、智慧医疗的发展、未来就业、生活等各个方面讲述数据科学对人类社会和日常生活的深远影响。


# 第2章数据

## 2.1 数据的定义
### 2.1.1 数据的定义
- **数据科学核心**：研究数据，获取知识
- **数据定义**：
  - 以定性或定量方式描述事物的符号记录
  - 可定义为意义的实体，涉及事物存在形式
- **数据表现形式**：
  - 数字
  - 文本
  - 音频
  - 图像
  - 视频
- **数据类型**：
  - 连续值（模拟数据）：如声音
  - 不连续值（数字数据）：如成绩
- **数据本质**：
  - 人为创造的对事物的表示方式
  - 通过观察或实验得来的对现实世界的描述和反映

### 2.1.2 其他相关概念
- **数据、信息与知识**：
  - **数据**：
	- 最低层次的抽象
	- 原始的、零散的，本身没有意义
	- 数据经过处理依然是数据，只有经过解释和理解才有意义
  - **信息**：
	- 次高层次的抽象
	- 对数据的解读和释义
	- 从数据中提取有用信息
  - **知识**：
	- 最高层次的抽象
	- 对某件物品或现象的理论性或实践性的理解
	- 通过传授或亲身经历获取
- **示例**：
  - 珠穆朗玛峰高度（数据）
  - 地质特性书籍（信息）
  - 攀上路径报告（知识）
- **数据科学中的其他概念**：
  - **元数据**：数据的数据
  - **元信息**：信息的信息
  - **数据文件**：信息与元数据的集成
- **相关示例**：
  - **岩石样本**：
	- 数据：重量、形状、尺寸
	- 信息：成分分析图像
	- 知识：地质活动证据
	- 元数据：收集时间、地点
	- 数据文件：实验室报告
  - **天气**：
	- 数据：风速、风向、温度
	- 信息：气象云图
	- 知识：高气压系统分布、天气稳定性
	- 元数据：雷达类型、传感器类型

## 2.2 数据简史
### 2.2.1 原始数据记录
- **穴居壁画**：
  - 最早的有记录的数据
  - 洞穴墙壁上的刻画
  - 记录日期或日常事件（图2-1）
- **结绳记事**：
  - 《周易·系辞下》记载
  - 一条绳子上打结记事
  - 上古时期中国及秘鲁印第安人习惯（图2-2）

### 2.2.2 数字与文字出现后的数据记录
- **莎草纸**：
  - 古埃及人发明
  - 最早、最便利的书写材料之一
  - 记录古埃及历史的主要载体（图2-3）
- **造纸术**：
  - 汉代发明
  - 文本形式的数据记录方式盛行（图2-4）

### 2.2.3 音频数据记录
- **留声机**：
  - 1877年爱迪生发明
  - 最早的录音机
  - 记录并重放声音（图2-5）

### 2.2.4 图像数据记录
- **静止图像**：
  - 1822年涅普斯拍摄世界第一张照片
  - 1839年达盖尔制成第一台实用的银版照相机（图2-6）
- **运动图像**：
  - 1874年朱尔·让桑发明摄影机
  - 现代电影摄影机的始祖（图2-7）

### 2.2.5 电子计算机与数据存储
- **第一台电子计算机**：
  - 1946年ENIAC问世
  - 数据存储方式的革命（图2-8）
- **计算机发展**：
  - 数据存储能力增强
  - 数据处理能力提升
  - 最新统计：天河2号处理速率达每秒钟22.86千万亿次浮点操作（图2-9）

### 2.2.6 互联网与数据传播
- **ARPANET**：
  - 最早的网络
  - 加速TCP/IP的问世
  - 1983年全部计算机完成向TCP/IP的转换
- **Internet发展**：
  - 1984年NSF建立国家超级计算中心及国家教育科技网
  - 1988年Internet开始对外开放
  - 1991年商业用户首次超过学术界用户
- **网络时代**：
  - 数据大爆炸
  - 社交网站、游戏商、视频网站、微博等数据产生量巨大

### 2.2.7 传感器网络与物联网
- **传感器网络**：
  - 大量部署在作用区域内的微小传感器节点
  - 自组织方式构成分布式智能化网络系统
  - 综合传感器技术、嵌入式计算技术、现代网络及无线通信技术、分布式信息处理技术
- **物联网**：
  - 利用传感器网络感知识别技术
  - 融合物理世界和信息世界
  - 数据收集的重要渠道（图2-11）

### 2.2.8 大数据时代
- **数据运用革命**：
  - 大量数据被产生和积存
  - 努力汲取数据养分，产生价值
  - 通过数据分析了解世界运行方式，一窥未来（图2-12，图2-13）


 

# 第 3 章大数据的概念和特征
# **大数据的概念与4V特性**

## **3.1 大数据的概念**
- **起源与定义**
  - **Nutch项目**：大数据术语最早用于描述搜索引擎需要处理的大量数据集。
  - **Gartner定义**：
	- 海量、高增长率和多样化信息资产。
	- 需新处理模式以增强决策力、洞察力和流程优化能力。
  - **维基百科定义**：
	- 规模巨大到主流软件无法在合理时间内处理的数据。
	- 用于企业经营决策的积极目的。
  - **《著云台》观点**：
	- 非结构化和半结构化数据。
	- 分析成本高，常与云计算结合（如MapReduce框架）。
- **国际数据公司定义**
  - 图3-1展示其定义框架。
- **共性总结**
  - **特性**：巨量、高增长、多样化。
  - **属性**：信息资产。
  - **处理要求**：需新模式和思维方式。
- **与传统数据的区别**
  - **机遇与挑战**：流动、变化、快速增长，蕴含巨大价值。
  - **关键**：新思维模式、技术手段、方法论。

## **3.2 大数据的4V特性**
- **图3-2展示4V特性框架**。

### **3.2.1 体量巨大（Volume）**
- **计量单位**：PB、EB、ZB，未来或达YB/BB。
- **驱动因素**：
  - 数据存储与网络技术发展。
  - 社交网络推动数据量倍增。
- **完整性优先**：数据数量级非核心，完整性使全本分析成为可能。
- **与数据仓库对比**
  - **客观世界数据（硬数据）**：
	- **测量数据**：传感器采集（位置、速度等）。
	- **原子数据**：事件与活动交织（如ATM交易、飞行事故记录）。
	- **衍生数据**：原子数据数学处理结果（如银行账户统计）。
  - **主观世界数据（软数据）**：
	- **多元数据**：图像、视频、音频（非结构化）。
	- **文本数据**：文本、文件（需统计工具分析）。
	- **复合数据**：硬数据与软数据结合（如元数据）。
  - **图3-3展示对比金字塔**：
	- 主观数据（上）与客观数据（下）的交点为数据意义。
	- 大数据强调主观世界巨量细节，基于统计结果提取假设。

### **3.2.2 多样性（Variety）**
- **数据类型**
  - **结构化数据**：数据库二维表结构（如关系型数据）。
  - **非结构化数据**：办公文档、图片、音频/视频等。
  - **半结构化数据**：自描述性数据（如XML、HTML）。
- **数据来源**
  - **互联网**：主观数据（文本、图片、日志、点击流）。
  - **物联网**：客观数据（传感器记录的声、光、电、温度等）。
- **图3-4展示数据类型特征**：
  - **档案数据**：非结构化、低多样性。
  - **媒体数据**：半结构化、体量巨大。
  - **传感器数据**：结构化、多样性强。

### **3.2.3 价值密度低、提纯难（Value/Veracity）**
- **数据升华过程**：
  - **数据→信息**：过滤与组织。
  - **信息→知识**：整合与呈现。
  - **知识→智慧**：领悟与归纳。
- **挑战**
  - **数据噪声与污染**：不一致性、不完整性、模糊性。
  - **数据量与复杂性**：提纯难度随数据量指数级增长。
- **案例**：
  - 监控视频中有效数据仅1-2秒。
  - 统计相关关系可能无实际意义，导致“干草垛中找针”。
- **图3-5展示数据提纯过程**。

### **3.2.4 速度快、时效要求高（Velocity）**
- **处理要求**：
  - **秒级定律**：分析结果需在秒级时间内生成。
  - 传统数据挖掘技术无法满足实时性需求。

### **3.2.5 对4V特性的综合体会**
- **技术挑战**：
  - 既有架构无法高效处理海量、多样化、快速增长的数据。
  - 关键在于提高数据“加工能力”以实现增值。
- **战略意义**：
  - 大数据是信息资产，驾驭能力决定洞察力深度。
- **综合定义**：
  - **大数据**：在计算机技术推动下，互联网/物联网涌现的高速、海量、多模态数据。
  - 需先进处理技术“提纯”价值，涵盖结构化、半结构化和非结构化数据。
- **未来展望**：
  - 大数据是21世纪“石油”，取之不尽，潜力无限。


# **第4章 大数据的产生根源**
- **4.1 大数据的产生根源**
  - **4.1.1 大数据时代出现的技术基础**
	- 计算机技术飞速发展
	- 无线互联技术推动移动互联网、传感器网络发展
	- 数据抓取、并行处理、高容量存储技术提升数据获取与处理能力
	- 数据可视化、虚拟现实、人工智能技术辅助数据价值挖掘与决策
  - **4.1.2 大数据时代出现的数据基础**
	- 互联网与物联网的蓬勃发展
	- 互联网数据：主观性、非结构化为主
	- 物联网数据：结构化、速率快、体量大，客观性数据为主
- **4.2 大数据简史**
  - 1944年，弗里蒙特·赖德首次提出“大数据”概念
  - 1949年，仙农研究存储容量
  - 1961年，德里克·普赖斯提出“指数增长规律”
  - 1971年，亚瑟·米勒提出数据量判别能力
  - 1996年，电子存储设备比纸质媒介更有效
  - 1997年，迈克尔·考克斯和大卫·埃尔斯沃斯首次使用“大数据”术语
  - 2000年，全球信息量研究启动
  - 2001年，道格·莱尼提出大数据“3V”特性
  - 2002年，美国政府涉足大规模数据挖掘
  - 2004年，“9·11”委员会呼吁反恐信息共享，零售商积累客户数据
  - 2007-2008年，数据量每十八个月翻一番
  - 2009年，美国人日均产生数据量研究，奥巴马政府推出data.gov网站
  - 2011年，IBM沃森计算机系统获胜
  - 2012年，大数据成为流行词汇，美国政府推动大数据研究
  - 2013年，被称为“大数据元年”
- **4.3 大数据时代的挑战**
  - **4.3.1 数据规模**
	- 数据增长速度超过计算和存储资源增长速度
	- 处理器设计面临功率墙限制，海量计算资源带来问题
  - **4.3.2 数据的多样性和异构性**
	- 机器分析算法只能处理同构数据
	- 数据分析第一步是数据结构化
  - **4.3.3 数据的不可靠问题**
	- 检测、验证数据真伪
	- 分辨有用数据和客观反映规律的数据
	- 处理缺失和错误数据
  - **4.3.4 数据的实时性要求**
	- 快速高效分析数据得出结论
	- 保证数据快速传递
	- 设计新索引结构支持查询
  - **4.3.5 数据隐私问题**
	- 有效管理隐私
	- 分享私人数据保证隐私不泄露
	- 保障信息共享安全性
  - **4.3.6 人机协作问题**
	- 通过可视化分析实现人机交互
	- 利用可视化技术使数据挖掘平民化
	- 支持多专家输入与结果同步探查
	- 利用人类集体智慧解决问题
  - **4.3.7 数据的访问与共享**
	- 防范数据垄断
	- 保证数据为全人类谋福利
  - **4.3.8 数据运用的合理性**
	- 分析结果代表人类社会的程度
	- 根据数据分析发现异常情况
	- 寻找大概率还是小概率事件
	- 证实异常真实性
  - **4.3.9 小结**
	- 大数据时代机遇与挑战并存
	- 要求不断革新创造，享受数据红利


# 5 各国政府和企业在大数据方面的研究现状

## 5.1 政府篇

### 5.1.1 联合国的大数据研究

**全球脉搏计划**：

- **启动时间**：2009年。
- **目标**：运用数据相关的创新方法和技术，帮助决策者快速应对全球性危机，推动全球发展，追踪全球发展趋势，保护弱势群体，强化对全球性经济危机的应对能力。
- **研究内容**：
  1. 研究创新性的实时数据分析方法和技术，早期发现全球发展过程中潜在的隐患。
  2. 组建免费和开源技术工具集，分析实时数据和共享科学推理及假设。
  3. 建立一个统一的、全球性的Pulse Lab系统，总部在纽约，在国家层面上引导全球脉搏计划的推进。
- **发展情况**：
  - 2012年，发布大数据政务白皮书《大数据促发展：挑战与机遇》。
  - 2013年8月，纽约市“Pulse Lab”有研究人员14人，印度尼西亚实验室有10人，乌干达实验室有8人。
  - 2014年，将如何利用大数据应对全球气候挑战作为气候峰会的重要议题。
- **研究数据来源**：
  1. **数据废弃物**：电子类服务过程中非主动性收集的事务性数据，如股票走势、学校出勤情况等。
  2. **在线信息**：网络上的数据内容，如新闻报道、社交媒体互动、电子商务、工作招聘信息等。
  3. **物理传感器数据**：卫星图像、交通数据、光辐射数据、城市发展和布局改变数据等。
  4. **群智数据**：由市民主动产生或提交的数据，如通过手机端的调查、热线电话、用户产生的自定义地图等。

### 5.1.2 美国的大数据研究

**国家战略**：

- **大数据作为核心资源**：美国政府将大数据上升到了国家战略的高度。
- **主要应用领域**：反恐。
- **主要项目和计划**：
  - **2002年**：组建用于筛选通信、犯罪、教育、金融、医疗和旅行等记录来识别可疑人的大数据库。
  - **2007年**：美国国家安全局开始实施棱镜计划 (Prism)，从9家美国互联网公司中进行数据挖掘工作。
  - **2009年**：推出data.gov网站，开放37万个数据集，提供上千个数据应用。
  - **2011年**：总统科技顾问委员会提出政策建议，指出大数据技术蕴含着重要的战略意义。
  - **2012年**：宣布投资2亿美元拉动大数据相关产业的发展，启动“大数据研究与开发计划”。

### 5.1.3 欧盟的大数据研究

**监管和推动公开**：

- **2012年1月**：欧委会提交《通用数据保护条例》等规定，旨在以较低的费用和简捷的重复使用条件，更加便捷地使用和重新使用公共数据。
- **应用领域**：智慧城市的建设。
- **智慧城市评价方面**：智慧经济、智慧治理、智慧生活、智慧人民、智慧环境、智慧移动性。
- **案例**：西班牙桑坦德市，通过成千上万的传感器收集数据，帮助市民了解交通状况、自动为公园的绿化浇水、控制街道两旁路灯的运作等。

## 5.2 企业篇

### 5.2.1 谷歌

**大数据布局**：

- **主要技术和系统**：
  - **Caffeine**：新一代增量索引系统，丢弃了MapReduce，将索引放置在分布式数据库BigTable上。
  - **Pregel**：用于分布式图计算的计算框架，主要用于图遍历、最短路径、PageRank计算等。
  - **Dremel**：采用列式存储，是一个交互式的数据分析系统，可跨越数千台服务器运行。
- **数据中心**：8个主要数据中心位于美国各地，另外2个在美国境外，分别在芬兰和比利时。还在中国香港和中国台湾，以及新加坡和智利建立了数据中心。
- **大数据分析智能应用**：客户情绪分析、交易风险(欺诈分析)、产品推荐、消息路由、诊断、客户流失预测、法律文案分类、电子邮件内容过滤、政治倾向预测、物种鉴定等。
- **BigQuery**：基于Dremel系统，谷歌推出的强大的数据分析软件和服务。

### 5.2.2 IBM

**大数据平台架构**：

- **“3A5 步”动态路线图**：
  1. **掌握信息 (Align)**
  2. **获取洞察 (Anticipate)**
  3. **采取行动 (Act)**
  4. **学习 (Learn)**
  5. **转型 (Transform)**
- **四大核心能力**：
  - Hadoop系统
  - 流计算 (Stream Computing)
  - 数据仓库 (Data Warehouse)
  - 信息整合与治理 (Information Integration and Governance)
- **应用场景**：
  1. **大数据探索**：帮助组织探索和挖掘相关数据，辅助决策。
  2. **增强的全方位客户视图**：全面了解客户，扩展现有的客户视图。
  3. **安全/智能扩展**：实时监控网络安全，检测欺诈，降低风险。
  4. **运营分析**：分析机器数据和运营数据，获得更好的业绩。
  5. **数据仓库扩展**：通过整合大数据和数据仓库，提高操作效率。

### 5.2.3 百度

**大数据引擎**：

- **核心攻关技术**：深度学习，改善多媒体搜索效果和智能搜索，如语音搜索、视觉搜索和自然语言搜索。
- **大数据引擎架构**：
  - **百度大脑**：深度学习，超大规模机器学习、大规模GPU并行化平台。
  - **数据工厂**：新一代数据库管理与查询技术、大数据挖掘机。
  - **开放云**：低能耗数据中心、超大规模分析式架构、新一代智能自动化运维、超强云安全。

### 5.2.4 阿里巴巴

**大数据应用方案**：

- **淘宝数据魔方**：商家可以了解淘宝平台上的行业宏观情况、自己品牌的市场状况、消费者行为情况等。
- **阿里小贷**：通过平台所掌握的企业交易数据，借助大数据技术自动分析判定是否给予企业贷款。
- **数据平台事业部和数据委员会**：重点开发数据安全、数据质量、数据化运营，并帮助集团各个事业部打通底层的数据基础设施平台。
- **数据地图**：追溯数据的源头，提高数据的质量和价值。
- **阿里巴巴大数据竞赛**：第一年比赛内容主要是运用电子商务的数据来进行商品推荐，第二年比赛聚焦于车联网数据的分析。

### 5.2.5 腾讯

**大数据平台核心模块**：

- **腾讯分布式数据仓库 (TDW)**：基于Hadoop/Hive进行深度定制，支持百PB级数据的离线存储和计算。
- **数据实时收集与分发平台 (TDB)**：从业务数据源端实时采集数据，进行预处理和分布式消息缓存后，分发给后端的离线TDW系统和在线处理系统TRC。
- **腾讯实时计算平台 (TRC)**：基于Storm流式计算，为对时间延迟敏感的业务提供海量数据实时处理服务。
- **统一资源调度平台 (Gaia)**：提供高并发任务调度和资源管理，支持离线业务、实时计算业务和在线服务业务。


# 第6章 关联分析

## 6.1 啤酒与尿布

### 6.1.1 案例详析
- **故事背景**：20世纪90年代，美国沃尔玛超市发现啤酒与尿布在周末销量同时增加。
- **原因分析**：年轻的父亲在购买尿布时会顺便购买啤酒。
- **沃尔玛的措施**：将啤酒与尿布摆放在相同区域，提升销售额。
- **成功因素**：
  1. 先进的计算机技术。
  2. 大数据的分析方法。

### 6.1.2 购物篮分析法
- **定义**：通过分析顾客购物篮内商品登记结算记录，研究购买行为。
- **两大类方法**：
  1. **美式购物篮分析法**：关注购物篮内商品之间的关联关系，适用于大卖场。
  2. **日式购物篮分析法**：关注影响商品销售的关联因素，如天气、温度、时间等。

### 6.1.3 商品间相关性分析
- **数据挖掘**：从大量数据中揭示隐含的、先前未知的并有潜在价值的信息。
- **关键性指标**：
  1. **支持度 (Support)**：商品A和商品B同时出现在购物篮中的概率。
  2. **置信度 (Confidence)**：购买商品A的同时购买商品B的概率。
  3. **提高度 (Lift)**：商品A的出现对商品B购买的影响程度。

### 6.1.4 外界因素的影响
- **案例**：
  1. 德国啤酒的“啤酒一气温指数”。
  2. 日本空调指数。
  3. 台湾七五三感冒指数。

### 6.1.5 思维启示
1. **不要只见树木，而不见森林**：从全局角度看待问题，关注购物篮整体。
2. **注重相关关系的研究**：商品之间的相关性反映了客户心理层面的因素。
3. **深挖数据背后的含义**：了解特定客户群体的消费行为。
4. **数据分析不要停留于表面**：发现现象后，要深挖本质。

## 6.2 亚马逊的个性化推荐

### 6.2.1 案例详析
- **背景**：亚马逊是全球电子商务的创始者，通过数据挖掘和个性化推荐提升销售额。
- **推荐系统**：考虑历史浏览记录、购买记录和其他购物者的记录，确保访问者购买商品。

### 6.2.2 亚马逊的推荐方式
1. **收集用户行为数据**：记录用户的搜索、浏览、打分、点评、购买等行为。
2. **整合用户行为数据**：分析会话日志，了解用户喜好。
3. **个性化推荐营销服务**：利用推荐算法实现个性化推荐。
4. **统计用户反馈数据**：评估推荐效果，优化推荐算法。

### 6.2.3 推荐算法
1. **基于人口统计学的推荐算法**：根据用户的基本信息发现用户的相关程度。
2. **基于内容的推荐**：基于项目的内容信息做出推荐。
3. **基于协同过滤的推荐算法**：利用用户的历史喜好信息计算用户之间的距离。
4. **基于关联规则的推荐**：以关联规则为基础，把已购商品作为规则头，规则体为推荐对象。
5. **基于效用的推荐**：建立对用户使用项目的效用函数。
6. **基于知识的推荐**：基于功能知识进行推理。
7. **组合方式的推荐**：综合多种推荐技术。

## 6.3 潘多拉音乐组计划

### 6.3.1 案例详析
- **背景**：潘多拉网络电台拥有8000万以上注册用户，通过分析用户对歌曲的反馈行为推送音乐。
- **用户模式**：
  1. 用户输入喜欢的歌曲或歌手名字，创建私人电台。
  2. 系统推送风格类似的歌曲，根据用户反馈不断优化推荐。

### 6.3.2 音乐基因组计划
- **定义**：将音乐分解成基本的基因片段，通过分析歌曲的旋律、和声、配器、歌词等属性进行推荐。
- **工作原理**：
  1. 用户输入歌曲创建个性化电台。
  2. 系统分析歌曲属性，找出类似风格的歌曲。
  3. 推荐找到的歌曲，记录用户反馈，优化推荐。

### 6.3.3 标签的运用
- **定义**：无层次化结构的、用来描述信息的关键词。
- **应用案例**：
  1. **Delicious**：书签类站点，通过标签分类书签。
  2. **Lastfm**：音乐推荐服务，通过分析用户听歌行为推荐音乐。
  3. **CiteULike**：论文书签网站，通过标签帮助用户发现相关论文。
  4. **Hulu**：视频网站，通过用户标签系统标记电视剧和电影。

## 6.4 塔吉特的大数据营销

### 6.4.1 案例详析
- **背景**：塔吉特通过分析顾客购买行为，精准预测顾客怀孕情况，推送相关商品广告。
- **方法**：
  1. 通过迎婴聚会的登记表分析顾客消费数据。
  2. 选出25种典型商品的消费数据，构建“怀孕预测指数”。
  3. 精确推送孕妇优惠广告，提升销售额。

### 6.4.2 思维启示——数据应用已经渗入生活的方方面面
- **数据力量**：提升商家业绩，精准营销。
- **客户管理**：通过ID号记录客户行为，进行个性化推荐。
- **跨行业应用**：
  1. **零售业**：如Tesco通过会员卡了解用户分类，进行个性化促销。
  2. **互联网行业**：如雅虎、AOL通过大数据分析用户行为，提供个性化服务。
  3. **能源行业**：如Opower通过数据分析提高用电效能，节省用电费用。


# 第7章 趋势预测

## 7.1 “搜索+比价”

“搜索+比价”是通过网站搜索功能，比较相同商品在不同售卖方的价格，从而选择最优购买方式。这是搜索引擎在网上购物领域的细分，旨在为消费者展示多个B2C网站的商品价格、质量、信誉、服务等信息。典型代表是美国的Farecast和Decide网站。

### 7.1.1 Farecast 案例详析

**背景**：2003年，计算机专家奥伦·埃齐奥尼在预订机票时发现，邻座乘客的票价更低，这激发了他开发机票价格预测系统的想法。

**发展**：
- 埃齐奥尼利用大数据技术，分析旅游网站上的机票价格，建立预测模型，判断当前票价是否合理。
- 系统通过分析票价与提前购买天数的关系，预测未来票价走势，帮助用户决定购票时机。
- 预测系统基于41天内12000个价格样本，预测准确性逐步提高。
- 最终，Farecast成为一家科技创业公司，提供机票价格预测服务，帮助用户节省开支。

**特点**：
- 预测系统基于海量数据，利用行业机票预订数据库提高准确性。
- 网站提供简洁明了的机票搜索和预测功能，支持多方面的限定和价格变化通知。
- 2008年，Farecast计划将技术应用到其他领域，如宾馆预订和二手车购买，但被微软收购，并入必应搜索引擎。

**成就**：
- 2013年，Farecast拥有约2000亿条飞行数据记录。
- 到2012年，系统用了近十万亿条价格记录，预测准确度高达75%，平均每张机票可为用户节省50美元。

### 7.1.2 Decide案例详析

**背景**：2008年，埃齐奥尼计划将“搜索+比价”技术应用到其他领域，创办了Decide.com。

**发展**：
- Decide.com获得800万美元的C轮融资，总融资达1700万美元。
- 网站抓取亚马逊、百思买等电商的商品数据，提供比价服务，帮助消费者做出购买决策。
- 使用大数据对160万件产品进行数据分析，预测价格趋势和购买指标。

**特点**：
- 搭建“线性分析模式”，利用专有价格预测算法，综合考虑上亿条价格波动信息和超过40个价格影响因素。
- 展示产品的全面更新时间线，避免用户购买后立即出现新产品。
- 提供产品打分系统，根据用户和专家评价，将产品分成四个等级，简化购买决策。

**成就**：
- 每月用户访问量达数十万户，页面浏览量超过100万次。
- 发现新商品出现后，老一代商品价格在短时间内反而上升的现象。

### 7.1.3 思维启示

**启示一：重要的是思维模式的运用**
- Farecast的初步模型仅基于12000个价格样本，但通过不断优化模型，提高预测准确性。
- 大数据的核心在于思维，而非数据或技术本身。

**启示二：数据的极致利用**
- Decide通过解决电子产品更新速度过快和市场价格变化过快的问题，提供最佳购物时机建议。
- 技术驱动下，对数据进行极致利用，提供低门槛的操作体验和直观全面的结果展示。

## 7.2 Twitter与对冲基金

### 7.2.1 案例详析

**背景**：英国对冲基金Derwent Capital Markets利用Twitter数据预测股市表现。

**发展**：
- 通过分析Twitter内容，感知市场情绪，进行投资决策。
- 分析程序评估人们的共同情绪，确定投资行为，预测股市涨跌。
- 约翰·博伦的研究显示，利用社交网站预测道琼斯指数的准确率达到87.6%。

**特点**：
- Twitter情绪可以预测今天情绪对明天股价变化的影响，尤其是在没有重大新闻事件的情况下。
- 分析程序通过比较正面评价和负面评价，确定人们的六种情绪：冷静、警觉、确信、活跃、友好和高兴。

**成就**：
- 4000万美元的对冲基金为投资客户设定了15%～20%的年回报率。

### 7.2.2 思维启示

**数据可以预测趋势与规律**：
- 社交媒体数据反映人们的意图、情感、观点和需求，通过正确解读数据可以预测事物运行规律。
- 对数据的解读过程带有主观色彩，需要仔细研判。

## 7.3 疾病预测

### 7.3.1 谷歌流感趋势

**背景**：谷歌2008年推出“谷歌流感趋势”，用于预警流感。

**发展**：
- 通过分析流感相关关键词的搜索，创建流感图表和地图，预测全球超过25个国家的流感趋势。
- 谷歌流感趋势比传统流感监测系统提前7～14天预测流感爆发。

**特点**：
- 利用谷歌搜索数据，实时估测全球流感疫情。
- 搜索流感相关主题的人数与实际患病人数之间存在密切关系。

**成就**：
- 谷歌流感趋势预测结果与传统监测数据非常接近，逐渐受到美国官方健康组织的认可。

### 7.3.2 其他案例

- **卡斯豪特教授**：提出用社交网络追踪疾病的构想，通过分析Facebook状态预测疾病传播。
- **BioCaster**：日本国家信息研究所开发的疾病预警网站，利用文本挖掘算法监视疾病传播。
- **Sickweather**：通过分析社交网络状态，预测全球范围内的疾病传播情况。

### 7.3.3 思维启示

**启示一：大数据傲慢**：
- 大数据不能完全取代传统数据收集方法，需将大数据结果与传统方法结果互相验证。
- 谷歌流感趋势因算法变化和搜索推荐导致预测失真，需对原始数据进行清洗，确定真正可用的数据。

**启示二：大数据时代的科学伦理问题**：
- 大数据时代带来隐私问题，需重视科技伦理，保障人类切身利益，促进社会可持续发展。
- 科技活动必须遵守伦理规范，以弘扬科技的正面效益，遏制其负面影响。

## 7.4 电影票房预测

### 7.4.1 案例详析

**背景**：谷歌通过分析搜索量和其他辅助数据，以94%的准确率预测新电影首映周末票房。

**发展**：
- 研究显示，电影搜索量与票房收入之间存在强关联。
- 谷歌构建线性回归模型，结合电影搜索量、广告点击量、上映影院数量等同系列电影前几部的票房表现，预测票房收入。

**特点**：
- 提前一个月预测票房，利用预告片搜索量提高预测准确性。
- 48%的电影观众在购票当天决定看什么片子，影片推广应持续到首映之后。

### 7.4.2 工作模式

- **数据分类**：将电影搜索分为涉及电影名的搜索和不涉及电影名的搜索。
- **线性回归模型**：建立指标与票房收入的关系，提前一周预测票房准确度达92%，提前一个月预测准确度也很高。

### 7.4.3 思维启示

**简单的就是最好的**：
- 线性模型虽然简单，但已达到很高的准确度，易于理解和分析。
- 大数据分析技术的优势在于从大量数据中挖掘出人们可以理解的规律，加深对行业的理解。

## 7.5 奥斯卡预测

### 7.5.1 案例详析

**背景**：微软研究院的戴维德·罗斯柴尔德通过数据分析预测奥斯卡奖项。

**发展**：
- 戴维德关注投票数据、预测市场数据、基础数据和用户生成数据，建立预测模型。
- 实时更新预测结果，利用历史数据建立模型，确保预测准确性。

**特点**：
- 动态数据挖掘：实时提供最新预测结果，展示变化原因和影响部分。
- 数据相关性：最佳影片奖和最佳改编剧本奖之间存在强烈相关性。

### 7.5.2 思维启示

**大数据可以做预测**：
- 大数据技术通过海量数据挖掘，发掘预后迹象，对未来事态进行预测。
- 大数据的导航作用使得企业在生产过程中能够及时调整，提高效率。


# 第8章 决策支持

## 8.1 《纸牌屋》

### 8.1.1 案例详析

**背景**：
《纸牌屋》是Netflix出品并播放的一部政治剧，改编自同名小说和英国迷你剧，讲述一个美国国会议员及其妻子在华盛顿高层“运作权力”的故事。该剧由大卫·芬奇执导，凯文·史派西主演，一经播出便在全球40多个国家成为最热门的在线剧集。

**Netflix简介**：
Netflix是一家在线影片租赁提供商，提供超大数量的DVD和流媒体服务，用户可以通过多种设备收看电影和电视节目。Netflix不仅连续五次被评为顾客最满意的网站，还是全球最大的流媒体运营商，其用户数超越了HBO电视网。

**成功与影响**：
《纸牌屋》的成功让Netflix在一季度新增超过300万流媒体用户，股价飙升至每股217美元，较上年低谷价格累计涨幅超3倍。这一成功让全球文化产业界意识到大数据的力量。

### 8.1.2 大数据的运用方式

**用户行为数据**：
Netflix拥有2700万美国订阅用户和3300万全球用户，记录了用户每天的3000万个行为（如暂停、回放、快进）、400万个评分和300万次搜索请求。这些数据帮助Netflix了解用户的喜好和口味。

**数据驱动决策**：
《纸牌屋》的数据库包含了3000万个用户的收视选择、400万条评论和300万次主题搜索。通过分析这些数据，Netflix决定了拍什么、谁来拍、谁来演和怎么播，实现了由用户需求决定生产的C2B模式。

### 8.1.3 思维启示

#### 8.1.3.1 启示一：大数据下更注重个性化

**个性化广告推送**：
大数据技术的预判功能使企业能够通过对大数据的解构，提供个性化、智能化的广告推送和服务推广，抢占更大的商业空间。

**消费者行为变化**：
社交媒体的兴起改变了消费者对广告的依赖方式，传统的广告和营销手法难以奏效。星巴克通过社交媒体进行精准营销，维护老顾客，通过口碑实现新顾客的增长。

**隐私问题**：
社交媒体对大数据的解构带来隐私问题。用户的信息被记录并用于推荐资源和广告，随着大数据技术的进步，这一问题变得更加突出。

#### 8.1.3.2 启示二：大数据推动变革的产生

**播出方式变革**：
《纸牌屋》一次性播放13集，改变了以往美剧逐周更新的模式。Netflix通过大数据观测到越来越多的人倾向于攒剧集一次性观看，因此采取了这种播出方式并获得巨大成功。

#### 8.1.3.3 启示三：如何运用数据科学这个工具

**导航仪**：
大数据是导航仪，基于海量数据的分析比传统抽样调查更具导航性。通过分析数千万观众的喜好，Netflix实现了从受众洞察到受众转化的每一步数据引导。

**显微镜**：
大数据是显微镜，让人洞悉网络营销的每一个细微状况，掌握传统数据手段无法洞察的业务细节。前期数据分析是《纸牌屋》成功的充分条件。

**纠错器**：
大数据是纠错器，可以实时发现营销过程中存在的问题，及时调整策略，提高营销效率。数据与业务形成不断循环、反哺，提升广告投入的效率。

**发动机**：
大数据是发动机，推动互联网成为用户不断转化的平台。数据驱动的精准营销引擎将颠覆传统的营销决策模式及营销执行过程，带来革命性冲击。

## 8.2 美国总统大选

### 8.2.1 案例详析

**背景**：
2012年，美国总统奥巴马成功击败对手罗姆尼，再次赢得选举。《时代》杂志撰文描述了奥巴马获胜背后的秘密——数据挖掘。奥巴马团队通过数据挖掘技术，实现了对选民的“微观”认知，制定了精准的竞选策略，赢得了大量草根阶层选民的支持和捐赠。

### 8.2.2 大数据的运用方式

**数据驱动的竞选**：
奥巴马团队重新建立了新式数据库，增加了大量来自Web追踪和社交媒体网站的新数据。通过18个月的数据处理，他们搞清了如何在海量非结构化数据中找到不同的利用模式，知道以哪些区域为目标、哪些信息能吸引特定选民群体、在哪里花钱效果更好等。

**精准广告投放**：
奥巴马团队通过复杂建模找到目标选民，在一些非传统节目中购买广告，例如《混乱之子》《行尸走肉》等，提高了广告购买率。

**个性化动员**：
对于不同的用户，奥巴马团队采取不同的动员渠道和互动方式。例如，在社交新闻网站Reddit上回答问题，利用Facebook进行大规模投票动员，通过志愿者电话动员等。

**人口特性分析系统**：
丹·瓦格纳建立了人口特性分析系统，根据选民是否会投票、是否会投给奥巴马，为每个选民打分。通过这个系统，奥巴马团队能够更准确地预测选民行为，并采取相应措施改变他们的选择。

### 8.2.3 思维启示

#### 8.2.3.1 启示一：数据由人创造，反映人的行为和心理

**数据分析的效果**：
奥巴马团队通过数据分析，精确地将竞选经费用到正确的地方，以更少的经费获得了胜利。商业上，以数据分析为支撑的决策同样能带来巨大利益。例如，Tesco通过用户行为分析，设计个性化服务，节省了大量市场宣传费用。

**个性化互动**：
沃尔玛通过Shoppycat应用，分析用户朋友的信息，推荐生日礼物，实现了个性化互动，提高了用户满意度。

#### 8.2.3.2 启示二：数据挖掘之前一定要做好充足准备

**数据收集和整理**：
奥巴马数据团队在竞选前两年开始收集大量信息，将民主党所有独立零散的选民数据库汇总在一起。企业在进行数据挖掘前，也需将分散的数据进行集中存储和格式清理。

**精准建模**：
数据挖掘需要与实际业务相定制，每一组数据都有独特的数据模型。奥巴马团队对每一个群体的选民进行建模，预测他们的捐款行为方式。

**动态调整模型**：
用户行为规律的变化会影响模型的精准性，因此需要随时动态调整模型。奥巴马团队在关键“摇摆州”获得了大量选民的投票倾向数据，能够准确了解选民态度，并及时调整竞选策略。


# 第9章 模式创新

## 9.1 大数据与反恐

### 9.1.1 美国“棱镜”计划

**背景与实施**：

- **棱镜计划**：2013年6月6日，美国国家安全局（NSA）和联邦调查局（FBI）通过进入各大网络运营商的服务器，监控普通民众的电子邮件、聊天记录、视频及照片等秘密资料。该项目被称为“棱镜”。
- **曝光过程**：
  - 2013年6月5日，英国《卫报》披露，美国国家安全局要求电信巨头威瑞森公司每天上交数百万用户的通话记录。
  - 2013年6月6日，美国《华盛顿邮报》披露，NSA和FBI通过进入微软、谷歌、苹果、雅虎等九大网络巨头的服务器，监控美国公民的秘密资料。

**监控范围与数据**：

- **监控对象**：任何在美国以外地区使用参与计划公司服务的客户，或是任何与国外人士通信的美国公民。
- **数据类型**：电子邮件、视频和语音交谈、影片、照片、VoIP交谈内容、档案传输、登入通知，以及社交网络细节。
- **使用情况**：综合情报文件“总统每日简报”在2012年内于1477个计划中使用了来自棱镜计划的资料。

### 9.1.2 加拿大的“棱镜门”

**背景与实施**：

- **类似计划**：早在2005年，加拿大国防部开始秘密实施了一项类似于“棱镜”的情报窃取项目。
- **公开反应**：
  - 加拿大国防部长表示，项目收集的只是信息来源的“元数据”，不会侵犯个人隐私。
  - 媒体报道称，这一窃听项目并不直接读取窃取的信息内容，只是收集信息来源的“元数据”。

**国际合作**：

- **合作监控**：英国政府的通信监控部门与美国国家安全局、加拿大通信安全局合作密切，英国至少三年前就加入了“棱镜”项目。

### 9.1.3 思维启示

#### 启示一：大数据时代如何保护隐私安全

- **隐私权的挑战**：在Web 2.0时代，隐私权逐渐被剥夺。大数据时代，如何保护个人隐私安全成为一个亟待解决的问题。
- **保护措施**：
  - **技术手段**：通过技术手段保护数据安全。
  - **法律手段**：通过立法保护个人隐私。
  - **道德建设**：加强道德建设，提高隐私保护意识。

#### 启示二：大数据带来的伦理忧思

- **伦理问题**：大数据带来的究竟是天堂还是地狱？“棱镜门”事件引发了公众对大数据的恐慌，人们害怕成为没有隐私的“透明人”。
- **规则建立**：大数据作为一种基础设施，必须建立自己的规则，对掌握大数据的人要有所约束。
- **商业应用**：广告营销是大数据应用最广泛的领域，通过消费者的购买记录、浏览记录提炼出用户性别、年龄和爱好，然后对消费者进行广告推送营销。
- **政治应用**：大数据在政治领域的应用引发了伦理争议，传统的政治伦理正在被颠覆。

## 9.2 利用大数据打击犯罪

### 9.2.1 “先知”系统

**背景与实施**：

- **背景**：美国洛杉矶因警员比例过低，一直是全美犯罪率最高的地区之一。
- **系统开发**：2012年，洛杉矶警察局与加州大学联合开发了一套类似“先知”的计算器系统。
- **工作原理**：
  - **数据分析**：通过分析过去的1300多万起案件，找到发案与日期、天气、交通状况以及其他相关事件之间的关系。
  - **预测模型**：参考地震预测模型，预测未来数小时内可能发生案件的区域。

**效果**：

- **测试结果**：在测试期间，系统预测与历史数据吻合良好。
- **实际应用**：警察们按照计算器发出的巡逻指令前往不同区域，使该地区财产犯罪下降了12%，盗窃案件下降了26%。

### 9.2.2 “犯罪数据分析和趋势预测系统”

**背景与实施**：

- **背景**：2013年起，北京怀柔警方开始使用“犯罪数据分析和趋势预测系统”。
- **数据来源**：收录了怀柔近9年来1.6万余件犯罪案件数据。
- **工作原理**：
  - **预测模型**：通过数学专家建立的多种预测模型，自动预测未来某段时间、某个区域可能发生犯罪的概率以及犯罪的种类。
  - **巡逻防控**：根据预测结果，加强对重点地区的巡逻防范工作。

**效果**：

- **实际应用**：分局情报信息中心要求派出所针对预测案发地加大巡逻防控工作，抓获嫌疑人。
- **统计结果**：2013年的1—5月，怀柔区接报110刑事和秩序类警情同比下降27.9%，其中抢劫案下降了近55%。

## 9.3 大数据与破案

### 9.3.1 《源代码》

**背景与实施**：

- **电影背景**：《源代码》是一部由邓肯·琼斯执导，杰克·吉伦哈尔、维拉·法米加、米歇尔·莫娜汉等人联袂出演的影片。
- **剧情简介**：
  - **任务背景**：柯尔特·斯蒂文斯上尉被选中执行一项特殊任务，利用“源代码”项目反复“穿越”到一名在列车爆炸案中遇害的死者身体里，每次只能回到爆炸前最后的8分钟。
  - **任务目标**：在“源代码”中一次次地“穿越”收集线索，在爆炸前最后的8分钟里寻找到元凶，避免更大规模的恐怖行动。

**数据科学应用**：

- **数据模拟**：科学家们利用收集来的数据创造了一个虚拟的平行空间，利用数据模拟了空间和时间的运行。
- **数据分析**：通过对大量数据的分析和寻找，柯尔特上尉得以在虚拟时空中找寻线索。

## 9.4 大数据的其他运用方式

### 9.4.1 大数据与纽约沙井盖维护

**背景与实施**：

- **问题背景**：纽约每年会发生许多起因内部失火而造成的沙井盖爆炸。
- **解决方案**：2007年，联合爱迪生电力公司向哥伦比亚大学的统计学家求助，希望通过历史数据研究预测出可能会出现问题并且需要维修的沙井盖。

**数据分析与应用**：

- **数据整理**：统计学家鲁丁和她的同事整理了1880年以来由会计人员或整修人员手动记录的数据。
- **预警情况**：发现了大型沙井盖爆炸的106种预警情况。
- **预测效果**：在布朗克斯的电网测试中，列出的前10%的高危沙井盖名单里，有44%发生了严重的事故。

**关键因素**：

- **决定性因素**：电缆的使用年限和是否出现过问题是两个决定性因素。
- **维修排序**：基于此，联合爱迪生电力公司可以迅速进行沙井盖事故的可能性排序。

### 9.4.2 大数据帮助寻根问祖

**背景与实施**：

- **公司背景**：成立于1983年的“家谱网”(Ancestry.com)通过庞大数据库帮助人们寻根问祖。
- **数据来源**：
  - **美国市场**：拥有1790—2000年的美国人口普查数据，各种移民记录、军队服役记录，旧报纸和杂志上的个人资料。
  - **英国市场**：可以追溯到13世纪剑桥大学的同学录。

**用户服务**：

- **用户分类**：
  - **免费用户**：可以建立、扩大和分享家庭树，上传照片、文档以及家族故事。
  - **付费用户**：可以获得家族寻根的提醒服务，查阅和搜索珍贵记录资料。
- **收入模式**：
  - **美国本土资料用户**：年费155.4美元。
  - **全世界资料用户**：年费299美元。

**技术与创新**：

- **故事浏览功能**：汇总容量达4PB的资源库，包括官方人事档案、用户提交信息以及由计算机生成的定制摘要信息。
- **图文转换工具**：将手写扫描图像转化为可供搜索的文本内容，提高信息汇总的精细水平。

**商业前景**：

- **企业用户价值**：个人数据对企业用户价值千金，使企业的宣传销售更有针对性，同时能更好地提供个性化服务。
- **合作开发**：与Narrative Science公司合作，生成可供阅读的生平回顾，提高信息的可读性和互动性。


# 第10章 数据密集型研究方法

## 10.1 范式和范式的演化过程

### 10.1.1 范式的定义

**范式**（Paradigm）是由美国科学哲学家托马斯·库恩在《科学革命的结构》中提出的概念，意指“模范”或“模型”。库恩认为范式是科学共同体共同遵从的理论基础和实践规范，包括基本理论、观念、方法、信念和自然观。范式在本体论、认识论和方法论三个层次上表现出对事物存在、知者与被知者关系以及研究方法的基本承诺。

### 10.1.2 范式的演变过程

范式的演变过程包括以下几个阶段：

1. **前学科时期**：没有共同接受的范式，科学家之间存在意见分歧。
2. **常规科学时期**：一种范式得到大多数科学家的支持，形成公认的范式。
3. **科学革命时期**：新问题和新事物动摇原有范式，导致范式转移。
4. **新常规科学时期**：新范式取代旧范式，建立新的科学共同体。

#### 10.1.2.1 经验范式

经验范式偏重于经验事实的描述和明确具体的实用性研究，以归纳为主，通过观察、假设和实验进行研究。经典范例包括伽利略的“两个铁球同时落地”实验。

#### 10.1.2.2 理论范式

理论范式偏重理论总结和理性概括，以演绎法为主，不局限于描述经验事实。经典范例包括数学中的集合论、物理学中的相对论、经济学中的博弈论等。

#### 10.1.2.3 模拟范式

模拟范式利用计算机进行数据模型构建和定量分析，主要用于数值模拟、模型拟合与数据分析、计算优化等问题。经典范例包括人工智能、热力学和分子问题、信号系统等。

#### 10.1.2.4 数据密集型研究范式

数据密集型研究范式是以数据考察为基础，联合理论、试验和模拟为一体的数据密集计算范式。它依靠工具获取或模拟产生数据，利用计算机软件处理和存储数据，并通过数据管理和统计工具分析数据。

## 10.2 第四范式兴起的社会根源

### 10.2.1 数据洪流的到来

新型硬件与数据中心、分布式计算、云计算、大容量数据存储与处理技术、社会化网络、移动终端设备、多样化的数据采集方式使海量数据的产生和记录成为可能。

### 10.2.2 科学界对海量数据的关注

科学观察、试验和研究设备的进化、计算机辅助技术的发展以及大规模合作的科学态势，使科学数据呈海量增长。科学界开始重点关注海量数据对科学研究的影响。

### 10.2.3 关联数据运动

互联网之父伯纳斯·李提出了关联数据的概念，强调数据互联而非文件互联。关联数据方法提出后受到广泛响应，形成了巨大的关联数据网络。

### 10.2.4 政府数据开放运动

各国政府积极开展数据开放工作，提供计算机可读和可处理的数据集，促进政府信息透明和公众参与，激发创新，实现资源价值。

## 10.3 对第四范式的分析

### 10.3.1 科学数据与科学研究的问题

1. **数据方面的问题**：
   - 缺少合理的数据保存、共享和重用制度保障。
   - 数据爆炸，大量新科学数据被全天候获取。
   - 缺乏有效的数据工具，对数据管理、分类、分析、挖掘的工具依旧缺乏。

2. **科学交流方面的问题**：
   - 科学交流模式未能发掘数据的原始价值，需要完善科学交流体系。

### 10.3.2 解决方案

1. 建立完整的采集、存储、管理、分析、发布链条。
2. 建立试验室数据管理系统，形成长期的数据存档和追根溯源机制。
3. 建立数据挖掘和分析的专门机构。
4. 开发数据捕获、分类管理和分析挖掘的新算法和工具。
5. 开发新型文献及数据出版和发布工具，支持快速变革。
6. 建立支持数据交流、发布、随处响应的基础设施。
7. 建立融数据和文献于一体的新型数字图书馆。
8. 制定国家政策，促进信息和数据的接入和重用。
9. 培育数据科学家，展开高质量的数据管理和分析。

## 10.4 数据科学研究的一般流程

数据科学研究从现实世界入手，收集原始数据，进行预处理，开展探索性数据分析，建立数据模型，解读数据并实现可视化展示，生成数据报告或构建数据产品。数据产品会产生更多数据，与现实世界互动，形成循环。

1. **数据收集**：收集原始数据，如网页浏览日志、体育活动记录、电子邮件原件等。
2. **数据预处理**：对原始数据进行清理，得到规整而干净的数据。
3. **探索性数据分析**：分析数据，确定是否需要重新收集或预处理数据。
4. **数据建模**：运用k-NN、线性回归、贝叶斯算法等建立数据模型。
5. **数据解读与可视化**：实现数据可视化展示，生成数据报告或交流研究心得。
6. **构建数据产品**：如搜索评级算法、推荐系统等，数据产品会产生更多数据，与现实世界互动，形成循环。


# 第11章 数据的获取和预处理

## 11.1 数据的获取

要研究数据科学，首先需要获取数据。在研究数据获取之前，先区分两个概念：数据的类型和数据的语义。

- **数据的语义**：指数据项在现实世界中的意义。例如，某公司的名称、某天、某个人的高度等。
- **数据的类型**：表征在该类数据上可执行的操作类型。

### 11.1.1 数据的类型

1996年，马里兰大学教授本·施奈德曼将数据分为以下七类：

1. 一维数据(1-D)
2. 二维数据(2-D)
3. 三维数据(3-D)
4. 多维数据(n-D)
5. 时态数据(Temporal)
6. 层次数据(Hierarchical)
7. 网络数据(Network)

在本书中，参考1946年史丹利·史密斯·史蒂文斯发表的《On the Theory of Scales of Measurement》一文，将数据分为四种类型：

1. **分类型数据(Categorical data)**：只关注是否存在相等或不等的情况，可运行的数学操作为求解=或≠。
2. **排序型数据(Ordinal data)**：存在排序关系，可运行的数据操作为=、≠、>、<。
3. **区间型数据(Interval data)**：定量性数据，可运行的数据操作为=、≠、>、<、+、-。
4. **比值型数据(Ratio data)**：测量产生的结果，属于定量性数据，可运行的数据操作为=、≠、>、<、+、-、*、÷。

区间型数据和比值型数据通常统称为定量型数据(Quantitative Data)。

#### 示例：订单数据分析

分析图11-1中的订单数据，区分数据的语义和类型：

- **订单号**：分类型数据
- **订单日期**：区间型数据
- **订单优先级别**：排序型数据
- **产品包装**：排序型数据
- **产品折扣**：比值型数据
- **运输日期**：区间型数据

### 11.1.2 网络爬虫技术

#### 11.1.2.1 概述

网络爬虫是一种按照一定规则自动抓取互联网信息的程序或脚本。一个通用的网络爬虫框架如图11-3所示。

![图11-3 通用的网络爬虫框架](图11-3.png)

互联网上的网页可以分为五个部分：

1. 已下载未过期网页
2. 已下载已过期网页
3. 待下载网页
4. 可知网页
5. 不可知网页

#### 11.1.2.2 抓取策略

1. **深度优先遍历策略**：从起始网页开始，选择一个URL进入，分析网页中的URL，逐层深入抓取。
2. **宽度优先遍历策略**：在完成当前层次的搜索后，再进行下一层次的搜索。
3. **反向链接数策略**：根据网页被其他网页链接指向的数量评价网页的重要程度。
4. **Partial PageRank策略**：计算每个页面的PageRank值，按值大小排列抓取顺序。
5. **大站优先策略**：根据所属网站分类，优先下载页面数多的网站。

#### 11.1.2.3 更新策略

1. **历史参考策略**：根据页面以往的历史更新数据预测未来更新时间。
2. **用户体验策略**：优先更新查询结果前几页的网页。
3. **聚类抽样策略**：对类似属性的网页进行抽样，以它们的更新周期作为整个类别的更新周期。

#### 11.1.2.4 分布式抓取系统

分布式抓取系统通常是一个分布式的三层结构：

1. **主从式(Master-Slave)**：Master服务器维护待抓取URL队列，分发URL给Slave服务器。
2. **对等式(Peer to Peer)**：所有抓取服务器分工相同，通过哈希值确定URL抓取主机。

#### 11.1.2.5 开源网络爬虫

1. **Heritrix**：获取完整精确的网站内容，不修改网页内容。
2. **Nutch**：深度遍历网站资源，保存可索引的内容。
3. **Larbin**：只抓取网页，不提供分析、存储和索引服务。
4. **Lucene**：基于Java的全文信息检索工具包，用于索引和搜索。

## 11.2 数据预处理的目的

数据预处理是数据处理过程中非常重要的一步，可能占整个数据处理流程中80%的时间。预处理的目的是提供干净、准确、简洁的数据，提高数据挖掘的效率和准确性。

原始数据中存在以下问题：

1. **杂乱性**：数据缺乏统一的标准和定义。
2. **重复性**：同一事物在数据库中存在多条完全相同的记录。
3. **不完整性**：属性值缺失或不确定。
4. **存在噪声**：测量变量中的随机错误或偏离期望的孤立点值。

数据预处理的主要任务包括：

1. **数据清理**：填写空缺值、平滑噪声数据、识别删除孤立点、解决数据中的不一致性问题。
2. **数据集成**：集成多个来源不同的数据库、数据立方或文件。
3. **数据变换**：对原始数据进行规范化和聚集操作。
4. **数据规约**：通过操作得到数据集的压缩表示。

## 11.3 数据清洗

数据清洗的主要任务是对原始数据进行处理，将“脏”数据转化为“干净的”数据。主要任务包括：

1. 填补空缺值
2. 平滑噪声数据
3. 纠正不一致数据
4. 消除冗余数据

### 11.3.1 填补空缺值

填补空缺值的方法：

1. **直接忽略存在属性缺失的元组**
2. **人工方式填写空缺值**
3. **自动填充空缺值**：使用全局变量、属性的平均值、回归、判定树等方法推断空缺值。

### 11.3.2 平滑噪声数据

#### 11.3.2.1 分箱法处理噪声数据

分箱法将数据按照一定规则放进一些箱子中，考察每个箱子中的数据并平滑处理。

**分箱方法**：

1. **等深分箱法**：每个箱子包含相同数量的样本。
2. **等宽分箱法**：每个箱子的区间范围相同。
3. **用户自定义区间法**：根据用户需要自定义区间。

**平滑处理方法**：

1. **按箱平均值平滑处理**：用箱中数据的平均值代替所有数据。
2. **按箱边界平滑处理**：用距离数据最近的边界值代替数据。
3. **按箱中值平滑处理**：用箱中数据的中值代替所有数据。

#### 11.3.2.2 其他平滑噪声数据的方法

1. **聚类方法**：将相似的值组织成群，孤立点视为噪声数据。
2. **回归法**：利用拟合函数平滑数据，如线性回归、非线性回归。

## 11.4 数据集成

数据集成是将多个数据源中的数据结合起来存放在一个一致的数据存储中。需要考虑多信息源的匹配、数据冗余、数据值冲突等问题。

### 11.4.1 多信息源的匹配

识别不同信息源中的现实世界实体并进行匹配，避免数据集成中的错误。

### 11.4.2 冗余数据的处理

冗余数据是指重复存在的数据，主要包括属性冗余和命名不一致导致的冗余。发现冗余问题的方法包括相关性分析，如卡方检验法。

## 11.5 数据变换

数据变换通过变换将数据转换成适合处理和分析的形式，包括以下内容：

1. **平滑**：去除数据中的噪声。
2. **聚集**：对数据进行汇总和聚集。
3. **数据概化**：使用概念分层，用更高层次的概念取代低层次数据。
4. **规范化**：将数据按比例缩放，使之落入一个小的特定区间。
5. **属性构造**：构造添加新的属性，提高数据处理和分析的精度。

### 11.5.1 数据规范化

常用规范化方法：

1. **最小一最大规范化**：将数据线性变换到指定区间。
2. **零—均值规范化**：基于平均值和标准差进行规范。
3. **小数定标规范化**：通过移动属性值小数点位置进行规范化。

## 11.6 数据归约

数据归约技术能够从原有庞大数据集中获得一个精简的数据集合，保持原有数据集的完整性，提高数据挖掘的效率。

### 11.6.1 数据立方体聚集

数据立方体是一类多维矩阵，让用户从多个角度探索和分析数据集。通过对数据立方体的聚集操作，可以实现数据归约。

### 11.6.2 维归约

维归约通过删除不相关的属性减少数据量，包括属性子集选择和主成分分析法。

#### 11.6.2.1 属性子集选择

从初始属性集中选择一个属性子集，常用的方法有：

1. **逐步向前选择**
2. **逐步向后删除**
3. **向前选择与向后删除的结合**
4. **决策树归纳**

#### 11.6.2.2 主成分分析

主成分分析通过正交变换将一组可能存在相关性的变量转换为一组线性不相关的变量，保留原始变量绝大多数信息，减少变量个数。

### 11.6.3 特征值归约

特征值归约将连续型特征的值离散化，使之成为少量的区间，每个区间映射到一个离散符号。特征值归约方法包括：

1. **有参数方法**：回归、对数线性模型
2. **无参数方法**：直方图、聚类、抽样


# 第12章 数据的存储与管理

## 12.1 数据的存储

### 12.1.1 数据存储的发展

数据存储的历史可以追溯到1725年法国纺织机械师布乔提出的“穿孔纸带”构想，该构想用于控制编织机，将编织图案的程序储存在穿孔纸带的小孔中。以下是数据存储媒介的重要发展历程：

1. **打孔纸卡**：
   - 1884年，赫尔曼·霍尔瑞斯申请了打孔纸卡的专利，用于数据存储，直到20世纪70年代中期。

2. **穿孔纸带**：
   - 1846年，亚历山大·拜恩最早使用穿孔纸带作为存储设备，纸带上每一行代表一个字符，容量比打孔纸卡大。

3. **计数电子管**：
   - 1946年，RCA公司研究用于早期电子管计算机的计数电子管，一个10英寸的管子能保存4096比特的数据，但因价格昂贵而迅速消失。

4. **盘式磁带**：
   - 20世纪50年代，IBM将盘式磁带用于数据存储，一卷磁带可代替1万张打孔纸卡，直到20世纪80年代前一直广泛使用。

5. **盒式录音磁带**：
   - 1963年飞利浦公司发明，20世纪70年代开始流行，用于一些计算机的数据存储。

6. **磁鼓**：
   - 12英寸长，每分钟转12500转，用于IBM 650系列计算机的主存储器，每支可保存不到10 KB的数据。

7. **软盘**：
   - 1969年发明8英寸软盘，可保存80 KB的只读数据；1973年推出256 KB的可读写软盘，容量和尺寸不断减小，直到20世纪90年代后期达到250 MB的3.5英寸软盘。

8. **硬盘**：
   - 1956年IBM发布305 RAMAC硬盘机，存储容量为4.4 MB；现代硬盘如日立Deskstar 7K500硬盘容量达到500 GB。

9. **光盘**：
   - 1958年发明，1972年第一张视频光盘问世，1978年LD光盘开始销售；1979年SONY和飞利浦联合发布5英寸光盘，1982年上市，容量为700 MB。

10. **DVD光盘**：
    - 采用780 nm的红外激光技术，容量可达8.5 GB。

### 12.1.2 大数据对存储带来的挑战

大数据时代的来临，给数据存储带来了新的挑战：

1. **容量问题**：
   - 海量数据存储系统需要简便的扩展能力，如通过增加模块或磁盘柜来增加容量。

2. **延迟问题**：
   - 大数据应用需要实时性，特别是涉及网上交易或金融类应用，要求高速吞吐。

3. **安全问题**：
   - 金融数据、医疗信息及政府情报等特殊行业有严格的安全标准和保密性需求，大数据分析催生新的安全性问题。

4. **成本问题**：
   - 成本控制是使用大数据环境的企业要考虑的核心问题，需提升每一台设备的效率，减少昂贵部件的使用。

5. **数据的积累**：
   - 数据的分析大都是基于时间段进行的，需保证数据长期保存，实现数据一致性检测功能，具备原位更新功能。

6. **灵活性**：
   - 大数据存储系统的基础设施规模大，但应用千变万化，要求存储能力能够随应用分析软件一起扩展。

7. **应用感知**：
   - 针对应用定制的基础存储设施越来越普遍，改善系统效率和性能。

8. **针对小用户**：
   - 小企业和个人也有大数据应用需求，如何吸引这部分群体是一个挑战。

### 12.1.3 云存储方式

云存储是一种新型的云状结构的存储系统，由多个存储设备组成，通过集群功能、分布式文件系统或类似网格计算等功能联合工作，提供存储服务和访问服务。

**云存储的优点**：

1. **可扩容能力强**：
   - 并行扩容，容量几乎无限制。

2. **易于管理**：
   - 数据迁移到云存储后，升级维护任务由云存储服务提供商完成，节约企业成本。

3. **成本低廉**：
   - 企业花很少的钱获得最优的数据存储服务。

4. **可以实现量身定制**：
   - 针对私有云，云服务提供商为企业客户提供量身定制的云存储服务方案。

## 12.2 数据的管理

### 12.2.1 数据管理的发展阶段

数据管理经历了三个阶段：人工管理阶段、文件系统阶段和数据库管理系统阶段。

#### 12.2.1.1 人工管理阶段

20世纪50年代中期以前，数据管理处于人工管理阶段：

1. **数据不保存**：计算机主要用于科学计算，对数据保存需求不迫切。
2. **应用程序管理数据**：每个应用程序包括数据的存储结构、存取方法和输入方法等，程序员负担重。
3. **数据不共享**：数据面向程序，一组数据只能对应一个程序。
4. **数据不独立**：程序依赖于数据，数据变化需修改应用程序。

#### 12.2.1.2 文件系统阶段

20世纪50年代后期到60年代中期，数据管理进入文件系统阶段：

1. **数据长期保留**：数据可以长期保留在外部存储器上反复处理。
2. **程序与数据独立**：数据的改变不一定要引起程序的改变，利用文件系统进行专门的数据管理。
3. **实时处理**：直接存取设备和索引文件、链接存取文件、直接存取文件等支持实时处理。

**问题**：

1. **编写应用程序不方便**：程序员需记住文件的组织形式和内容。
2. **数据冗余大**：每个应用程序有对应的文件，数据重复存储。
3. **易造成不一致性**：更新操作时，数据在不同文件中不一致。
4. **数据独立性差**：存储文件的逻辑结构或物理结构变化需修改程序。
5. **不支持并发访问**。
6. **数据间联系弱**。
7. **难以按用户需求表示数据**。
8. **安全控制功能差**。

#### 12.2.1.3 数据库管理系统阶段

20世纪60年代后期开始，数据管理进入数据库管理系统阶段：

1. **数据结构化**：描述数据及其联系，集成相互关联的数据。
2. **数据共享**：数据面向整个应用系统。
3. **降低数据冗余**。
4. **数据独立**：数据与应用程序相互独立。
5. **保证安全可靠性和正确性**：通过数据完整性控制、安全性控制、并发控制和备份与恢复策略。
6. **方便用户接口**：用户可以使用查询语言或终端命令操作数据库。

### 12.2.2 大数据时代数据管理的特点

大数据时代，数据量巨大，结构复杂多样，数据产生速率快，实时性要求高，价值密度低，数据存疑。传统数据库管理系统难以满足需求，需新的数据管理方式。

**传统关系型数据库的瓶颈**：

1. **二维表格数据模型不能有效处理多维数据**：不能有效处理半结构化和非结构化的海量数据。
2. **高并发，读写性能低**：关系数据库达到一定规模时，易发生死锁等并发问题，读写性能下降。
3. **支撑容量有限**：处理海量数据时效率低下。
4. **可扩展性和可用性低**：难以通过添加硬件和服务节点扩展性能和负载能力。
5. **建设和运行维护成本高**：企业级关系数据库价格高，且随系统规模增大而上升。

### 12.2.3 非关系型数据

非关系型数据库(NoSQL)是一种与关系型数据库不同的数据库管理系统，数据存储格式松散，易于横向扩展。

**NoSQL的优势**：

1. **易扩展**：数据之间无关系，容易扩展。
2. **大数据量，高性能**：具有非常高的读写性能，尤其在大数据量下表现优秀。
3. **灵活的数据模型**：无须事先为数据建立字段，随时存储自定义的数据格式。
4. **高可用性**：在不太影响性能的情况下，实现高可用架构。

### 12.2.4 开源的NoSQL数据库软件

#### 12.2.4.1 Membase

Membase是NoSQL家族的新成员，开源项目，采用Apache2.0许可。由North Scale的Memcached核心团队开发，Zynga和NHN为主要贡献者。

**特点**：

1. **易安装、操作**：从单节点方便扩展到集群，兼容Memcached有线协议。
2. **复用性**：兼容多种编程语言和框架，提供图形化界面和编程接口。
3. **线性扩展能力**：自动将在线数据迁移到低延迟存储介质，支持异步、同步写操作，动态再平衡现有集群。

#### 12.2.4.2 MongoDB

MongoDB介于关系数据库和非关系数据库之间，支持松散的数据结构，类似Json的Bjson格式。

**主要功能特性**：

1. **面向集合存储**：数据分组存储在集合中，每个集合有唯一标识名，可包含无限数目的文档。
2. **模式自由**：无需知道文件的任何结构定义，可存储不同结构的文件。
3. **支持动态查询、完全索引、复制和故障恢复**。
4. **高效存储大型对象**：使用二进制数据存储，支持自动处理碎片。
5. **多语言支持**：支持Ruby, Python, Java, C++, Php等多种语言。

#### 12.2.4.3 Hypertable

Hypertable是一个开源、高性能、可伸缩的数据库，采用与谷歌Bigtable相似的模型。

**关键基础设施**：

1. **Google File System(GFS)**：高可用性文件系统，提供全局命名空间。
2. **MapReduce**：计算框架，与GFS紧密协作，处理海量数据。
3. **Bigtable**：传统数据库的替代，通过主键组织海量数据，实现高效查询。

#### 12.2.4.4 Apache Cassandra

Apache Cassandra是一套开源分布式Key-Value存储系统，最初由Facebook开发，用于储存大数据。

**主要特性**：

1. **分布式**：由一堆数据库节点构成分布式网络服务，扩展性能简单。
2. **基于Column的结构化**。
3. **高伸展性**。


# 第13章 数据的处理

## 13.1 Hadoop

在大数据时代，需要解决大量数据和异构数据带来的数据处理难题。Hadoop是一个分布式系统基础架构，由Apache基金会开发，用户可以在不了解分布式底层细节的情况下开发分布式程序，充分利用集群的威力进行高速运算和存储。

### 13.1.1 Hadoop的起源

#### 13.1.1.1 项目起源

Hadoop由Apache Software Foundation于2005年秋作为Lucene的子项目Nutch的一部分正式引入，受到Google Lab开发的MapReduce和Google File System (GFS)的启发。2006年3月，MapReduce和Nutch Distributed File System (NDFS)被纳入Hadoop项目中。Hadoop是互联网上对搜索关键字进行内容分类的热门工具，能解决许多具有极大伸缩性的问题。

#### 13.1.1.2 名字起源

Hadoop的名字是一个虚构的名字，由项目创建者道格·卡廷的孩子给一个棕黄色的大象玩具起的名字。命名标准是简短、容易发音和拼写，没有太多的意义，并且不会被用于别处。

### 13.1.2 优点

Hadoop是一个能够对大量数据进行分布式处理的软件框架，具有以下优点：

1. **高可靠性**：按位存储和处理数据。
2. **高扩展性**：在可用的计算机集簇间分配数据并完成计算任务，可以扩展到数以千计的节点。
3. **高效性**：在节点间动态地移动数据，保证各个节点的动态平衡，处理速度非常快。
4. **高容错性**：自动保存数据的多个副本，并自动将失败的任务重新分配。

### 13.1.3 架构

Hadoop由许多元素构成，最底部是HDFS，其上一层是MapReduce引擎，由JobTrackers和TaskTrackers组成。

#### 13.1.3.1 HDFS

HDFS对外部客户机而言像一个传统的分级文件系统，但其架构基于一组特定的节点，包括NameNode和DataNode。文件被分成块并复制到多个计算机中。

#### 13.1.3.2 NameNode

NameNode管理文件系统名称空间和控制外部客户机的访问，决定文件映射到DataNode的复制块上。

#### 13.1.3.3 DataNode

DataNode响应来自HDFS客户机的读写请求，并响应来自NameNode的创建、删除和复制块的命令。

#### 13.1.3.4 文件操作

HDFS主要支持以流的形式访问写入的大型文件。客户机将文件缓存到本地临时存储，然后发送给NameNode和DataNode。

#### 13.1.3.5 Linux集群

Hadoop框架可在单一的Linux平台上使用，但使用存放在机架上的商业服务器才能发挥其力量。这些机架组成一个Hadoop集群，通过集群拓扑知识决定如何在整个集群中分配作业和文件。

### 13.1.4 MapReduce流程

Hadoop最有趣的方面之一是Map and Reduce流程，它受到谷歌开发的启发，用于并行处理大数据集。

1. **Map函数**：接受一组数据并将其转换为一个键/值对列表。
2. **Reduce函数**：接受Map函数生成的列表，然后根据它们的键缩小键—值对列表。

**示例**：

假设输入域是“one small step for man, one giant leap for mankind”，运行Map函数将得出以下键/值对列表：

```
(one,1)(small,1)(step,1)(for,1)(man,1)(one,1)(giant,1)(leap,1)(for,1)(mankind,1)
```

应用Reduce函数后，将得到以下一组键/值对：

```
(one,2)(small,1)(step,1)(for,2)(man,1)(giant,1)(leap,1)(mankind,1)
```

在Hadoop上，MapReduce应用程序由JobTracker控制，TaskTracker负责执行具体的任务。

## 13.2 Spark

### 13.2.1 概述

Spark发源于美国加州大学伯克利分校AMPLab的集群计算平台，2009年由马泰主导编写，2010年开放源码，2013年进入Apache孵化器项目，2014年成为Apache顶级项目之一。Spark立足于内存计算，从多迭代批量处理出发，兼容数据仓库、流处理和图计算等多种计算范式。

### 13.2.2 Spark的特点

Spark的特点可以概括为“轻”“快”“灵”“巧”：

1. **轻**：核心代码只有2万行，利用Scala语言的简洁和丰富表达力，并在容错设计上不打折扣。
2. **快**：对小数据集能达到亚秒级的延迟，对大数据集的迭代机器学习、即席查询、图计算等应用，比基于MapReduce、Hive和Pregel的实现快十倍到百倍。
3. **灵**：提供不同层面的灵活性，支持内存计算、多迭代批量处理、即席查询、流处理和图计算等多种范式。
4. **巧**：借助Hadoop、Hive、Pregel和Scala等项目的优势，实现借势和借力。

### 13.2.3 编程模型

Spark的计算抽象是数据流，带有工作集的数据流，在保证容错的前提下，用内存来承载工作集。Spark程序工作在Spark RDD空间和Scala原生数据空间中。

**主要算子**：

1. **输入算子**：将Scala集合类型或存储中的数据吸入RDD空间，转为RDD。
2. **变换算子**：RDD经过变换算子生成新的RDD。
3. **缓存算子**：将计算的中间结果缓存下来。
4. **行动算子**：输入是RDD，输出是原生数据，触发实际计算。

### 13.2.4 运行和调度

Spark程序由客户端启动，分两个阶段：

1. **记录变换算子序列**：增量构建DAG图。
2. **DAG Scheduler**：将DAG图转化为作业及其任务集。

**依赖描述**：

1. **窄依赖**：父RDD的每一个分区最多被一个子RDD的分区所用。
2. **宽依赖**：子RDD的分区依赖于父RDD的所有分区，通常对应于shuffle类操作。

**调度优化**：

- **流水线优化**：将多个窄依赖的变换算子合并，减少全局barrier和中间结果物化，提高性能。
- **Stage划分**：DAG调度器从当前算子往前回溯依赖图，碰到宽依赖时生成一个Stage，实施流水线优化。

**容错**：

- **窄依赖**：只需重算丢失的父RDD分区。
- **宽依赖**：需要父RDD的所有分区都存在，重算成本高，建议在宽依赖处加检查点。


# 第14章 数据的可视化 - 思维导图大纲

## 14.1 概述
- **定义与意义**
  - 约翰·图基名言：“一幅图画最伟大的价值莫过于它能够使我们实际看到的比我们期望看到的内容丰富得多。”
  - 维基百科定义：“借助于图形化手段，清晰有效地传达与沟通信息。”
- **可视化的优势**
  - 简单清晰
  - 发现规律
- **数据可视化的分类**
  - **科学可视化**
    - 关注三维现象的可视化
    - 应用于建筑学、气象学、医学或生物学领域
    - 重点在于逼真渲染
  - **信息可视化**
    - 研究大规模非数值型信息资源的视觉呈现
    - 利用图形图像技术与方法帮助理解和分析数据
- **为什么需要数据可视化**
  - 处理复杂数据结构、关系和逻辑分类
  - **Anscombe的四重奏**
    - 1973年由统计学家F.J.Anscombe构造的四组数据
    - 统计学特征相近但可视化效果差异大

## 14.2 可视化工具
- **Excel**
  - **优点**：快速分析数据的理想工具，适合创建内部使用的数据图
  - **缺点**：图形化功能有限，难以制作符合专业出版物和网站需要的数据图
- **Google Chart API**
  - **优点**：功能丰富，支持动态图表，适用于所有支持SVG、Canvas和VML的浏览器
  - **缺点**：图表在客户端生成，不支持JavaScript的设备无法使用，无法离线使用或另存为其他格式
- **Visual.ly**
  - **定位**：信息图设计师的在线集市
  - **功能**：提供大量信息图模板，激发灵感
- **Crossfilter**
  - **功能**：展示大数据集的JavaScript库，支持超快交互，适用于上百万或更多数据
  - **特点**：调整一个图表的输入范围时，其他关联图表的数据也会随之改变
- **Polymaps**
  - **功能**：生成多图多变焦的数据集，支持快速矢量数据可视化演示
  - **支持地图**：开放街道地图、CloudMade、微软和其他供应商的基于图像的网络地图制图
- **Kartograph**
  - **功能**：构建交互式地图的简单、轻量级类库
  - **组成**：包含一个Python库用于生成SVG地图，一个Js类库用于前端展示地图
- **Processing**
  - **特点**：数据可视化的招牌工具，编写简单代码并编译成Java
  - **扩展**：Processing.js项目使网站无需Java Applets即可使用Processing，支持Objective-C端口，可在iOS上使用
  - **社区**：拥有大量实例和代码
- **R**
  - **功能**：完整的数据处理、计算和制图软件系统
  - **特点**：
    - 数据存储和处理系统、数组运算工具（尤其强大的是向量、矩阵运算）、完整连贯的统计分析工具
    - 优秀的统计制图功能、简便而强大的编程语言
    - 可操纵数据的输入和输出，实现分支、循环、自定义功能
  - **优势**：提供集成的统计工具和各种数学计算、统计计算的函数，让使用者能灵活地进行数据分析，甚至创造出新的统计计算方法
- **Weka**
  - **全名**：怀卡托智能分析环境 (Waikato Environment for Knowledge Analysis)
  - **功能**：公开的数据挖掘工作平台，集合了大量机器学习算法，包括数据预处理、分类、回归、聚类等
  - **特点**：在新的交互式界面上进行可视化
- **Gephi**
  - **定位**：基于JVM的开源免费跨平台复杂网络分析软件
  - **功能**：用于各种网络和复杂系统的动态和分层图的交互可视化与探测
  - **应用**：探索性数据分析、链接分析、社交网络分析、生物网络分析等
  - **特点**：能处理大规模数据集并生成漂亮的可视化图形，还能对数据进行清洗和分类


# 第15章 大数据与智慧城市 - 思维导图大纲

## 15.1 概述
- **智慧城市建设项目**
  - 全球范围内的重视
  - 信息技术应用于社会基础设施
  - 目标：稳定供给能源、绿色环保
- **大规模项目**
  - 中国天津的“环保城”
  - 阿布扎比的“马斯达尔城”
  - 韩国的“松岛新城”
- **信息技术企业的参与**
  - 自2010年开始参与智慧城市项目
- **智慧城市建设**
  - 庞大数据的整合分析过程
  - 涉及建筑、汽车、家电、信息技术和金融等行业
  - 数据科学中相关技术应用的集大成者

### 15.1.1 智慧城市的定义
- **定义**
  - 新一代信息技术支撑、知识社会下一代创新环境下的城市形态
- **基础**
  - 物联网、云计算等新一代信息技术
  - 维基、社交网络、FabLab、LivingLab、综合集成法等工具和方法
- **目标**
  - 营造有利于创新涌现的生态
  - 高效利用资源、节约成本和能源
  - 改进服务交付和生活质量
  - 减少对环境的影响
  - 支持创新和低碳经济
- **特征**
  - 全面物联、充分整合、激励创新、协同运作
  - 全面透彻的感知、宽带泛在的互联、智能融合的应用、以人为本的可持续创新

### 15.1.2 智慧城市产生背景
- **相关概念**
  - 数字城市、感知城市、无线城市、智能城市、生态城市、低碳城市
  - 电子政务、智能交通、智能电网等行业信息化概念
- **智慧城市的理念**
  - 不仅在于技术应用、网络建设、人的参与、智慧效果
  - 强调以人为本和可持续创新
- **发展源流**
  - 知识社会的创新2.0方法论应用
  - 实现全面感知、泛在互联、普适计算与融合应用
  - 实现以用户创新、开放创新、大众创新、协同创新为特征的可持续创新
- **城市系统**
  - 由组织(人)、业务/政务、交通、通信、水和能源等六个核心系统组成

## 15.2 大数据与智慧城市
- **信息技术的作用**
  - 实现基础设施故障的可视化
  - 实现基础设施管理自动化
- **企业参与**
  - IBM提供智慧城市解决方案
  - Cisco提出“Smart+Connected Communities”理念
  - Accenture发表智能电网数据管理方案
- **跨行业合作**
  - 信息技术企业与房屋设备、电动车、空调、灯具等制造商协作
  - 开拓新的服务内容和应用市场

### 15.2.1 智慧城市的基本特征与层次构成
- **基本特征**
  - **物联化**：基于传感器的系统扩展可见性，提供新的实时数据源
  - **互联化**：事件处理软件导出和业务相关的事件，实现对运营系统的实际行为的洞察
  - **智能化**：数学算法和统计工具利用可用数据提供对城市事件的更深入洞察
- **层次构成**
  - **物联化层**
	- 传感器、制动器、可编程的逻辑控制器(PLC)和分布式智能传感器
	- 数据捕获和控制、管理分布式设备基础设施
  - **互联化层**
	- 事件处理和服务、数据建模和集成、流程整合
  - **智能化层**
	- 分析功能、业务优化功能

### 15.2.2 智慧城市建设中所应用的数据科学技术
- **数据信息的收集**
  - 利用传感网络收集数据信息
  - 智能电表的应用
- **数据信息的整合**
  - 不同数据信息的整合和统一管理
  - 数据信息整合平台
- **数据信息分析与应用**
  - 大容量、实时性分析技术
  - Hadoop技术
  - 流计算技术

## 15.3 智慧城市案例
### 15.3.1 韩国
- **松岛新城**
  - 智能大厦、商务园区、会展中心、住宅小区
  - 照明控制、耗电记录集中管理
  - 视频会议系统实现远程教学及远程医疗

### 15.3.2 日本
- **“智慧日本”战略**
  - 电子化政府治理、医疗健康信息服务、教育与人才培育
- **电子病历系统**
  - 基本普及在各类医院
  - 整合各种临床信息系统和知识库

### 15.3.3 美国
- **哥伦布市**
  - 良好的服务产业生态系统
  - 54所大学，包括俄亥俄州立大学哥伦布校区
  - 2013年，全市共有4家公司入选美国《财富》500强名单
  - 超级计算机中心(Ohio Supercomputer Center, OSC)
  - 无线网络部署
  - 能源改革
  - 绿色经济实用住房项目
  - 公共教育活动“实现绿色哥伦布”
  - E3项目
  - 自行车道修建
- **其他建设智慧城市的举措**
  - 建设现代化的城市电网
  - 研制虚拟车辆设计平台
  - 智能道路照明工程
  - 联邦智能交通系统
  - 优化能源分配，保证电力供给
  - 大数据推动智能水资源管理
  - 减少交通事故

### 15.3.4 爱沙尼亚
- **塔林市**
  - 全球智慧社区论坛公布的“2013全球7大智慧城市”之一
  - 内阁会议无纸化
  - 所有学校均可上网
  - 18分钟即可通过网络注册公司
  - 98%的银行交易通过网络完成
  - 91%的所得税通过电子平台申报
  - 无线网络覆盖率超过98%

### 15.3.5 荷兰
- **阿姆斯特丹智慧城市计划(Amsterdam Smart City, ASC)**
  - **可持续性生活**
	- West Orange项目
	- Geuzenveld项目
  - **可持续性工作**
	- 智能大厦项目
  - **可持续性交通**
	- Energy Dock项目
  - **可持续性公共空间**
	- 气候街道(the Climate Street)

### 15.3.6 英国
- **打造“数字”之都**
  - 《数字英国》(Digital Britain)计划
  - 2012年建成覆盖所有人口的宽带网络
- **智能屋试点应用**
  - 格洛斯特的“智能屋”试点
  - 中央电脑控制各种家庭设备
- **“贝丁顿零化石能源发展”生态社区**
  - 楼顶风帽自然通风装置
  - 节约81%的供热能耗以及45%的电力消耗

### 15.3.7 巴西
- **里约热内卢城市运营中心**
  - IBM公司设计的城市运营管理系统
  - 整合30多个城市管理部门数据
  - 实现信息共享和协同工作
  - 提高城市应急响应能力


# 第16章 大数据与智慧医疗 - 思维导图大纲

## 16.1 概述
- **大数据浪潮**
  - 从计算机、互联网、云计算到物联网
  - 医疗服务作为人类基本需求，数据量庞大
- **医疗数字化**
  - 病历、影像、远程医疗等产生大量数据
  - 大数据应用于临床诊断、远程监控、药品研发、防止医疗诈骗等
- **医疗大数据的价值**
  - 麦肯锡：大数据是生产资料
  - 医疗大数据分析可为美国产生3000亿美元价值，减少8%的医疗保健支出
- **医疗数据的增长**
  - 到2020年，医疗数据将增至35ZB，是2009年的44倍
  - 影像数据增长最快，其次是EMR电子病历数据
- **医疗数据类型**
  - 医学影像数据
  - 电子病例、电子健康档案
  - 基因组学、蛋白组学数据

## 16.2 智慧医疗的范畴
### 16.2.1 临床操作
- **比较效果研究**
  - 通过分析病人特征和疗效数据，找到最佳治疗途径
  - 精准分析对象包括病人体征、费用和疗效数据
- **临床决策支持系统**
  - 提高工作效率和诊疗质量
  - 防止潜在的错误，如药物不良反应
- **医疗数据透明度**
  - 提高医疗过程数据的透明度，促进医疗服务质量提高
- **远程病人监控**
  - 对慢性病患者进行远程监控，收集数据并反馈给监控设备
- **对病人档案的先进分析**
  - 确定某类疾病的易感人群，提供预防性保健方案

### 16.2.2 付款/定价
- **自动化系统**
  - 检测欺诈行为，减少医疗索赔欺诈
- **基于卫生经济学和疗效研究的定价计划**
  - 制药公司参与分担治疗风险，基于治疗效果制定定价策略

### 16.2.3 研发
- **预测建模**
  - 通过数据建模和分析，确定最有效率的投入产出比
- **提高临床试验设计的统计工具和算法**
  - 提高临床试验设计水平，加快招募患者
- **临床实验数据的分析**
  - 确定药品更多的适应症，发现副作用
- **个性化治疗**
  - 通过对大型数据集的分析发展个性化治疗
- **疾病模式的分析**
  - 分析疾病模式和趋势，优化研发重点

### 16.2.4 新的商业模式
- **汇总患者的临床记录和医疗保险数据集**
  - 提高医疗支付方、医疗服务提供方和医药企业的决策能力
- **网络平台和社区**
  - 病人和医生分享治疗经验和医疗见解的平台

### 16.2.5 公众健康
- **改善公众健康监控**
  - 通过患者电子病历数据库，快速检测传染病，进行疫情监测

### 16.2.6 思维模式启示
- **大数据带来的挑战**
  - 数据存储安全、效率、成本问题
- **科学规划存储架构**
  - 提高数据恢复能力，减少存储扩容压力

## 16.3 大数据与智慧医疗
### 16.3.1 大数据服务心脏病患者
- **加州太平洋医疗中心**
  - 使用IBM SPSS Statistics软件管理和分析心脏病患者数据
  - 开发准确的心脏病风险模型，改善患者长期治疗成果

### 16.3.2 “魔毯”病人的监控
- **GE和Intel联合开发**
  - 使用家中地毯内装的传感器，感应老人下床和行走的速度和压力

### 16.3.3 大数据监测脑外伤病人恢复
- **IBM公司、Excel Medical Electronics公司与UCLA合作**
  - 利用大数据技术预测脑外伤病人的脑部压力情况

### 16.3.4 大数据帮助实现个性化用药和诊断
- **个性化用药指南和标准**
  - 根据个人基因情况实现个性化诊断和用药

## 16.4 可穿戴技术
### 16.4.1 可穿戴技术的概念
- **定义**
  - 能直接穿在身上或整合进用户衣服或配件的科学技术
- **发展历程**
  - 20世纪60年代提出，70年代发明可穿戴式计算机，1977年发明盲人背心

### 16.4.2 可穿戴设备简析
- **美信：生命体征测量T恤**
  - 嵌有多种传感器，测量心电图、体温及用户活动量
- **TI的Health Tech产品**
  - 提高整合度、降低功耗，拥有智能连接的组件
- **Valencell: 可随身穿戴的微型生理监测模块**
  - 包含传感器模块、数字信号处理芯片及生物辨识韧体
- **Google Glass**
  - 结合声控、导航、照相与视频聊天功能的可穿戴式IT产品
- **苹果iWatch**
  - 内置iOS系统，支持Facetime、WiFi、蓝牙、Airplay等功能
- **BrainLink 意念头箍**
  - 头戴式脑电波传感器，通过蓝牙连接智能手机等终端设备

### 16.4.3 可穿戴设备与智慧医疗
- **体外数据采集**
  - 通过运动传感器或GPS获取运动状况、运动距离和运动量
- **体征数据监测**
  - 监测心率、脉率、呼吸频率、体温等重要生理活动

### 16.4.4 思维启示——可穿戴设备的缺陷
- **技术挑战**
  - 测量的精准度及人们使用的随意性
- **隐私保护**
  - 可穿戴设备提供大量数据，个人隐私泄露风险增加

## 16.5 总结与展望
- **数据安全与隐私保护**
  - 建立健全的数据安全管理体系，保护患者隐私
- **技术创新与标准化**
  - 加强技术创新，制定和完善技术标准和规范
- **人才培养与团队建设**
  - 加强人才培养，提高医疗从业人员的信息化素养
- **公众认知与接受度**
  - 加强宣传和教育，提高公众对智慧医疗的认知度和接受度
- **未来展望**
  - 大数据与智慧医疗结合将迎来广阔发展前景，推动医疗服务的个性化和精准化


# 第17章 大数据与未来生活 - 思维导图大纲

## 17.1 数据科学家
### 17.1.1 数据科学家的定义
- **科学家**
  - 从生硬的数据中找出潜在的趋势，形成知识与智慧
- **艺术家**
  - 解读数据中的精彩故事，是分析家与艺术家的结合
- **探险家**
  - 运用多种技巧，找到数据背后的秘密，发掘新机遇
- **革命家**
  - 数据与智慧的桥梁，改变世界
- **超人**
  - 计算机科学家、统计学家，懂数学、明算理、知人文、会创造、能发现

### 17.1.2 数据科学家的从业前景
- **大数据从业人员的薪金水平**
  - BI从业者平均薪金为90000美元，管理者平均薪水为119000美元
  - 数据整合领域薪金更高，普通从业者和管理者分别为97000美元和120000美元
- **企业对数据科学家的需求**
  - 帮助组织在大量信息中挖掘有价值的数据，转化为深入的认知和精准预测的模型
  - 制造商研究需求数据和供应链信息，互联网企业分析客户单击流数据，零售企业分析密集型数据，医疗领域提高诊断和治疗效率
- **大数据领域从业人员的十个趋势**
  - **趋势一：薪金将继续增长**
	- BI管理者薪金将达134000美元，普通BI从业者薪金将达到96000美元
	- 数据整合和数据仓库管理人员薪金将达131000美元，普通工作人员薪金101000美元
  - **趋势二：大数据人才供不应求**
	- 未来6年，美国本土可能缺乏14万～19万具备深入分析数据能力的人才，150万管理人员和分析师缺口
  - **趋势三：雇佣外包**
	- 25%的组织将大数据分析业务外包给美国和境外企业，17%的组织外包给美国境内企业，22%的组织外包给境外企业
  - **趋势四：人才团队内出现分歧**
	- 新生代从业人员更喜欢使用开放的开源工具和云计算，对工作环境更敏感
  - **趋势五：大数据专业人士需要不断进步**
	- 引入更多特定技术培训和认证课程，统计学和分析学培训非常有价值
  - **趋势六：精通大数据的专业人才将成为最重要的业务角色**
	- 55%的管理和工作人员具备IT以外的相关经验，承担更多非IT领域的职责
  - **趋势七：大数据领域需要数据科学家**
	- 数据科学家擅长将统计学方式用于开发算法，了解如何建立统计模型
  - **趋势八：高校回应大数据人才缺口**
	- 企业寻找基于R语言统计编程以及基于Hadoop、MapReduce编程的人员，众多大学加强机器学习相关课程
  - **趋势九：数据驱动的工作令人满意并充满挑战**
	- 69%的BI和数据整合从业人员对工作满意，91%的BI分析和IM人员以及93%的管理人士受到智力挑战
  - **趋势十：大数据专业人士将拥抱未来**
	- 提高薪酬待遇并延长职业生涯，需要熟悉下一代专业知识的方法和技术

## 17.2 对未来数据科学发展的探讨
### 17.2.1 数据不是万能的
- **数据不懂社交**
  - 大脑懂得社会认知，擅长反射彼此的情绪状态，侦测不合作的行为
- **计算机数据分析擅长测量社会交往的“量”而非“质”**
  - 网络科学家可以测量社交互动情况，但无法捕捉感情
- **数据不懂背景**
  - 人类的决策镶嵌在时间序列和背景之中，数据分析不懂叙事和思维的浮现过程
- **数据会制造出更大的“干草垛”**
  - 随着数据增多，统计上的相关关系增多，欺骗性增长
- **大数据无法解决大问题**
  - 大数据不能找到平行世界中的社会来当对照组，无法解决经济刺激等大问题
- **数据偏爱潮流，忽视杰作**
  - 数据分析可以侦测文化产品的趋势，但会摒弃一些重要的特异产品
- **数据掩盖了价值观念**
  - 数据依照某人的倾向和价值观念构建，数据分析结果看似客观，但价值选择贯穿全过程

### 17.2.2 提防进入数据误区
- **数据的可接近性并不使得使用合乎伦理**
  - 大数据监测和预示生活方便，但个人隐私暴露，匿名化失效，可能践踏人性价值
- **越大的数据并不是越好的数据**
  - 对数据的盲目依赖导致思维和决策僵化，滥用数据或分析失误损害民众安全和利益
- **大数据的有线接入产生新的垄断和数码沟**
  - 数据垄断阻碍信息流动，浪费数据资源，阻碍创新，大数据应用存在接入和技能双重鸿沟
